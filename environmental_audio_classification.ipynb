{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srilekha-03/deep-learning/blob/main/environmental_audio_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpJkApALgX6X",
        "outputId": "9f229bfd-8537-40f2-8684-ddf2c312ce97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest...\n",
            "Training XGBoost...\n",
            "Training SVM...\n",
            "Training MLP...\n",
            "\n",
            "Model Performance:\n",
            "Random Forest: Accuracy = 0.5309\n",
            "XGBoost: Accuracy = 0.5235\n",
            "SVM: Accuracy = 0.0889\n",
            "MLP: Accuracy = 0.2395\n",
            "\n",
            "Hyperparameter Tuning for Random Forest...\n",
            "Best Parameters: {'max_depth': 20, 'n_estimators': 200}\n",
            "Best Score (CV): 0.49259259259259264\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          Axe       0.36      0.36      0.36        14\n",
            " BirdChirping       0.79      0.69      0.73        16\n",
            "     Chainsaw       0.69      0.73      0.71        15\n",
            "     Clapping       0.83      0.25      0.38        20\n",
            "         Fire       0.78      0.88      0.82        16\n",
            "     Firework       0.25      0.38      0.30        13\n",
            "    Footsteps       0.33      0.44      0.38        16\n",
            "         Frog       0.83      0.29      0.43        17\n",
            "    Generator       0.40      0.20      0.27        10\n",
            "      Gunshot       0.55      0.35      0.43        17\n",
            "      Handsaw       0.67      1.00      0.80        12\n",
            "   Helicopter       0.67      0.67      0.67        24\n",
            "       Insect       0.75      0.75      0.75        20\n",
            "         Lion       0.50      0.33      0.40        12\n",
            "         Rain       0.33      0.42      0.37        12\n",
            "      Silence       0.81      0.93      0.87        14\n",
            "     Speaking       0.54      0.37      0.44        19\n",
            "     Squirrel       0.41      0.41      0.41        17\n",
            " Thunderstorm       0.50      0.67      0.57        15\n",
            "  TreeFalling       0.40      0.73      0.52        11\n",
            "VehicleEngine       0.44      0.36      0.40        11\n",
            "   WaterDrops       0.58      0.73      0.65        15\n",
            "    Whistling       0.67      0.62      0.64        13\n",
            "         Wind       0.70      0.64      0.67        22\n",
            "  WingFlaping       0.33      0.06      0.11        16\n",
            "     WolfHowl       0.59      0.91      0.71        11\n",
            "     WoodChop       0.17      0.57      0.27         7\n",
            "\n",
            "     accuracy                           0.54       405\n",
            "    macro avg       0.55      0.55      0.52       405\n",
            " weighted avg       0.58      0.54      0.53       405\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  9]\n",
            " [ 0 11  0  0  1  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  1  0\n",
            "   0  0  0]\n",
            " [ 0  0 11  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  1  1\n",
            "   0  0  0]\n",
            " [ 2  0  0  5  0  3  1  0  0  1  3  0  0  0  0  0  0  0  0  2  0  0  0  0\n",
            "   0  0  3]\n",
            " [ 0  0  0  0 14  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
            "   0  0  0]\n",
            " [ 4  0  0  0  0  5  1  0  0  0  0  0  0  0  0  0  0  1  2  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  1  1  7  0  0  0  0  0  0  0  0  0  0  0  1  3  0  1  0  0\n",
            "   0  0  2]\n",
            " [ 0  1  0  0  0  1  1  5  0  0  0  0  2  0  0  0  1  2  0  0  0  1  1  0\n",
            "   0  2  0]\n",
            " [ 0  0  2  0  0  0  0  0  2  0  1  0  1  0  1  0  0  1  0  1  0  0  0  1\n",
            "   0  0  0]\n",
            " [ 1  0  1  0  0  1  1  0  0  6  0  0  0  0  0  0  0  1  0  1  0  1  0  0\n",
            "   1  0  3]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0 16  0  0  1  0  1  0  2  1  1  0  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  1  0  0  1 15  0  0  0  0  1  0  0  1  0  0  0\n",
            "   0  0  0]\n",
            " [ 1  0  0  1  0  2  0  0  0  0  0  0  0  4  0  0  0  0  2  0  0  0  0  0\n",
            "   1  1  0]\n",
            " [ 0  0  1  0  0  0  1  0  0  0  0  0  0  0  5  2  0  1  1  0  0  0  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 13  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  1  0  0  0  1  0  0  1  1  1  2  0  1  0  0  7  1  0  0  0  0  0  1\n",
            "   0  2  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  0  0  3  1  0  0  1  1  7  0  1  1  1  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  1  0 10  0  1  0  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  8  0  1  1  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  1  1  1  0  0  1  0  0  2  0  0  1  0  0  4  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  2  0 11  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  1  0  0  0  0  0  8  0\n",
            "   0  2  0]\n",
            " [ 0  0  0  0  1  1  1  0  0  0  0  0  0  0  3  0  1  0  1  0  0  0  0 14\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  1  1  4  0  0  1  0  0  0  2  1  0  0  1  1  0  1  0  0  0\n",
            "   1  0  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
            "   0 10  0]\n",
            " [ 1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
            "   0  0  4]]\n",
            "\n",
            "Best model saved as 'best_model.pkl'!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/sample_data/extracted_features_final.csv')  # Replace with your actual file path\n",
        "\n",
        "# Encode the target column (Class Name)\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded Class'] = label_encoder.fit_transform(df['Class Name'])  # Add encoded column\n",
        "\n",
        "# Drop 'Class ID' and select features/target\n",
        "df = df.drop(columns=['Class ID'])  # Drop 'Class ID' column\n",
        "X = df.iloc[:, 1:-1].values  # Features (exclude 'Class Name' and 'Encoded Class')\n",
        "y = df['Encoded Class'].values  # Encoded target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# 1. Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "results['Random Forest'] = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# 2. XGBoost\n",
        "print(\"Training XGBoost...\")\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "results['XGBoost'] = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# 3. Support Vector Machine (SVM)\n",
        "print(\"Training SVM...\")\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "results['SVM'] = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "# 4. Neural Network (MLP Classifier)\n",
        "print(\"Training MLP...\")\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "results['MLP'] = accuracy_score(y_test, y_pred_mlp)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nModel Performance:\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: Accuracy = {acc:.4f}\")\n",
        "\n",
        "# Hyperparameter Tuning for Random Forest\n",
        "print(\"\\nHyperparameter Tuning for Random Forest...\")\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None]\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score (CV):\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_best, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "\n",
        "joblib.dump(best_model, 'best_model.pkl')\n",
        "print(\"\\nBest model saved as 'best_model.pkl'!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHds3QEo1xiW",
        "outputId": "cd0aa299-9f2e-4207-8370-aa10aa478684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eb9xRbP5oou",
        "outputId": "0205546c-8cd6-41dd-a8dd-f50c8c73285f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==1.0.2 in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn==1.0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoFEKpQ65wdL",
        "outputId": "70484bb5-cc17-4a86-c34c-3fdc5815a377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade xgboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-SLNc6r5z-N",
        "outputId": "0e241d11-3b72-4739-c575-26ded4e96eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Voting Classifier Performance:\n",
            "Voting Classifier Accuracy: 0.4741\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Define individual classifiers\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "svm = SVC(kernel='rbf', random_state=42, probability=True)  # Set probability=True for soft voting\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
        "\n",
        "# Create a voting classifier (soft voting)\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', rf), ('xgb', xgb), ('svm', svm), ('mlp', mlp)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "results['Voting Classifier'] = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nVoting Classifier Performance:\")\n",
        "print(f\"Voting Classifier Accuracy: {results['Voting Classifier']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIrUazU45AmM",
        "outputId": "feb3eb5f-f6ca-41ca-98ec-43a6cba4e447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Voting Classifier Performance:\n",
            "Voting Classifier Accuracy: 0.4741\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Define individual classifiers\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "svm = SVC(kernel='rbf', random_state=42, probability=True)  # Set probability=True for soft voting\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
        "\n",
        "# Create a voting classifier (soft voting)\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', rf), ('xgb', xgb), ('svm', svm), ('mlp', mlp)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "results['Voting Classifier'] = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nVoting Classifier Performance:\")\n",
        "print(f\"Voting Classifier Accuracy: {results['Voting Classifier']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ihWeeS25PDf",
        "outputId": "dbb26334-8b8c-46d8-b5bd-df68ec294de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bagging SVM Performance:\n",
            "Bagging SVM Accuracy: 0.0889\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Bagging for SVM\n",
        "bagging_svm = BaggingClassifier(base_estimator=SVC(kernel='rbf', random_state=42), n_estimators=50, random_state=42)\n",
        "bagging_svm.fit(X_train, y_train)\n",
        "y_pred_bagging_svm = bagging_svm.predict(X_test)\n",
        "results['Bagging SVM'] = accuracy_score(y_test, y_pred_bagging_svm)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nBagging SVM Performance:\")\n",
        "print(f\"Bagging SVM Accuracy: {results['Bagging SVM']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJPLIcAP5Ruz",
        "outputId": "2b19aded-2a6e-4be9-8bf2-505fad38dc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AdaBoost Performance:\n",
            "AdaBoost Accuracy: 0.5111\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# AdaBoost with Random Forest as base estimator\n",
        "ada_boost = AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=42), n_estimators=50, random_state=42)\n",
        "ada_boost.fit(X_train, y_train)\n",
        "y_pred_ada = ada_boost.predict(X_test)\n",
        "results['AdaBoost'] = accuracy_score(y_test, y_pred_ada)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nAdaBoost Performance:\")\n",
        "print(f\"AdaBoost Accuracy: {results['AdaBoost']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-N3Mb-k5Vln",
        "outputId": "e1e542a8-93b3-4ef4-baa1-82323eb07012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Gradient Boosting Performance:\n",
            "Gradient Boosting Accuracy: 0.4914\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Gradient Boosting\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "results['Gradient Boosting'] = accuracy_score(y_test, y_pred_gb)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nGradient Boosting Performance:\")\n",
        "print(f\"Gradient Boosting Accuracy: {results['Gradient Boosting']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_fOzBT05YLX",
        "outputId": "b8edc890-1c5e-4416-dbe3-4da885da227a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Stacking Classifier Performance:\n",
            "Stacking Classifier Accuracy: 0.2988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define base models\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(random_state=42)),\n",
        "    ('xgb', XGBClassifier(random_state=42)),\n",
        "    ('svm', SVC(kernel='rbf', random_state=42)),\n",
        "    ('mlp', MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "# Define meta-model\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "# Create a stacking classifier\n",
        "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_stacking = stacking_clf.predict(X_test)\n",
        "results['Stacking Classifier'] = accuracy_score(y_test, y_pred_stacking)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nStacking Classifier Performance:\")\n",
        "print(f\"Stacking Classifier Accuracy: {results['Stacking Classifier']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jhp0CaHAGeS",
        "outputId": "782f79cd-b3ff-4bda-bcac-eaf1d6944885"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ANN...\n",
            "Epoch 1/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.0691 - loss: 3.3290 - val_accuracy: 0.1679 - val_loss: 2.9303\n",
            "Epoch 2/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1343 - loss: 2.9649 - val_accuracy: 0.2321 - val_loss: 2.6682\n",
            "Epoch 3/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1813 - loss: 2.7876 - val_accuracy: 0.2914 - val_loss: 2.4671\n",
            "Epoch 4/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2259 - loss: 2.6006 - val_accuracy: 0.3062 - val_loss: 2.3164\n",
            "Epoch 5/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2815 - loss: 2.4205 - val_accuracy: 0.3284 - val_loss: 2.2174\n",
            "Epoch 6/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2803 - loss: 2.3913 - val_accuracy: 0.3259 - val_loss: 2.1440\n",
            "Epoch 7/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3234 - loss: 2.2870 - val_accuracy: 0.3309 - val_loss: 2.0783\n",
            "Epoch 8/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3017 - loss: 2.2430 - val_accuracy: 0.3556 - val_loss: 2.0151\n",
            "Epoch 9/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3547 - loss: 2.1344 - val_accuracy: 0.3679 - val_loss: 1.9805\n",
            "Epoch 10/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3339 - loss: 2.1780 - val_accuracy: 0.3704 - val_loss: 1.9722\n",
            "Epoch 11/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3427 - loss: 2.1547 - val_accuracy: 0.3728 - val_loss: 1.9327\n",
            "Epoch 12/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4045 - loss: 2.0321 - val_accuracy: 0.3951 - val_loss: 1.9051\n",
            "Epoch 13/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3900 - loss: 1.9888 - val_accuracy: 0.4000 - val_loss: 1.8730\n",
            "Epoch 14/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3767 - loss: 2.0440 - val_accuracy: 0.4123 - val_loss: 1.8541\n",
            "Epoch 15/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3524 - loss: 2.0274 - val_accuracy: 0.4074 - val_loss: 1.8564\n",
            "Epoch 16/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3933 - loss: 1.9368 - val_accuracy: 0.4148 - val_loss: 1.8332\n",
            "Epoch 17/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4019 - loss: 1.9439 - val_accuracy: 0.4370 - val_loss: 1.8288\n",
            "Epoch 18/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4004 - loss: 1.9022 - val_accuracy: 0.4222 - val_loss: 1.7947\n",
            "Epoch 19/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3944 - loss: 1.9066 - val_accuracy: 0.4321 - val_loss: 1.7989\n",
            "Epoch 20/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4139 - loss: 1.8795 - val_accuracy: 0.4296 - val_loss: 1.7769\n",
            "Epoch 21/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4269 - loss: 1.8497 - val_accuracy: 0.4346 - val_loss: 1.7730\n",
            "Epoch 22/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4472 - loss: 1.7760 - val_accuracy: 0.4370 - val_loss: 1.7499\n",
            "Epoch 23/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4183 - loss: 1.8425 - val_accuracy: 0.4395 - val_loss: 1.7443\n",
            "Epoch 24/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4494 - loss: 1.7683 - val_accuracy: 0.4444 - val_loss: 1.7414\n",
            "Epoch 25/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4586 - loss: 1.8133 - val_accuracy: 0.4494 - val_loss: 1.7117\n",
            "Epoch 26/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4635 - loss: 1.7166 - val_accuracy: 0.4617 - val_loss: 1.6972\n",
            "Epoch 27/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4955 - loss: 1.6599 - val_accuracy: 0.4691 - val_loss: 1.6795\n",
            "Epoch 28/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4539 - loss: 1.6661 - val_accuracy: 0.4642 - val_loss: 1.6749\n",
            "Epoch 29/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4535 - loss: 1.7058 - val_accuracy: 0.4667 - val_loss: 1.6568\n",
            "Epoch 30/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4711 - loss: 1.7339 - val_accuracy: 0.4815 - val_loss: 1.6420\n",
            "Epoch 31/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5006 - loss: 1.6353 - val_accuracy: 0.4864 - val_loss: 1.6527\n",
            "Epoch 32/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4828 - loss: 1.6357 - val_accuracy: 0.4864 - val_loss: 1.6398\n",
            "Epoch 33/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4750 - loss: 1.6371 - val_accuracy: 0.4840 - val_loss: 1.6404\n",
            "Epoch 34/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5277 - loss: 1.5844 - val_accuracy: 0.4938 - val_loss: 1.6214\n",
            "Epoch 35/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4872 - loss: 1.6705 - val_accuracy: 0.4889 - val_loss: 1.6162\n",
            "Epoch 36/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5093 - loss: 1.5575 - val_accuracy: 0.5309 - val_loss: 1.5972\n",
            "Epoch 37/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4812 - loss: 1.6743 - val_accuracy: 0.4889 - val_loss: 1.6001\n",
            "Epoch 38/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5284 - loss: 1.5243 - val_accuracy: 0.4914 - val_loss: 1.6011\n",
            "Epoch 39/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5225 - loss: 1.5282 - val_accuracy: 0.4988 - val_loss: 1.6096\n",
            "Epoch 40/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4937 - loss: 1.5589 - val_accuracy: 0.5383 - val_loss: 1.5805\n",
            "Epoch 41/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4920 - loss: 1.5866 - val_accuracy: 0.4938 - val_loss: 1.5907\n",
            "Epoch 42/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5218 - loss: 1.5348 - val_accuracy: 0.4889 - val_loss: 1.6017\n",
            "Epoch 43/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5105 - loss: 1.4911 - val_accuracy: 0.5210 - val_loss: 1.5661\n",
            "Epoch 44/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5047 - loss: 1.4831 - val_accuracy: 0.5086 - val_loss: 1.5678\n",
            "Epoch 45/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5156 - loss: 1.5089 - val_accuracy: 0.5185 - val_loss: 1.5727\n",
            "Epoch 46/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5416 - loss: 1.4252 - val_accuracy: 0.5037 - val_loss: 1.5776\n",
            "Epoch 47/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 1.4527 - val_accuracy: 0.5259 - val_loss: 1.5598\n",
            "Epoch 48/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5465 - loss: 1.3998 - val_accuracy: 0.5160 - val_loss: 1.5437\n",
            "Epoch 49/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 1.4531 - val_accuracy: 0.5111 - val_loss: 1.5515\n",
            "Epoch 50/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5548 - loss: 1.4351 - val_accuracy: 0.5407 - val_loss: 1.5285\n",
            "Epoch 51/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5294 - loss: 1.4408 - val_accuracy: 0.5333 - val_loss: 1.5220\n",
            "Epoch 52/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5184 - loss: 1.4782 - val_accuracy: 0.5605 - val_loss: 1.5114\n",
            "Epoch 53/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 1.4463 - val_accuracy: 0.5432 - val_loss: 1.5128\n",
            "Epoch 54/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5332 - loss: 1.4199 - val_accuracy: 0.5333 - val_loss: 1.5220\n",
            "Epoch 55/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5666 - loss: 1.3307 - val_accuracy: 0.5383 - val_loss: 1.5096\n",
            "Epoch 56/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5441 - loss: 1.3834 - val_accuracy: 0.5605 - val_loss: 1.4944\n",
            "Epoch 57/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5670 - loss: 1.3401 - val_accuracy: 0.5605 - val_loss: 1.4824\n",
            "Epoch 58/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5498 - loss: 1.3850 - val_accuracy: 0.5235 - val_loss: 1.5025\n",
            "Epoch 59/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5743 - loss: 1.3496 - val_accuracy: 0.5309 - val_loss: 1.4983\n",
            "Epoch 60/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5690 - loss: 1.3295 - val_accuracy: 0.5531 - val_loss: 1.4936\n",
            "Epoch 61/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5694 - loss: 1.3787 - val_accuracy: 0.5556 - val_loss: 1.4877\n",
            "Epoch 62/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5482 - loss: 1.3821 - val_accuracy: 0.5481 - val_loss: 1.4899\n",
            "Epoch 63/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5620 - loss: 1.3744 - val_accuracy: 0.5358 - val_loss: 1.4892\n",
            "Epoch 64/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5641 - loss: 1.3581 - val_accuracy: 0.5506 - val_loss: 1.4921\n",
            "Epoch 65/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5729 - loss: 1.3196 - val_accuracy: 0.5481 - val_loss: 1.4890\n",
            "Epoch 66/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 1.3033 - val_accuracy: 0.5605 - val_loss: 1.4987\n",
            "Epoch 67/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5771 - loss: 1.3049 - val_accuracy: 0.5457 - val_loss: 1.4999\n",
            "Epoch 68/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5804 - loss: 1.3156 - val_accuracy: 0.5704 - val_loss: 1.4830\n",
            "Epoch 69/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5787 - loss: 1.3215 - val_accuracy: 0.5630 - val_loss: 1.4800\n",
            "Epoch 70/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5877 - loss: 1.2731 - val_accuracy: 0.5333 - val_loss: 1.4906\n",
            "Epoch 71/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5846 - loss: 1.2181 - val_accuracy: 0.5630 - val_loss: 1.4805\n",
            "Epoch 72/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5784 - loss: 1.2833 - val_accuracy: 0.5852 - val_loss: 1.4579\n",
            "Epoch 73/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 1.2508 - val_accuracy: 0.5728 - val_loss: 1.4619\n",
            "Epoch 74/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5717 - loss: 1.3071 - val_accuracy: 0.5753 - val_loss: 1.4617\n",
            "Epoch 75/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5920 - loss: 1.2590 - val_accuracy: 0.5457 - val_loss: 1.4885\n",
            "Epoch 76/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6080 - loss: 1.1668 - val_accuracy: 0.5901 - val_loss: 1.4540\n",
            "Epoch 77/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 1.2103 - val_accuracy: 0.5827 - val_loss: 1.4578\n",
            "Epoch 78/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5636 - loss: 1.2900 - val_accuracy: 0.5753 - val_loss: 1.4749\n",
            "Epoch 79/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5887 - loss: 1.2781 - val_accuracy: 0.5802 - val_loss: 1.4611\n",
            "Epoch 80/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 1.1797 - val_accuracy: 0.5975 - val_loss: 1.4572\n",
            "Epoch 81/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 1.1885 - val_accuracy: 0.5679 - val_loss: 1.4788\n",
            "Epoch 82/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 1.2020 - val_accuracy: 0.5901 - val_loss: 1.4720\n",
            "Epoch 83/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 1.2062 - val_accuracy: 0.5802 - val_loss: 1.4645\n",
            "Epoch 84/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 1.1881 - val_accuracy: 0.5728 - val_loss: 1.4621\n",
            "Epoch 85/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 1.2626 - val_accuracy: 0.5580 - val_loss: 1.4679\n",
            "Epoch 86/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 1.2543 - val_accuracy: 0.5457 - val_loss: 1.4735\n",
            "Epoch 87/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 1.1692 - val_accuracy: 0.6000 - val_loss: 1.4307\n",
            "Epoch 88/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6077 - loss: 1.1880 - val_accuracy: 0.5679 - val_loss: 1.4648\n",
            "Epoch 89/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6048 - loss: 1.1980 - val_accuracy: 0.5778 - val_loss: 1.4638\n",
            "Epoch 90/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 1.1475 - val_accuracy: 0.5753 - val_loss: 1.4573\n",
            "Epoch 91/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5942 - loss: 1.2207 - val_accuracy: 0.5630 - val_loss: 1.4648\n",
            "Epoch 92/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6088 - loss: 1.1904 - val_accuracy: 0.5802 - val_loss: 1.4571\n",
            "Epoch 93/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 1.2126 - val_accuracy: 0.5827 - val_loss: 1.4567\n",
            "Epoch 94/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6020 - loss: 1.1693 - val_accuracy: 0.5728 - val_loss: 1.4613\n",
            "Epoch 95/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6369 - loss: 1.1189 - val_accuracy: 0.5901 - val_loss: 1.4397\n",
            "Epoch 96/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6453 - loss: 1.1575 - val_accuracy: 0.5778 - val_loss: 1.4424\n",
            "Epoch 97/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6099 - loss: 1.1525 - val_accuracy: 0.5852 - val_loss: 1.4559\n",
            "Epoch 98/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6305 - loss: 1.1234 - val_accuracy: 0.5704 - val_loss: 1.4683\n",
            "Epoch 99/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5991 - loss: 1.2115 - val_accuracy: 0.5679 - val_loss: 1.4578\n",
            "Epoch 100/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6473 - loss: 1.0646 - val_accuracy: 0.5975 - val_loss: 1.4392\n",
            "Epoch 101/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 1.1174 - val_accuracy: 0.5802 - val_loss: 1.4756\n",
            "Epoch 102/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 1.2137 - val_accuracy: 0.5778 - val_loss: 1.4593\n",
            "Epoch 103/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 1.1487 - val_accuracy: 0.5802 - val_loss: 1.4639\n",
            "Epoch 104/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 1.1183 - val_accuracy: 0.5556 - val_loss: 1.4670\n",
            "Epoch 105/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 1.1084 - val_accuracy: 0.5926 - val_loss: 1.4625\n",
            "Epoch 106/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6393 - loss: 1.0773 - val_accuracy: 0.5877 - val_loss: 1.4592\n",
            "Epoch 107/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6288 - loss: 1.0896 - val_accuracy: 0.5951 - val_loss: 1.4407\n",
            "Epoch 108/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6549 - loss: 1.0496 - val_accuracy: 0.6049 - val_loss: 1.4407\n",
            "Epoch 109/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6476 - loss: 1.0582 - val_accuracy: 0.5951 - val_loss: 1.4517\n",
            "Epoch 110/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6529 - loss: 1.0752 - val_accuracy: 0.6000 - val_loss: 1.4438\n",
            "Epoch 111/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6383 - loss: 1.0774 - val_accuracy: 0.5901 - val_loss: 1.4548\n",
            "Epoch 112/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6496 - loss: 1.0493 - val_accuracy: 0.5778 - val_loss: 1.4619\n",
            "Epoch 113/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 1.1011 - val_accuracy: 0.5827 - val_loss: 1.4658\n",
            "Epoch 114/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6410 - loss: 1.0838 - val_accuracy: 0.5704 - val_loss: 1.4599\n",
            "Epoch 115/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6404 - loss: 1.0834 - val_accuracy: 0.5951 - val_loss: 1.4576\n",
            "Epoch 116/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 1.1232 - val_accuracy: 0.6049 - val_loss: 1.4633\n",
            "Epoch 117/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6376 - loss: 1.0335 - val_accuracy: 0.5975 - val_loss: 1.4667\n",
            "Epoch 118/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6709 - loss: 1.0326 - val_accuracy: 0.5926 - val_loss: 1.4824\n",
            "Epoch 119/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6411 - loss: 1.0452 - val_accuracy: 0.6025 - val_loss: 1.4750\n",
            "Epoch 120/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6399 - loss: 1.0763 - val_accuracy: 0.5901 - val_loss: 1.4628\n",
            "Epoch 121/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6357 - loss: 1.0977 - val_accuracy: 0.5877 - val_loss: 1.5005\n",
            "Epoch 122/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: 1.1037 - val_accuracy: 0.5852 - val_loss: 1.4604\n",
            "Epoch 123/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6432 - loss: 1.0459 - val_accuracy: 0.5901 - val_loss: 1.4571\n",
            "Epoch 124/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6504 - loss: 1.0050 - val_accuracy: 0.5679 - val_loss: 1.4937\n",
            "Epoch 125/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6389 - loss: 1.0642 - val_accuracy: 0.5852 - val_loss: 1.4619\n",
            "Epoch 126/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6740 - loss: 1.0089 - val_accuracy: 0.5975 - val_loss: 1.4513\n",
            "Epoch 127/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6648 - loss: 1.0384 - val_accuracy: 0.6000 - val_loss: 1.4545\n",
            "Epoch 128/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 1.0090 - val_accuracy: 0.6025 - val_loss: 1.4666\n",
            "Epoch 129/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6510 - loss: 1.0370 - val_accuracy: 0.6025 - val_loss: 1.4520\n",
            "Epoch 130/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6564 - loss: 1.0227 - val_accuracy: 0.5901 - val_loss: 1.4532\n",
            "Epoch 131/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6491 - loss: 1.0441 - val_accuracy: 0.5975 - val_loss: 1.4461\n",
            "Epoch 132/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6559 - loss: 1.0186 - val_accuracy: 0.5877 - val_loss: 1.4650\n",
            "Epoch 133/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6643 - loss: 1.0162 - val_accuracy: 0.6000 - val_loss: 1.4792\n",
            "Epoch 134/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6726 - loss: 1.0426 - val_accuracy: 0.5975 - val_loss: 1.4699\n",
            "Epoch 135/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6772 - loss: 0.9582 - val_accuracy: 0.6074 - val_loss: 1.4575\n",
            "Epoch 136/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6566 - loss: 1.0222 - val_accuracy: 0.5827 - val_loss: 1.4812\n",
            "Epoch 137/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6680 - loss: 0.9929 - val_accuracy: 0.6025 - val_loss: 1.4581\n",
            "Epoch 138/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6406 - loss: 1.0213 - val_accuracy: 0.5877 - val_loss: 1.4878\n",
            "Epoch 139/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6412 - loss: 1.0477 - val_accuracy: 0.5852 - val_loss: 1.4836\n",
            "Epoch 140/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 1.0366 - val_accuracy: 0.5951 - val_loss: 1.4781\n",
            "Epoch 141/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6602 - loss: 1.0099 - val_accuracy: 0.6049 - val_loss: 1.4893\n",
            "Epoch 142/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6671 - loss: 0.9729 - val_accuracy: 0.6000 - val_loss: 1.4980\n",
            "Epoch 143/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6724 - loss: 0.9869 - val_accuracy: 0.6000 - val_loss: 1.4963\n",
            "Epoch 144/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6670 - loss: 0.9963 - val_accuracy: 0.6099 - val_loss: 1.4902\n",
            "Epoch 145/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6605 - loss: 1.0084 - val_accuracy: 0.5877 - val_loss: 1.4938\n",
            "Epoch 146/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6528 - loss: 0.9982 - val_accuracy: 0.5704 - val_loss: 1.5136\n",
            "Epoch 147/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6824 - loss: 0.9295 - val_accuracy: 0.5901 - val_loss: 1.4986\n",
            "Epoch 148/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 0.9598 - val_accuracy: 0.6049 - val_loss: 1.4889\n",
            "Epoch 149/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7031 - loss: 0.9555 - val_accuracy: 0.5778 - val_loss: 1.4850\n",
            "Epoch 150/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6413 - loss: 1.0577 - val_accuracy: 0.6049 - val_loss: 1.4494\n",
            "Epoch 151/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6734 - loss: 1.0169 - val_accuracy: 0.6099 - val_loss: 1.4633\n",
            "Epoch 152/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6661 - loss: 0.9930 - val_accuracy: 0.6025 - val_loss: 1.4874\n",
            "Epoch 153/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6723 - loss: 0.9706 - val_accuracy: 0.5951 - val_loss: 1.4906\n",
            "Epoch 154/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6690 - loss: 1.0274 - val_accuracy: 0.6049 - val_loss: 1.4936\n",
            "Epoch 155/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.9707 - val_accuracy: 0.5975 - val_loss: 1.4782\n",
            "Epoch 156/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 0.8792 - val_accuracy: 0.6025 - val_loss: 1.4787\n",
            "Epoch 157/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6693 - loss: 0.9214 - val_accuracy: 0.6049 - val_loss: 1.4890\n",
            "Epoch 158/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6701 - loss: 1.0060 - val_accuracy: 0.6099 - val_loss: 1.4837\n",
            "Epoch 159/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 0.9795 - val_accuracy: 0.6173 - val_loss: 1.4808\n",
            "Epoch 160/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6534 - loss: 1.0239 - val_accuracy: 0.6025 - val_loss: 1.4977\n",
            "Epoch 161/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6795 - loss: 0.9322 - val_accuracy: 0.6025 - val_loss: 1.4791\n",
            "Epoch 162/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.9751 - val_accuracy: 0.5901 - val_loss: 1.4864\n",
            "Epoch 163/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6923 - loss: 0.8985 - val_accuracy: 0.6099 - val_loss: 1.4781\n",
            "Epoch 164/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6986 - loss: 0.9064 - val_accuracy: 0.5802 - val_loss: 1.4923\n",
            "Epoch 165/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.9337 - val_accuracy: 0.5901 - val_loss: 1.4933\n",
            "Epoch 166/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6925 - loss: 0.8588 - val_accuracy: 0.5926 - val_loss: 1.5030\n",
            "Epoch 167/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6663 - loss: 0.9647 - val_accuracy: 0.5926 - val_loss: 1.5117\n",
            "Epoch 168/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6732 - loss: 0.9283 - val_accuracy: 0.5802 - val_loss: 1.5028\n",
            "Epoch 169/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.8863 - val_accuracy: 0.5901 - val_loss: 1.5016\n",
            "Epoch 170/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6701 - loss: 0.9314 - val_accuracy: 0.5926 - val_loss: 1.4786\n",
            "Epoch 171/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.8848 - val_accuracy: 0.6074 - val_loss: 1.4832\n",
            "Epoch 172/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.8796 - val_accuracy: 0.5975 - val_loss: 1.4951\n",
            "Epoch 173/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6812 - loss: 0.8937 - val_accuracy: 0.5951 - val_loss: 1.5315\n",
            "Epoch 174/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.8910 - val_accuracy: 0.5951 - val_loss: 1.5209\n",
            "Epoch 175/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7045 - loss: 0.9045 - val_accuracy: 0.6025 - val_loss: 1.5097\n",
            "Epoch 176/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 0.9546 - val_accuracy: 0.5802 - val_loss: 1.4989\n",
            "Epoch 177/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6837 - loss: 0.9429 - val_accuracy: 0.5877 - val_loss: 1.4984\n",
            "Epoch 178/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7249 - loss: 0.8220 - val_accuracy: 0.5926 - val_loss: 1.5064\n",
            "Epoch 179/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6874 - loss: 0.8967 - val_accuracy: 0.6099 - val_loss: 1.5141\n",
            "Epoch 180/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.8726 - val_accuracy: 0.5951 - val_loss: 1.4983\n",
            "Epoch 181/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6893 - loss: 0.9309 - val_accuracy: 0.5877 - val_loss: 1.5049\n",
            "Epoch 182/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6664 - loss: 0.9515 - val_accuracy: 0.6000 - val_loss: 1.4932\n",
            "Epoch 183/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6853 - loss: 0.9402 - val_accuracy: 0.6049 - val_loss: 1.4857\n",
            "Epoch 184/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8714 - val_accuracy: 0.5852 - val_loss: 1.4875\n",
            "Epoch 185/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8849 - val_accuracy: 0.6074 - val_loss: 1.4799\n",
            "Epoch 186/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.9042 - val_accuracy: 0.5827 - val_loss: 1.5196\n",
            "Epoch 187/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6891 - loss: 0.8914 - val_accuracy: 0.5901 - val_loss: 1.5249\n",
            "Epoch 188/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6917 - loss: 0.8924 - val_accuracy: 0.6049 - val_loss: 1.5158\n",
            "Epoch 189/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.8765 - val_accuracy: 0.5753 - val_loss: 1.5260\n",
            "Epoch 190/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6999 - loss: 0.8581 - val_accuracy: 0.6049 - val_loss: 1.5208\n",
            "Epoch 191/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.8283 - val_accuracy: 0.5877 - val_loss: 1.5301\n",
            "Epoch 192/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.8692 - val_accuracy: 0.6099 - val_loss: 1.5235\n",
            "Epoch 193/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7171 - loss: 0.8373 - val_accuracy: 0.6025 - val_loss: 1.5372\n",
            "Epoch 194/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7057 - loss: 0.8852 - val_accuracy: 0.5926 - val_loss: 1.5221\n",
            "Epoch 195/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6682 - loss: 0.9280 - val_accuracy: 0.6099 - val_loss: 1.5175\n",
            "Epoch 196/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6847 - loss: 0.9206 - val_accuracy: 0.6025 - val_loss: 1.5280\n",
            "Epoch 197/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7082 - loss: 0.8706 - val_accuracy: 0.5901 - val_loss: 1.5322\n",
            "Epoch 198/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.8897 - val_accuracy: 0.6025 - val_loss: 1.5178\n",
            "Epoch 199/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7158 - loss: 0.8525 - val_accuracy: 0.5975 - val_loss: 1.5186\n",
            "Epoch 200/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6991 - loss: 0.8664 - val_accuracy: 0.5778 - val_loss: 1.5201\n",
            "Epoch 201/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7015 - loss: 0.8550 - val_accuracy: 0.6025 - val_loss: 1.5437\n",
            "Epoch 202/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.8088 - val_accuracy: 0.5852 - val_loss: 1.5552\n",
            "Epoch 203/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6996 - loss: 0.8548 - val_accuracy: 0.5753 - val_loss: 1.5389\n",
            "Epoch 204/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7056 - loss: 0.8586 - val_accuracy: 0.5975 - val_loss: 1.5352\n",
            "Epoch 205/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7103 - loss: 0.8436 - val_accuracy: 0.6000 - val_loss: 1.5176\n",
            "Epoch 206/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7011 - loss: 0.8543 - val_accuracy: 0.5901 - val_loss: 1.5392\n",
            "Epoch 207/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7022 - loss: 0.8774 - val_accuracy: 0.5951 - val_loss: 1.5490\n",
            "Epoch 208/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.8292 - val_accuracy: 0.5802 - val_loss: 1.5406\n",
            "Epoch 209/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.8742 - val_accuracy: 0.6074 - val_loss: 1.5328\n",
            "Epoch 210/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.7636 - val_accuracy: 0.6198 - val_loss: 1.5412\n",
            "Epoch 211/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.8577 - val_accuracy: 0.5877 - val_loss: 1.5357\n",
            "Epoch 212/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.9008 - val_accuracy: 0.6099 - val_loss: 1.5072\n",
            "Epoch 213/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.8188 - val_accuracy: 0.6247 - val_loss: 1.5186\n",
            "Epoch 214/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.9034 - val_accuracy: 0.5901 - val_loss: 1.5418\n",
            "Epoch 215/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.8176 - val_accuracy: 0.6099 - val_loss: 1.5243\n",
            "Epoch 216/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 0.9119 - val_accuracy: 0.6025 - val_loss: 1.5209\n",
            "Epoch 217/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7068 - loss: 0.8651 - val_accuracy: 0.6025 - val_loss: 1.5377\n",
            "Epoch 218/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6977 - loss: 0.8612 - val_accuracy: 0.5827 - val_loss: 1.5638\n",
            "Epoch 219/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7121 - loss: 0.8395 - val_accuracy: 0.5951 - val_loss: 1.5508\n",
            "Epoch 220/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.8232 - val_accuracy: 0.5877 - val_loss: 1.5525\n",
            "Epoch 221/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.8155 - val_accuracy: 0.5827 - val_loss: 1.5445\n",
            "Epoch 222/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.7825 - val_accuracy: 0.6000 - val_loss: 1.5449\n",
            "Epoch 223/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7046 - loss: 0.8559 - val_accuracy: 0.5877 - val_loss: 1.5456\n",
            "Epoch 224/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7199 - loss: 0.8494 - val_accuracy: 0.6049 - val_loss: 1.5350\n",
            "Epoch 225/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 0.7974 - val_accuracy: 0.6025 - val_loss: 1.5529\n",
            "Epoch 226/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6933 - loss: 0.8605 - val_accuracy: 0.5802 - val_loss: 1.5637\n",
            "Epoch 227/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7115 - loss: 0.8260 - val_accuracy: 0.5852 - val_loss: 1.5678\n",
            "Epoch 228/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7057 - loss: 0.8567 - val_accuracy: 0.5901 - val_loss: 1.5581\n",
            "Epoch 229/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7178 - loss: 0.8494 - val_accuracy: 0.5926 - val_loss: 1.5283\n",
            "Epoch 230/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.8132 - val_accuracy: 0.5901 - val_loss: 1.5613\n",
            "Epoch 231/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7184 - loss: 0.7979 - val_accuracy: 0.6025 - val_loss: 1.5645\n",
            "Epoch 232/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.8419 - val_accuracy: 0.6148 - val_loss: 1.5778\n",
            "Epoch 233/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.7950 - val_accuracy: 0.6025 - val_loss: 1.5822\n",
            "Epoch 234/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7198 - loss: 0.8372 - val_accuracy: 0.6099 - val_loss: 1.5719\n",
            "Epoch 235/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7155 - loss: 0.8043 - val_accuracy: 0.6247 - val_loss: 1.5632\n",
            "Epoch 236/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7192 - loss: 0.8277 - val_accuracy: 0.6148 - val_loss: 1.5439\n",
            "Epoch 237/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.7925 - val_accuracy: 0.6247 - val_loss: 1.5658\n",
            "Epoch 238/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7187 - loss: 0.8443 - val_accuracy: 0.6000 - val_loss: 1.5630\n",
            "Epoch 239/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.7998 - val_accuracy: 0.6198 - val_loss: 1.5750\n",
            "Epoch 240/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7191 - loss: 0.8170 - val_accuracy: 0.6173 - val_loss: 1.5655\n",
            "Epoch 241/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.7689 - val_accuracy: 0.6296 - val_loss: 1.5717\n",
            "Epoch 242/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.8279 - val_accuracy: 0.6049 - val_loss: 1.5616\n",
            "Epoch 243/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.7889 - val_accuracy: 0.5802 - val_loss: 1.5667\n",
            "Epoch 244/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7201 - loss: 0.8379 - val_accuracy: 0.5852 - val_loss: 1.5507\n",
            "Epoch 245/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.7670 - val_accuracy: 0.5877 - val_loss: 1.5643\n",
            "Epoch 246/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.7947 - val_accuracy: 0.6099 - val_loss: 1.5685\n",
            "Epoch 247/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.8079 - val_accuracy: 0.6049 - val_loss: 1.5710\n",
            "Epoch 248/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.7893 - val_accuracy: 0.5951 - val_loss: 1.5810\n",
            "Epoch 249/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.8051 - val_accuracy: 0.6173 - val_loss: 1.5549\n",
            "Epoch 250/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7178 - loss: 0.8065 - val_accuracy: 0.6148 - val_loss: 1.5836\n",
            "Epoch 251/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.8042 - val_accuracy: 0.5926 - val_loss: 1.5845\n",
            "Epoch 252/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7034 - loss: 0.8199 - val_accuracy: 0.6222 - val_loss: 1.5651\n",
            "Epoch 253/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7239 - loss: 0.7734 - val_accuracy: 0.6148 - val_loss: 1.5725\n",
            "Epoch 254/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.7808 - val_accuracy: 0.6074 - val_loss: 1.6035\n",
            "Epoch 255/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.7846 - val_accuracy: 0.6272 - val_loss: 1.5632\n",
            "Epoch 256/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.7857 - val_accuracy: 0.6148 - val_loss: 1.5714\n",
            "Epoch 257/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.7761 - val_accuracy: 0.6148 - val_loss: 1.6026\n",
            "Epoch 258/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.7677 - val_accuracy: 0.5975 - val_loss: 1.6049\n",
            "Epoch 259/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.7961 - val_accuracy: 0.6025 - val_loss: 1.5938\n",
            "Epoch 260/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.8016 - val_accuracy: 0.6148 - val_loss: 1.5752\n",
            "Epoch 261/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.7954 - val_accuracy: 0.6173 - val_loss: 1.5717\n",
            "Epoch 262/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.7867 - val_accuracy: 0.6148 - val_loss: 1.5819\n",
            "Epoch 263/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.8211 - val_accuracy: 0.6148 - val_loss: 1.5855\n",
            "Epoch 264/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.7592 - val_accuracy: 0.6123 - val_loss: 1.5777\n",
            "Epoch 265/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.7994 - val_accuracy: 0.6173 - val_loss: 1.5780\n",
            "Epoch 266/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.7687 - val_accuracy: 0.6099 - val_loss: 1.6066\n",
            "Epoch 267/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.7777 - val_accuracy: 0.6049 - val_loss: 1.6013\n",
            "Epoch 268/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.7853 - val_accuracy: 0.6198 - val_loss: 1.5774\n",
            "Epoch 269/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7089 - loss: 0.7888 - val_accuracy: 0.6148 - val_loss: 1.5971\n",
            "Epoch 270/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.7862 - val_accuracy: 0.6099 - val_loss: 1.5953\n",
            "Epoch 271/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.7384 - val_accuracy: 0.6099 - val_loss: 1.5770\n",
            "Epoch 272/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.7220 - val_accuracy: 0.6099 - val_loss: 1.5786\n",
            "Epoch 273/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.7846 - val_accuracy: 0.6000 - val_loss: 1.5661\n",
            "Epoch 274/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.7543 - val_accuracy: 0.6173 - val_loss: 1.5802\n",
            "Epoch 275/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.7501 - val_accuracy: 0.5926 - val_loss: 1.6117\n",
            "Epoch 276/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.7560 - val_accuracy: 0.5926 - val_loss: 1.6098\n",
            "Epoch 277/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7514 - loss: 0.7259 - val_accuracy: 0.5901 - val_loss: 1.5873\n",
            "Epoch 278/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7515 - val_accuracy: 0.6123 - val_loss: 1.6217\n",
            "Epoch 279/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.7658 - val_accuracy: 0.6123 - val_loss: 1.5993\n",
            "Epoch 280/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7492 - loss: 0.7614 - val_accuracy: 0.6074 - val_loss: 1.6198\n",
            "Epoch 281/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.7967 - val_accuracy: 0.6148 - val_loss: 1.5763\n",
            "Epoch 282/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7389 - loss: 0.7528 - val_accuracy: 0.6123 - val_loss: 1.5669\n",
            "Epoch 283/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.7929 - val_accuracy: 0.5901 - val_loss: 1.6238\n",
            "Epoch 284/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7325 - loss: 0.7723 - val_accuracy: 0.5951 - val_loss: 1.6312\n",
            "Epoch 285/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7441 - loss: 0.7397 - val_accuracy: 0.6099 - val_loss: 1.6194\n",
            "Epoch 286/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7628 - loss: 0.6915 - val_accuracy: 0.6222 - val_loss: 1.6039\n",
            "Epoch 287/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7401 - loss: 0.7936 - val_accuracy: 0.6123 - val_loss: 1.6069\n",
            "Epoch 288/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 0.7297 - val_accuracy: 0.6049 - val_loss: 1.5791\n",
            "Epoch 289/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7543 - loss: 0.7607 - val_accuracy: 0.6099 - val_loss: 1.5778\n",
            "Epoch 290/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7445 - loss: 0.7322 - val_accuracy: 0.6099 - val_loss: 1.5934\n",
            "Epoch 291/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.7506 - val_accuracy: 0.6049 - val_loss: 1.6278\n",
            "Epoch 292/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7415 - loss: 0.7708 - val_accuracy: 0.6000 - val_loss: 1.6205\n",
            "Epoch 293/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.7300 - val_accuracy: 0.6049 - val_loss: 1.6087\n",
            "Epoch 294/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.7493 - val_accuracy: 0.5926 - val_loss: 1.6102\n",
            "Epoch 295/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7415 - loss: 0.7195 - val_accuracy: 0.6173 - val_loss: 1.5864\n",
            "Epoch 296/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.8278 - val_accuracy: 0.5975 - val_loss: 1.6119\n",
            "Epoch 297/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7540 - loss: 0.7171 - val_accuracy: 0.6296 - val_loss: 1.5892\n",
            "Epoch 298/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.7632 - val_accuracy: 0.6148 - val_loss: 1.6138\n",
            "Epoch 299/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.7275 - val_accuracy: 0.6123 - val_loss: 1.6039\n",
            "Epoch 300/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.6932 - val_accuracy: 0.6222 - val_loss: 1.6228\n",
            "Epoch 301/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7277 - loss: 0.7470 - val_accuracy: 0.6099 - val_loss: 1.6056\n",
            "Epoch 302/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7062 - loss: 0.7936 - val_accuracy: 0.6272 - val_loss: 1.6282\n",
            "Epoch 303/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7477 - loss: 0.7248 - val_accuracy: 0.6272 - val_loss: 1.6315\n",
            "Epoch 304/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.7623 - val_accuracy: 0.6272 - val_loss: 1.6328\n",
            "Epoch 305/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.6663 - val_accuracy: 0.6272 - val_loss: 1.6398\n",
            "Epoch 306/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.7495 - val_accuracy: 0.6049 - val_loss: 1.6649\n",
            "Epoch 307/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.6849 - val_accuracy: 0.6173 - val_loss: 1.6531\n",
            "Epoch 308/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6922 - val_accuracy: 0.6123 - val_loss: 1.6651\n",
            "Epoch 309/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.6691 - val_accuracy: 0.6272 - val_loss: 1.6325\n",
            "Epoch 310/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.7264 - val_accuracy: 0.6049 - val_loss: 1.6363\n",
            "Epoch 311/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.7624 - val_accuracy: 0.6321 - val_loss: 1.6323\n",
            "Epoch 312/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.7307 - val_accuracy: 0.6247 - val_loss: 1.6389\n",
            "Epoch 313/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7564 - loss: 0.7299 - val_accuracy: 0.6247 - val_loss: 1.6343\n",
            "Epoch 314/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.6999 - val_accuracy: 0.6173 - val_loss: 1.6202\n",
            "Epoch 315/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7472 - loss: 0.7532 - val_accuracy: 0.6198 - val_loss: 1.6259\n",
            "Epoch 316/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7580 - loss: 0.6978 - val_accuracy: 0.6099 - val_loss: 1.6344\n",
            "Epoch 317/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 0.6851 - val_accuracy: 0.6074 - val_loss: 1.6617\n",
            "Epoch 318/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.7517 - val_accuracy: 0.5877 - val_loss: 1.6769\n",
            "Epoch 319/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7653 - loss: 0.6776 - val_accuracy: 0.6000 - val_loss: 1.6713\n",
            "Epoch 320/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.6741 - val_accuracy: 0.5926 - val_loss: 1.6608\n",
            "Epoch 321/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7604 - loss: 0.7276 - val_accuracy: 0.5951 - val_loss: 1.6513\n",
            "Epoch 322/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.7697 - val_accuracy: 0.6025 - val_loss: 1.6452\n",
            "Epoch 323/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7628 - loss: 0.7252 - val_accuracy: 0.6049 - val_loss: 1.6409\n",
            "Epoch 324/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.6913 - val_accuracy: 0.6000 - val_loss: 1.6481\n",
            "Epoch 325/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7754 - loss: 0.6542 - val_accuracy: 0.5951 - val_loss: 1.6500\n",
            "Epoch 326/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.6790 - val_accuracy: 0.6173 - val_loss: 1.6357\n",
            "Epoch 327/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7334 - loss: 0.7494 - val_accuracy: 0.6049 - val_loss: 1.6530\n",
            "Epoch 328/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.7674 - val_accuracy: 0.6049 - val_loss: 1.6392\n",
            "Epoch 329/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7464 - loss: 0.7470 - val_accuracy: 0.6148 - val_loss: 1.6702\n",
            "Epoch 330/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7695 - loss: 0.6992 - val_accuracy: 0.6222 - val_loss: 1.6669\n",
            "Epoch 331/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7707 - loss: 0.6584 - val_accuracy: 0.6049 - val_loss: 1.7050\n",
            "Epoch 332/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.6324 - val_accuracy: 0.6099 - val_loss: 1.6792\n",
            "Epoch 333/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7448 - loss: 0.8084 - val_accuracy: 0.6198 - val_loss: 1.6696\n",
            "Epoch 334/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.7353 - val_accuracy: 0.6148 - val_loss: 1.6952\n",
            "Epoch 335/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.7218 - val_accuracy: 0.6173 - val_loss: 1.7195\n",
            "Epoch 336/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7673 - loss: 0.6915 - val_accuracy: 0.6049 - val_loss: 1.7091\n",
            "Epoch 337/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7544 - loss: 0.7002 - val_accuracy: 0.6123 - val_loss: 1.7093\n",
            "Epoch 338/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7618 - loss: 0.6913 - val_accuracy: 0.6198 - val_loss: 1.7080\n",
            "Epoch 339/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.6367 - val_accuracy: 0.6123 - val_loss: 1.7104\n",
            "Epoch 340/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.7133 - val_accuracy: 0.5975 - val_loss: 1.7004\n",
            "Epoch 341/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.7024 - val_accuracy: 0.6099 - val_loss: 1.6905\n",
            "Epoch 342/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.6734 - val_accuracy: 0.6321 - val_loss: 1.6654\n",
            "Epoch 343/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.6823 - val_accuracy: 0.6272 - val_loss: 1.6921\n",
            "Epoch 344/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.6701 - val_accuracy: 0.6222 - val_loss: 1.7001\n",
            "Epoch 345/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.7186 - val_accuracy: 0.6222 - val_loss: 1.6971\n",
            "Epoch 346/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7456 - loss: 0.7520 - val_accuracy: 0.6148 - val_loss: 1.7036\n",
            "Epoch 347/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6980 - val_accuracy: 0.6049 - val_loss: 1.7118\n",
            "Epoch 348/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7246 - loss: 0.7567 - val_accuracy: 0.6099 - val_loss: 1.7005\n",
            "Epoch 349/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.6590 - val_accuracy: 0.6198 - val_loss: 1.7139\n",
            "Epoch 350/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7701 - loss: 0.6899 - val_accuracy: 0.6173 - val_loss: 1.6942\n",
            "Epoch 351/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.6886 - val_accuracy: 0.6099 - val_loss: 1.7270\n",
            "Epoch 352/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7534 - loss: 0.6959 - val_accuracy: 0.6099 - val_loss: 1.7070\n",
            "Epoch 353/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.7075 - val_accuracy: 0.6074 - val_loss: 1.7007\n",
            "Epoch 354/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.6680 - val_accuracy: 0.6148 - val_loss: 1.6994\n",
            "Epoch 355/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.6882 - val_accuracy: 0.6099 - val_loss: 1.7003\n",
            "Epoch 356/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.6731 - val_accuracy: 0.6173 - val_loss: 1.7028\n",
            "Epoch 357/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.6491 - val_accuracy: 0.6074 - val_loss: 1.7126\n",
            "Epoch 358/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 0.6957 - val_accuracy: 0.6074 - val_loss: 1.7078\n",
            "Epoch 359/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.6913 - val_accuracy: 0.6099 - val_loss: 1.7251\n",
            "Epoch 360/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.7521 - val_accuracy: 0.6173 - val_loss: 1.7351\n",
            "Epoch 361/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7587 - loss: 0.6918 - val_accuracy: 0.5975 - val_loss: 1.7209\n",
            "Epoch 362/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7601 - loss: 0.6885 - val_accuracy: 0.6198 - val_loss: 1.6989\n",
            "Epoch 363/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7601 - loss: 0.6916 - val_accuracy: 0.6222 - val_loss: 1.7106\n",
            "Epoch 364/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.6910 - val_accuracy: 0.6074 - val_loss: 1.6877\n",
            "Epoch 365/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7657 - loss: 0.6866 - val_accuracy: 0.6247 - val_loss: 1.6739\n",
            "Epoch 366/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7536 - loss: 0.6381 - val_accuracy: 0.6198 - val_loss: 1.6963\n",
            "Epoch 367/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.6695 - val_accuracy: 0.5975 - val_loss: 1.6751\n",
            "Epoch 368/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7690 - loss: 0.6923 - val_accuracy: 0.6148 - val_loss: 1.6917\n",
            "Epoch 369/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.6672 - val_accuracy: 0.6123 - val_loss: 1.7033\n",
            "Epoch 370/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.6543 - val_accuracy: 0.6025 - val_loss: 1.7342\n",
            "Epoch 371/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.6994 - val_accuracy: 0.6222 - val_loss: 1.7418\n",
            "Epoch 372/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7521 - loss: 0.7214 - val_accuracy: 0.6123 - val_loss: 1.6844\n",
            "Epoch 373/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7785 - loss: 0.7234 - val_accuracy: 0.6025 - val_loss: 1.7011\n",
            "Epoch 374/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.6314 - val_accuracy: 0.6198 - val_loss: 1.6734\n",
            "Epoch 375/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7737 - loss: 0.6335 - val_accuracy: 0.6321 - val_loss: 1.6833\n",
            "Epoch 376/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.6869 - val_accuracy: 0.6074 - val_loss: 1.6793\n",
            "Epoch 377/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7606 - loss: 0.6813 - val_accuracy: 0.6222 - val_loss: 1.6977\n",
            "Epoch 378/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.6990 - val_accuracy: 0.6099 - val_loss: 1.7100\n",
            "Epoch 379/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7547 - loss: 0.7326 - val_accuracy: 0.6198 - val_loss: 1.6814\n",
            "Epoch 380/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.6606 - val_accuracy: 0.6074 - val_loss: 1.6865\n",
            "Epoch 381/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.6960 - val_accuracy: 0.6222 - val_loss: 1.6646\n",
            "Epoch 382/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7805 - loss: 0.6312 - val_accuracy: 0.6296 - val_loss: 1.6787\n",
            "Epoch 383/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.7168 - val_accuracy: 0.6247 - val_loss: 1.6840\n",
            "Epoch 384/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.7333 - val_accuracy: 0.6074 - val_loss: 1.6912\n",
            "Epoch 385/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.6530 - val_accuracy: 0.5951 - val_loss: 1.6804\n",
            "Epoch 386/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.7340 - val_accuracy: 0.5901 - val_loss: 1.7468\n",
            "Epoch 387/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.7038 - val_accuracy: 0.5901 - val_loss: 1.7125\n",
            "Epoch 388/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7541 - loss: 0.7016 - val_accuracy: 0.6123 - val_loss: 1.6931\n",
            "Epoch 389/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7639 - loss: 0.6746 - val_accuracy: 0.6198 - val_loss: 1.6714\n",
            "Epoch 390/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.7337 - val_accuracy: 0.5975 - val_loss: 1.6949\n",
            "Epoch 391/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.7282 - val_accuracy: 0.5901 - val_loss: 1.6917\n",
            "Epoch 392/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.6018 - val_accuracy: 0.6099 - val_loss: 1.6858\n",
            "Epoch 393/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.6343 - val_accuracy: 0.6148 - val_loss: 1.6969\n",
            "Epoch 394/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.6232 - val_accuracy: 0.6025 - val_loss: 1.6889\n",
            "Epoch 395/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7842 - loss: 0.6196 - val_accuracy: 0.6148 - val_loss: 1.6805\n",
            "Epoch 396/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.6172 - val_accuracy: 0.6000 - val_loss: 1.6943\n",
            "Epoch 397/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.6532 - val_accuracy: 0.6148 - val_loss: 1.7033\n",
            "Epoch 398/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.6957 - val_accuracy: 0.6049 - val_loss: 1.7157\n",
            "Epoch 399/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.6751 - val_accuracy: 0.6198 - val_loss: 1.6957\n",
            "Epoch 400/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7592 - loss: 0.6835 - val_accuracy: 0.6000 - val_loss: 1.7191\n",
            "Epoch 401/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7800 - loss: 0.6556 - val_accuracy: 0.6049 - val_loss: 1.7017\n",
            "Epoch 402/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7713 - loss: 0.6864 - val_accuracy: 0.6049 - val_loss: 1.7156\n",
            "Epoch 403/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7651 - loss: 0.6748 - val_accuracy: 0.5926 - val_loss: 1.7269\n",
            "Epoch 404/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.7409 - val_accuracy: 0.6074 - val_loss: 1.7152\n",
            "Epoch 405/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7652 - loss: 0.6286 - val_accuracy: 0.6074 - val_loss: 1.7214\n",
            "Epoch 406/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7748 - loss: 0.6436 - val_accuracy: 0.6025 - val_loss: 1.7258\n",
            "Epoch 407/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.6848 - val_accuracy: 0.6025 - val_loss: 1.7332\n",
            "Epoch 408/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7509 - loss: 0.6616 - val_accuracy: 0.5926 - val_loss: 1.7315\n",
            "Epoch 409/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7550 - loss: 0.7195 - val_accuracy: 0.6222 - val_loss: 1.7303\n",
            "Epoch 410/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7556 - loss: 0.7071 - val_accuracy: 0.6025 - val_loss: 1.7045\n",
            "Epoch 411/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7602 - loss: 0.6979 - val_accuracy: 0.6049 - val_loss: 1.7053\n",
            "Epoch 412/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.7063 - val_accuracy: 0.6296 - val_loss: 1.7051\n",
            "Epoch 413/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.6564 - val_accuracy: 0.5975 - val_loss: 1.7235\n",
            "Epoch 414/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 0.6407 - val_accuracy: 0.6173 - val_loss: 1.7352\n",
            "Epoch 415/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 0.6324 - val_accuracy: 0.6074 - val_loss: 1.7306\n",
            "Epoch 416/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.6866 - val_accuracy: 0.6198 - val_loss: 1.7438\n",
            "Epoch 417/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.6629 - val_accuracy: 0.6049 - val_loss: 1.7493\n",
            "Epoch 418/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.6188 - val_accuracy: 0.6123 - val_loss: 1.7507\n",
            "Epoch 419/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6771 - val_accuracy: 0.6247 - val_loss: 1.7395\n",
            "Epoch 420/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 0.6506 - val_accuracy: 0.6370 - val_loss: 1.7280\n",
            "Epoch 421/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.6888 - val_accuracy: 0.6123 - val_loss: 1.7375\n",
            "Epoch 422/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.6937 - val_accuracy: 0.6173 - val_loss: 1.7411\n",
            "Epoch 423/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.6212 - val_accuracy: 0.6222 - val_loss: 1.7437\n",
            "Epoch 424/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.6269 - val_accuracy: 0.6346 - val_loss: 1.7317\n",
            "Epoch 425/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.6997 - val_accuracy: 0.5926 - val_loss: 1.7708\n",
            "Epoch 426/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7624 - loss: 0.6887 - val_accuracy: 0.6099 - val_loss: 1.7536\n",
            "Epoch 427/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7601 - loss: 0.7046 - val_accuracy: 0.5901 - val_loss: 1.7832\n",
            "Epoch 428/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.6394 - val_accuracy: 0.5951 - val_loss: 1.7626\n",
            "Epoch 429/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.7161 - val_accuracy: 0.6074 - val_loss: 1.7640\n",
            "Epoch 430/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7614 - loss: 0.6547 - val_accuracy: 0.5975 - val_loss: 1.7350\n",
            "Epoch 431/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7874 - loss: 0.6044 - val_accuracy: 0.6123 - val_loss: 1.7417\n",
            "Epoch 432/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7563 - loss: 0.6909 - val_accuracy: 0.6247 - val_loss: 1.6936\n",
            "Epoch 433/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7900 - loss: 0.6276 - val_accuracy: 0.6198 - val_loss: 1.6947\n",
            "Epoch 434/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7667 - loss: 0.6861 - val_accuracy: 0.6049 - val_loss: 1.7136\n",
            "Epoch 435/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.6380 - val_accuracy: 0.6173 - val_loss: 1.7137\n",
            "Epoch 436/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.6232 - val_accuracy: 0.6000 - val_loss: 1.7432\n",
            "Epoch 437/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.6395 - val_accuracy: 0.6148 - val_loss: 1.7402\n",
            "Epoch 438/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.6464 - val_accuracy: 0.6049 - val_loss: 1.7450\n",
            "Epoch 439/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.6953 - val_accuracy: 0.6025 - val_loss: 1.7322\n",
            "Epoch 440/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.6090 - val_accuracy: 0.6099 - val_loss: 1.7447\n",
            "Epoch 441/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.5923 - val_accuracy: 0.6247 - val_loss: 1.7326\n",
            "Epoch 442/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.6509 - val_accuracy: 0.6148 - val_loss: 1.7434\n",
            "Epoch 443/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.6267 - val_accuracy: 0.5975 - val_loss: 1.7576\n",
            "Epoch 444/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.6879 - val_accuracy: 0.6049 - val_loss: 1.7610\n",
            "Epoch 445/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.6098 - val_accuracy: 0.6123 - val_loss: 1.7726\n",
            "Epoch 446/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.6616 - val_accuracy: 0.6049 - val_loss: 1.7774\n",
            "Epoch 447/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.6273 - val_accuracy: 0.6123 - val_loss: 1.7605\n",
            "Epoch 448/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7836 - loss: 0.5796 - val_accuracy: 0.6049 - val_loss: 1.7922\n",
            "Epoch 449/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.6405 - val_accuracy: 0.6074 - val_loss: 1.7900\n",
            "Epoch 450/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.5983 - val_accuracy: 0.6173 - val_loss: 1.7948\n",
            "Epoch 451/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.6148 - val_accuracy: 0.6198 - val_loss: 1.7898\n",
            "Epoch 452/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7705 - loss: 0.6541 - val_accuracy: 0.6049 - val_loss: 1.7934\n",
            "Epoch 453/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.6414 - val_accuracy: 0.6099 - val_loss: 1.8223\n",
            "Epoch 454/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.5914 - val_accuracy: 0.6247 - val_loss: 1.8177\n",
            "Epoch 455/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.6154 - val_accuracy: 0.6173 - val_loss: 1.8033\n",
            "Epoch 456/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.6414 - val_accuracy: 0.6049 - val_loss: 1.7920\n",
            "Epoch 457/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.6314 - val_accuracy: 0.6025 - val_loss: 1.7867\n",
            "Epoch 458/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.6179 - val_accuracy: 0.6148 - val_loss: 1.7895\n",
            "Epoch 459/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.6294 - val_accuracy: 0.5951 - val_loss: 1.8164\n",
            "Epoch 460/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5918 - val_accuracy: 0.6049 - val_loss: 1.8189\n",
            "Epoch 461/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.6117 - val_accuracy: 0.6123 - val_loss: 1.8164\n",
            "Epoch 462/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.6183 - val_accuracy: 0.6198 - val_loss: 1.7927\n",
            "Epoch 463/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.5970 - val_accuracy: 0.6198 - val_loss: 1.7649\n",
            "Epoch 464/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.5966 - val_accuracy: 0.6123 - val_loss: 1.8023\n",
            "Epoch 465/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7868 - loss: 0.6408 - val_accuracy: 0.6296 - val_loss: 1.7956\n",
            "Epoch 466/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7624 - loss: 0.6274 - val_accuracy: 0.6049 - val_loss: 1.7940\n",
            "Epoch 467/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.6204 - val_accuracy: 0.6049 - val_loss: 1.8232\n",
            "Epoch 468/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7630 - loss: 0.7108 - val_accuracy: 0.6123 - val_loss: 1.8021\n",
            "Epoch 469/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7813 - loss: 0.6680 - val_accuracy: 0.6198 - val_loss: 1.8177\n",
            "Epoch 470/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.6261 - val_accuracy: 0.6025 - val_loss: 1.8353\n",
            "Epoch 471/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.6480 - val_accuracy: 0.6099 - val_loss: 1.8328\n",
            "Epoch 472/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.6430 - val_accuracy: 0.6000 - val_loss: 1.8331\n",
            "Epoch 473/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.6176 - val_accuracy: 0.6123 - val_loss: 1.8317\n",
            "Epoch 474/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.6467 - val_accuracy: 0.6074 - val_loss: 1.8844\n",
            "Epoch 475/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7795 - loss: 0.6549 - val_accuracy: 0.6222 - val_loss: 1.8389\n",
            "Epoch 476/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7771 - loss: 0.6439 - val_accuracy: 0.6370 - val_loss: 1.8123\n",
            "Epoch 477/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.6371 - val_accuracy: 0.6198 - val_loss: 1.8232\n",
            "Epoch 478/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.5630 - val_accuracy: 0.6198 - val_loss: 1.8309\n",
            "Epoch 479/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.6013 - val_accuracy: 0.6222 - val_loss: 1.8326\n",
            "Epoch 480/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5796 - val_accuracy: 0.6123 - val_loss: 1.8426\n",
            "Epoch 481/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.6434 - val_accuracy: 0.6074 - val_loss: 1.8266\n",
            "Epoch 482/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.5886 - val_accuracy: 0.6222 - val_loss: 1.8276\n",
            "Epoch 483/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.6188 - val_accuracy: 0.6173 - val_loss: 1.8395\n",
            "Epoch 484/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.6378 - val_accuracy: 0.6222 - val_loss: 1.8247\n",
            "Epoch 485/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.5781 - val_accuracy: 0.6148 - val_loss: 1.8684\n",
            "Epoch 486/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.6520 - val_accuracy: 0.6074 - val_loss: 1.8668\n",
            "Epoch 487/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.6389 - val_accuracy: 0.6148 - val_loss: 1.8569\n",
            "Epoch 488/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7688 - loss: 0.6343 - val_accuracy: 0.6123 - val_loss: 1.8322\n",
            "Epoch 489/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.6192 - val_accuracy: 0.6272 - val_loss: 1.8080\n",
            "Epoch 490/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.5762 - val_accuracy: 0.6074 - val_loss: 1.8286\n",
            "Epoch 491/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.6377 - val_accuracy: 0.6148 - val_loss: 1.8388\n",
            "Epoch 492/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.6563 - val_accuracy: 0.6074 - val_loss: 1.8495\n",
            "Epoch 493/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7928 - loss: 0.5907 - val_accuracy: 0.6025 - val_loss: 1.8511\n",
            "Epoch 494/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.6195 - val_accuracy: 0.6222 - val_loss: 1.8274\n",
            "Epoch 495/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.6846 - val_accuracy: 0.5827 - val_loss: 1.8343\n",
            "Epoch 496/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7890 - loss: 0.6002 - val_accuracy: 0.6173 - val_loss: 1.8207\n",
            "Epoch 497/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.5641 - val_accuracy: 0.6049 - val_loss: 1.8344\n",
            "Epoch 498/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.6151 - val_accuracy: 0.6049 - val_loss: 1.8450\n",
            "Epoch 499/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5953 - val_accuracy: 0.6222 - val_loss: 1.8514\n",
            "Epoch 500/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8139 - loss: 0.5897 - val_accuracy: 0.6123 - val_loss: 1.8767\n",
            "Epoch 501/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.6168 - val_accuracy: 0.6074 - val_loss: 1.8756\n",
            "Epoch 502/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5891 - val_accuracy: 0.6000 - val_loss: 1.8961\n",
            "Epoch 503/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6519 - val_accuracy: 0.6123 - val_loss: 1.8746\n",
            "Epoch 504/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.5584 - val_accuracy: 0.6222 - val_loss: 1.9052\n",
            "Epoch 505/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.6034 - val_accuracy: 0.6049 - val_loss: 1.9044\n",
            "Epoch 506/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.5882 - val_accuracy: 0.6123 - val_loss: 1.8739\n",
            "Epoch 507/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7596 - loss: 0.6568 - val_accuracy: 0.5951 - val_loss: 1.8665\n",
            "Epoch 508/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 0.6672 - val_accuracy: 0.6296 - val_loss: 1.8264\n",
            "Epoch 509/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.5747 - val_accuracy: 0.6321 - val_loss: 1.8890\n",
            "Epoch 510/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.6252 - val_accuracy: 0.6148 - val_loss: 1.9067\n",
            "Epoch 511/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.6532 - val_accuracy: 0.6074 - val_loss: 1.9151\n",
            "Epoch 512/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.5992 - val_accuracy: 0.6148 - val_loss: 1.8959\n",
            "Epoch 513/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.6119 - val_accuracy: 0.6099 - val_loss: 1.8676\n",
            "Epoch 514/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.6539 - val_accuracy: 0.6247 - val_loss: 1.8638\n",
            "Epoch 515/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.6015 - val_accuracy: 0.6272 - val_loss: 1.8691\n",
            "Epoch 516/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.5910 - val_accuracy: 0.6247 - val_loss: 1.8610\n",
            "Epoch 517/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7697 - loss: 0.6416 - val_accuracy: 0.6198 - val_loss: 1.8319\n",
            "Epoch 518/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.6394 - val_accuracy: 0.6247 - val_loss: 1.8510\n",
            "Epoch 519/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7891 - loss: 0.5924 - val_accuracy: 0.6198 - val_loss: 1.8482\n",
            "Epoch 520/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8027 - loss: 0.5882 - val_accuracy: 0.6198 - val_loss: 1.8920\n",
            "Epoch 521/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7873 - loss: 0.6190 - val_accuracy: 0.6049 - val_loss: 1.9475\n",
            "Epoch 522/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7882 - loss: 0.6191 - val_accuracy: 0.6000 - val_loss: 1.9063\n",
            "Epoch 523/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.5678 - val_accuracy: 0.5877 - val_loss: 1.9270\n",
            "Epoch 524/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7890 - loss: 0.6003 - val_accuracy: 0.6049 - val_loss: 1.8956\n",
            "Epoch 525/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7696 - loss: 0.6184 - val_accuracy: 0.6049 - val_loss: 1.9017\n",
            "Epoch 526/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.5749 - val_accuracy: 0.5951 - val_loss: 1.9438\n",
            "Epoch 527/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7830 - loss: 0.6075 - val_accuracy: 0.5951 - val_loss: 1.9146\n",
            "Epoch 528/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.6567 - val_accuracy: 0.6123 - val_loss: 1.9345\n",
            "Epoch 529/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7681 - loss: 0.6803 - val_accuracy: 0.6025 - val_loss: 1.9301\n",
            "Epoch 530/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.6275 - val_accuracy: 0.6247 - val_loss: 1.8838\n",
            "Epoch 531/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.6230 - val_accuracy: 0.5926 - val_loss: 1.8875\n",
            "Epoch 532/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.5596 - val_accuracy: 0.5975 - val_loss: 1.8665\n",
            "Epoch 533/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.5986 - val_accuracy: 0.6148 - val_loss: 1.8338\n",
            "Epoch 534/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.6824 - val_accuracy: 0.6148 - val_loss: 1.8676\n",
            "Epoch 535/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 0.6938 - val_accuracy: 0.6198 - val_loss: 1.8713\n",
            "Epoch 536/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7745 - loss: 0.6254 - val_accuracy: 0.6222 - val_loss: 1.8661\n",
            "Epoch 537/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7890 - loss: 0.6004 - val_accuracy: 0.6099 - val_loss: 1.8913\n",
            "Epoch 538/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7697 - loss: 0.6835 - val_accuracy: 0.6148 - val_loss: 1.8564\n",
            "Epoch 539/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.6273 - val_accuracy: 0.6222 - val_loss: 1.8912\n",
            "Epoch 540/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.5725 - val_accuracy: 0.6198 - val_loss: 1.8933\n",
            "Epoch 541/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.6354 - val_accuracy: 0.6148 - val_loss: 1.9132\n",
            "Epoch 542/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.5666 - val_accuracy: 0.6099 - val_loss: 1.9094\n",
            "Epoch 543/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.6328 - val_accuracy: 0.6099 - val_loss: 1.8505\n",
            "Epoch 544/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7928 - loss: 0.5914 - val_accuracy: 0.6049 - val_loss: 1.8436\n",
            "Epoch 545/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7885 - loss: 0.5680 - val_accuracy: 0.6123 - val_loss: 1.8545\n",
            "Epoch 546/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.5866 - val_accuracy: 0.6173 - val_loss: 1.8793\n",
            "Epoch 547/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.5937 - val_accuracy: 0.6198 - val_loss: 1.8617\n",
            "Epoch 548/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7939 - loss: 0.5813 - val_accuracy: 0.6123 - val_loss: 1.8840\n",
            "Epoch 549/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5636 - val_accuracy: 0.6247 - val_loss: 1.9077\n",
            "Epoch 550/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5701 - val_accuracy: 0.6173 - val_loss: 1.9090\n",
            "Epoch 551/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.6247 - val_accuracy: 0.6370 - val_loss: 1.8624\n",
            "Epoch 552/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.5883 - val_accuracy: 0.6198 - val_loss: 1.9070\n",
            "Epoch 553/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.5279 - val_accuracy: 0.6074 - val_loss: 1.8865\n",
            "Epoch 554/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.5853 - val_accuracy: 0.6049 - val_loss: 1.8829\n",
            "Epoch 555/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.5806 - val_accuracy: 0.6247 - val_loss: 1.9252\n",
            "Epoch 556/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.6043 - val_accuracy: 0.6173 - val_loss: 1.9206\n",
            "Epoch 557/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.5713 - val_accuracy: 0.6123 - val_loss: 1.9192\n",
            "Epoch 558/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.5999 - val_accuracy: 0.6173 - val_loss: 1.8881\n",
            "Epoch 559/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.6112 - val_accuracy: 0.6123 - val_loss: 1.8914\n",
            "Epoch 560/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.5872 - val_accuracy: 0.6346 - val_loss: 1.8611\n",
            "Epoch 561/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.5998 - val_accuracy: 0.6321 - val_loss: 1.8691\n",
            "Epoch 562/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.6071 - val_accuracy: 0.6222 - val_loss: 1.8469\n",
            "Epoch 563/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.6116 - val_accuracy: 0.6272 - val_loss: 1.8953\n",
            "Epoch 564/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.5897 - val_accuracy: 0.6198 - val_loss: 1.8596\n",
            "Epoch 565/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.5770 - val_accuracy: 0.6123 - val_loss: 1.8687\n",
            "Epoch 566/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7766 - loss: 0.6720 - val_accuracy: 0.6123 - val_loss: 1.8713\n",
            "Epoch 567/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.5611 - val_accuracy: 0.6173 - val_loss: 1.8589\n",
            "Epoch 568/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.6482 - val_accuracy: 0.6123 - val_loss: 1.8802\n",
            "Epoch 569/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 0.6395 - val_accuracy: 0.6173 - val_loss: 1.8591\n",
            "Epoch 570/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.6535 - val_accuracy: 0.6049 - val_loss: 1.8827\n",
            "Epoch 571/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.6190 - val_accuracy: 0.6173 - val_loss: 1.9198\n",
            "Epoch 572/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8222 - loss: 0.5613 - val_accuracy: 0.6099 - val_loss: 1.9054\n",
            "Epoch 573/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.5651 - val_accuracy: 0.6173 - val_loss: 1.9461\n",
            "Epoch 574/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.5657 - val_accuracy: 0.6272 - val_loss: 1.8601\n",
            "Epoch 575/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.5461 - val_accuracy: 0.6148 - val_loss: 1.8831\n",
            "Epoch 576/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7808 - loss: 0.6311 - val_accuracy: 0.6198 - val_loss: 1.8476\n",
            "Epoch 577/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.6143 - val_accuracy: 0.6123 - val_loss: 1.8682\n",
            "Epoch 578/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.5472 - val_accuracy: 0.6148 - val_loss: 1.8897\n",
            "Epoch 579/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.5431 - val_accuracy: 0.6074 - val_loss: 1.8984\n",
            "Epoch 580/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.5902 - val_accuracy: 0.6074 - val_loss: 1.9026\n",
            "Epoch 581/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.5972 - val_accuracy: 0.6247 - val_loss: 1.8698\n",
            "Epoch 582/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.5762 - val_accuracy: 0.6123 - val_loss: 1.8824\n",
            "Epoch 583/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7863 - loss: 0.6083 - val_accuracy: 0.6074 - val_loss: 1.8843\n",
            "Epoch 584/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7868 - loss: 0.6445 - val_accuracy: 0.6346 - val_loss: 1.8896\n",
            "Epoch 585/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.5722 - val_accuracy: 0.6272 - val_loss: 1.9048\n",
            "Epoch 586/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.5896 - val_accuracy: 0.6148 - val_loss: 1.9395\n",
            "Epoch 587/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.5941 - val_accuracy: 0.6247 - val_loss: 1.9274\n",
            "Epoch 588/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7988 - loss: 0.6145 - val_accuracy: 0.6148 - val_loss: 1.9157\n",
            "Epoch 589/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.6184 - val_accuracy: 0.6247 - val_loss: 1.9395\n",
            "Epoch 590/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7890 - loss: 0.5780 - val_accuracy: 0.6074 - val_loss: 1.9375\n",
            "Epoch 591/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.5393 - val_accuracy: 0.6074 - val_loss: 1.9230\n",
            "Epoch 592/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.5528 - val_accuracy: 0.6123 - val_loss: 1.9259\n",
            "Epoch 593/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.6098 - val_accuracy: 0.6099 - val_loss: 1.9334\n",
            "Epoch 594/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.6083 - val_accuracy: 0.6099 - val_loss: 1.9046\n",
            "Epoch 595/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.5895 - val_accuracy: 0.6099 - val_loss: 1.8964\n",
            "Epoch 596/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8014 - loss: 0.5679 - val_accuracy: 0.6173 - val_loss: 1.9004\n",
            "Epoch 597/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.6033 - val_accuracy: 0.5926 - val_loss: 1.9050\n",
            "Epoch 598/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.6302 - val_accuracy: 0.6074 - val_loss: 1.8803\n",
            "Epoch 599/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.5598 - val_accuracy: 0.6148 - val_loss: 1.8810\n",
            "Epoch 600/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.5191 - val_accuracy: 0.6247 - val_loss: 1.8617\n",
            "Epoch 601/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.5501 - val_accuracy: 0.6222 - val_loss: 1.8578\n",
            "Epoch 602/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.5975 - val_accuracy: 0.6123 - val_loss: 1.8991\n",
            "Epoch 603/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.5829 - val_accuracy: 0.6123 - val_loss: 1.9177\n",
            "Epoch 604/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.6093 - val_accuracy: 0.6025 - val_loss: 1.9074\n",
            "Epoch 605/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.5709 - val_accuracy: 0.6222 - val_loss: 1.8880\n",
            "Epoch 606/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.5868 - val_accuracy: 0.6049 - val_loss: 1.9140\n",
            "Epoch 607/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.5986 - val_accuracy: 0.6049 - val_loss: 1.9041\n",
            "Epoch 608/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.6289 - val_accuracy: 0.6173 - val_loss: 1.9049\n",
            "Epoch 609/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.5710 - val_accuracy: 0.6000 - val_loss: 1.9325\n",
            "Epoch 610/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.5405 - val_accuracy: 0.6049 - val_loss: 1.9042\n",
            "Epoch 611/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.5905 - val_accuracy: 0.6173 - val_loss: 1.9082\n",
            "Epoch 612/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.5992 - val_accuracy: 0.6099 - val_loss: 1.9002\n",
            "Epoch 613/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7877 - loss: 0.6369 - val_accuracy: 0.6049 - val_loss: 1.9109\n",
            "Epoch 614/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.5098 - val_accuracy: 0.6025 - val_loss: 1.9479\n",
            "Epoch 615/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.5681 - val_accuracy: 0.6025 - val_loss: 1.9615\n",
            "Epoch 616/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.5583 - val_accuracy: 0.6148 - val_loss: 1.9325\n",
            "Epoch 617/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7847 - loss: 0.6157 - val_accuracy: 0.6099 - val_loss: 1.9132\n",
            "Epoch 618/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.5642 - val_accuracy: 0.6025 - val_loss: 1.9238\n",
            "Epoch 619/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7961 - loss: 0.5662 - val_accuracy: 0.6099 - val_loss: 1.9001\n",
            "Epoch 620/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7780 - loss: 0.5893 - val_accuracy: 0.6000 - val_loss: 1.9640\n",
            "Epoch 621/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.6523 - val_accuracy: 0.6099 - val_loss: 1.9331\n",
            "Epoch 622/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.5743 - val_accuracy: 0.6025 - val_loss: 1.9235\n",
            "Epoch 623/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5953 - val_accuracy: 0.6173 - val_loss: 1.9203\n",
            "Epoch 624/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5576 - val_accuracy: 0.6148 - val_loss: 1.9261\n",
            "Epoch 625/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.5667 - val_accuracy: 0.6173 - val_loss: 1.9106\n",
            "Epoch 626/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.6824 - val_accuracy: 0.6049 - val_loss: 1.9295\n",
            "Epoch 627/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.5631 - val_accuracy: 0.6099 - val_loss: 1.9728\n",
            "Epoch 628/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7828 - loss: 0.6111 - val_accuracy: 0.6272 - val_loss: 1.9566\n",
            "Epoch 629/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.5460 - val_accuracy: 0.6074 - val_loss: 1.9957\n",
            "Epoch 630/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.6027 - val_accuracy: 0.6000 - val_loss: 1.9954\n",
            "Epoch 631/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5405 - val_accuracy: 0.6296 - val_loss: 1.9924\n",
            "Epoch 632/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.6232 - val_accuracy: 0.6025 - val_loss: 1.9999\n",
            "Epoch 633/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5491 - val_accuracy: 0.6025 - val_loss: 1.9887\n",
            "Epoch 634/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.5434 - val_accuracy: 0.5951 - val_loss: 1.9759\n",
            "Epoch 635/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5562 - val_accuracy: 0.6049 - val_loss: 1.9489\n",
            "Epoch 636/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5937 - val_accuracy: 0.6025 - val_loss: 1.9643\n",
            "Epoch 637/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.6276 - val_accuracy: 0.6099 - val_loss: 1.9486\n",
            "Epoch 638/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.5764 - val_accuracy: 0.6296 - val_loss: 1.9236\n",
            "Epoch 639/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.5784 - val_accuracy: 0.6247 - val_loss: 1.9272\n",
            "Epoch 640/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.5467 - val_accuracy: 0.6000 - val_loss: 1.9237\n",
            "Epoch 641/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7928 - loss: 0.5681 - val_accuracy: 0.6148 - val_loss: 1.9339\n",
            "Epoch 642/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.5696 - val_accuracy: 0.6074 - val_loss: 1.9347\n",
            "Epoch 643/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.5750 - val_accuracy: 0.6247 - val_loss: 1.9120\n",
            "Epoch 644/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.5517 - val_accuracy: 0.6000 - val_loss: 1.9084\n",
            "Epoch 645/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.6061 - val_accuracy: 0.6099 - val_loss: 1.9132\n",
            "Epoch 646/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.5313 - val_accuracy: 0.6198 - val_loss: 1.9374\n",
            "Epoch 647/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.5737 - val_accuracy: 0.6173 - val_loss: 1.9489\n",
            "Epoch 648/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.5618 - val_accuracy: 0.6198 - val_loss: 1.9653\n",
            "Epoch 649/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5811 - val_accuracy: 0.6074 - val_loss: 1.9573\n",
            "Epoch 650/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.6025 - val_accuracy: 0.6025 - val_loss: 1.9705\n",
            "Epoch 651/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7783 - loss: 0.6388 - val_accuracy: 0.6198 - val_loss: 1.9713\n",
            "Epoch 652/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.5245 - val_accuracy: 0.6272 - val_loss: 1.9519\n",
            "Epoch 653/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.5659 - val_accuracy: 0.6198 - val_loss: 1.9680\n",
            "Epoch 654/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7933 - loss: 0.5999 - val_accuracy: 0.6272 - val_loss: 1.9612\n",
            "Epoch 655/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.5602 - val_accuracy: 0.6148 - val_loss: 1.9583\n",
            "Epoch 656/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.6112 - val_accuracy: 0.6049 - val_loss: 1.9997\n",
            "Epoch 657/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.5774 - val_accuracy: 0.6148 - val_loss: 2.0104\n",
            "Epoch 658/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8100 - loss: 0.5334 - val_accuracy: 0.6148 - val_loss: 1.9706\n",
            "Epoch 659/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.5753 - val_accuracy: 0.6321 - val_loss: 1.9889\n",
            "Epoch 660/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.5554 - val_accuracy: 0.6247 - val_loss: 1.9683\n",
            "Epoch 661/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.6227 - val_accuracy: 0.6173 - val_loss: 1.9510\n",
            "Epoch 662/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.6004 - val_accuracy: 0.6123 - val_loss: 1.9881\n",
            "Epoch 663/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.6207 - val_accuracy: 0.6296 - val_loss: 1.9596\n",
            "Epoch 664/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8101 - loss: 0.5556 - val_accuracy: 0.6346 - val_loss: 1.9721\n",
            "Epoch 665/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.5307 - val_accuracy: 0.6247 - val_loss: 1.9608\n",
            "Epoch 666/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.5852 - val_accuracy: 0.6173 - val_loss: 2.0065\n",
            "Epoch 667/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.5619 - val_accuracy: 0.6198 - val_loss: 1.9598\n",
            "Epoch 668/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7913 - loss: 0.6341 - val_accuracy: 0.6222 - val_loss: 1.9394\n",
            "Epoch 669/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.5653 - val_accuracy: 0.6198 - val_loss: 1.9504\n",
            "Epoch 670/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.5765 - val_accuracy: 0.6148 - val_loss: 1.9730\n",
            "Epoch 671/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.5046 - val_accuracy: 0.6173 - val_loss: 2.0017\n",
            "Epoch 672/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5721 - val_accuracy: 0.6247 - val_loss: 1.9865\n",
            "Epoch 673/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8213 - loss: 0.5315 - val_accuracy: 0.6272 - val_loss: 1.9948\n",
            "Epoch 674/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.6034 - val_accuracy: 0.6222 - val_loss: 1.9637\n",
            "Epoch 675/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5605 - val_accuracy: 0.6321 - val_loss: 1.9500\n",
            "Epoch 676/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7941 - loss: 0.5610 - val_accuracy: 0.6370 - val_loss: 1.9890\n",
            "Epoch 677/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.5468 - val_accuracy: 0.6222 - val_loss: 1.9920\n",
            "Epoch 678/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.5550 - val_accuracy: 0.6296 - val_loss: 1.9779\n",
            "Epoch 679/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.5859 - val_accuracy: 0.6173 - val_loss: 1.9450\n",
            "Epoch 680/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7783 - loss: 0.5950 - val_accuracy: 0.6148 - val_loss: 1.9309\n",
            "Epoch 681/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5784 - val_accuracy: 0.6272 - val_loss: 1.9409\n",
            "Epoch 682/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.6203 - val_accuracy: 0.6173 - val_loss: 1.9397\n",
            "Epoch 683/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.5522 - val_accuracy: 0.6296 - val_loss: 1.9235\n",
            "Epoch 684/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8211 - loss: 0.5253 - val_accuracy: 0.6321 - val_loss: 1.9037\n",
            "Epoch 685/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.5810 - val_accuracy: 0.6222 - val_loss: 1.9388\n",
            "Epoch 686/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.5944 - val_accuracy: 0.6222 - val_loss: 1.9801\n",
            "Epoch 687/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.5324 - val_accuracy: 0.6198 - val_loss: 1.9636\n",
            "Epoch 688/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.5329 - val_accuracy: 0.6099 - val_loss: 1.9913\n",
            "Epoch 689/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.5280 - val_accuracy: 0.6222 - val_loss: 1.9729\n",
            "Epoch 690/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.5033 - val_accuracy: 0.6173 - val_loss: 2.0149\n",
            "Epoch 691/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.5561 - val_accuracy: 0.6099 - val_loss: 1.9707\n",
            "Epoch 692/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.5976 - val_accuracy: 0.6049 - val_loss: 2.0081\n",
            "Epoch 693/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.6260 - val_accuracy: 0.6222 - val_loss: 1.9666\n",
            "Epoch 694/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7899 - loss: 0.5744 - val_accuracy: 0.6000 - val_loss: 1.9798\n",
            "Epoch 695/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5940 - val_accuracy: 0.6198 - val_loss: 1.9668\n",
            "Epoch 696/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.5136 - val_accuracy: 0.6321 - val_loss: 1.9602\n",
            "Epoch 697/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.5624 - val_accuracy: 0.6173 - val_loss: 1.9731\n",
            "Epoch 698/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.5572 - val_accuracy: 0.6123 - val_loss: 1.9899\n",
            "Epoch 699/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.5240 - val_accuracy: 0.5951 - val_loss: 1.9940\n",
            "Epoch 700/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.5465 - val_accuracy: 0.5951 - val_loss: 1.9766\n",
            "Epoch 701/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.5587 - val_accuracy: 0.6025 - val_loss: 1.9395\n",
            "Epoch 702/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.5665 - val_accuracy: 0.6025 - val_loss: 1.9592\n",
            "Epoch 703/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.5644 - val_accuracy: 0.6148 - val_loss: 1.9700\n",
            "Epoch 704/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.5774 - val_accuracy: 0.6074 - val_loss: 1.9731\n",
            "Epoch 705/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5524 - val_accuracy: 0.5951 - val_loss: 1.9768\n",
            "Epoch 706/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.5151 - val_accuracy: 0.6025 - val_loss: 1.9755\n",
            "Epoch 707/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.5490 - val_accuracy: 0.6025 - val_loss: 1.9650\n",
            "Epoch 708/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.5133 - val_accuracy: 0.5951 - val_loss: 1.9722\n",
            "Epoch 709/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8144 - loss: 0.5067 - val_accuracy: 0.6074 - val_loss: 1.9925\n",
            "Epoch 710/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7995 - loss: 0.5776 - val_accuracy: 0.6198 - val_loss: 1.9704\n",
            "Epoch 711/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.5688 - val_accuracy: 0.6099 - val_loss: 1.9615\n",
            "Epoch 712/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.5526 - val_accuracy: 0.6173 - val_loss: 1.9594\n",
            "Epoch 713/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5558 - val_accuracy: 0.6049 - val_loss: 1.9617\n",
            "Epoch 714/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.6351 - val_accuracy: 0.6099 - val_loss: 1.9881\n",
            "Epoch 715/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.5663 - val_accuracy: 0.6148 - val_loss: 1.9729\n",
            "Epoch 716/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.5831 - val_accuracy: 0.6173 - val_loss: 1.9455\n",
            "Epoch 717/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.5399 - val_accuracy: 0.6272 - val_loss: 1.9487\n",
            "Epoch 718/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.5714 - val_accuracy: 0.5951 - val_loss: 1.9733\n",
            "Epoch 719/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.5864 - val_accuracy: 0.6296 - val_loss: 1.9413\n",
            "Epoch 720/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.5264 - val_accuracy: 0.6025 - val_loss: 1.9447\n",
            "Epoch 721/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7902 - loss: 0.6145 - val_accuracy: 0.6025 - val_loss: 1.9522\n",
            "Epoch 722/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.5645 - val_accuracy: 0.5975 - val_loss: 1.9790\n",
            "Epoch 723/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.5314 - val_accuracy: 0.6148 - val_loss: 1.9980\n",
            "Epoch 724/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.5393 - val_accuracy: 0.6148 - val_loss: 1.9977\n",
            "Epoch 725/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.5605 - val_accuracy: 0.6173 - val_loss: 1.9755\n",
            "Epoch 726/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.5715 - val_accuracy: 0.6198 - val_loss: 1.9660\n",
            "Epoch 727/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.5872 - val_accuracy: 0.6099 - val_loss: 1.9944\n",
            "Epoch 728/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.5939 - val_accuracy: 0.6247 - val_loss: 1.9952\n",
            "Epoch 729/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5893 - val_accuracy: 0.6148 - val_loss: 1.9977\n",
            "Epoch 730/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.5829 - val_accuracy: 0.6049 - val_loss: 1.9671\n",
            "Epoch 731/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.5839 - val_accuracy: 0.6049 - val_loss: 1.9847\n",
            "Epoch 732/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.6070 - val_accuracy: 0.6049 - val_loss: 1.9875\n",
            "Epoch 733/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5640 - val_accuracy: 0.6025 - val_loss: 1.9569\n",
            "Epoch 734/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.5473 - val_accuracy: 0.6222 - val_loss: 1.9738\n",
            "Epoch 735/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.5839 - val_accuracy: 0.6198 - val_loss: 1.9817\n",
            "Epoch 736/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.6099 - val_accuracy: 0.6123 - val_loss: 1.9432\n",
            "Epoch 737/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.5377 - val_accuracy: 0.6296 - val_loss: 1.9682\n",
            "Epoch 738/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5161 - val_accuracy: 0.6222 - val_loss: 1.9651\n",
            "Epoch 739/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.4954 - val_accuracy: 0.6296 - val_loss: 1.9884\n",
            "Epoch 740/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.5799 - val_accuracy: 0.6148 - val_loss: 1.9878\n",
            "Epoch 741/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.5657 - val_accuracy: 0.6099 - val_loss: 1.9732\n",
            "Epoch 742/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 0.5282 - val_accuracy: 0.6247 - val_loss: 1.9842\n",
            "Epoch 743/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.5746 - val_accuracy: 0.6099 - val_loss: 1.9823\n",
            "Epoch 744/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.5194 - val_accuracy: 0.6173 - val_loss: 2.0029\n",
            "Epoch 745/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.5427 - val_accuracy: 0.6173 - val_loss: 2.0149\n",
            "Epoch 746/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.5700 - val_accuracy: 0.6123 - val_loss: 2.0183\n",
            "Epoch 747/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.5462 - val_accuracy: 0.6123 - val_loss: 2.0287\n",
            "Epoch 748/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.6322 - val_accuracy: 0.6099 - val_loss: 2.0369\n",
            "Epoch 749/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.5872 - val_accuracy: 0.6247 - val_loss: 2.0243\n",
            "Epoch 750/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.5395 - val_accuracy: 0.6173 - val_loss: 1.9858\n",
            "Epoch 751/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.5069 - val_accuracy: 0.6148 - val_loss: 2.0020\n",
            "Epoch 752/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5292 - val_accuracy: 0.6099 - val_loss: 2.0373\n",
            "Epoch 753/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.5546 - val_accuracy: 0.6049 - val_loss: 1.9534\n",
            "Epoch 754/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7962 - loss: 0.6125 - val_accuracy: 0.6099 - val_loss: 1.9911\n",
            "Epoch 755/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.5823 - val_accuracy: 0.5975 - val_loss: 2.0377\n",
            "Epoch 756/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.5291 - val_accuracy: 0.5901 - val_loss: 2.0227\n",
            "Epoch 757/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.5360 - val_accuracy: 0.5901 - val_loss: 2.0230\n",
            "Epoch 758/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.6069 - val_accuracy: 0.6025 - val_loss: 2.0114\n",
            "Epoch 759/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.4949 - val_accuracy: 0.6049 - val_loss: 2.0300\n",
            "Epoch 760/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8323 - loss: 0.5083 - val_accuracy: 0.5975 - val_loss: 2.0355\n",
            "Epoch 761/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.5533 - val_accuracy: 0.6099 - val_loss: 1.9848\n",
            "Epoch 762/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.5532 - val_accuracy: 0.6198 - val_loss: 1.9999\n",
            "Epoch 763/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7851 - loss: 0.6018 - val_accuracy: 0.6198 - val_loss: 1.9721\n",
            "Epoch 764/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.5421 - val_accuracy: 0.6148 - val_loss: 1.9787\n",
            "Epoch 765/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8087 - loss: 0.5498 - val_accuracy: 0.6148 - val_loss: 1.9834\n",
            "Epoch 766/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.5261 - val_accuracy: 0.6272 - val_loss: 1.9825\n",
            "Epoch 767/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.5245 - val_accuracy: 0.6049 - val_loss: 2.0445\n",
            "Epoch 768/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.5816 - val_accuracy: 0.6222 - val_loss: 1.9797\n",
            "Epoch 769/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.4910 - val_accuracy: 0.6247 - val_loss: 1.9454\n",
            "Epoch 770/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.5262 - val_accuracy: 0.6148 - val_loss: 1.9708\n",
            "Epoch 771/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.4968 - val_accuracy: 0.6272 - val_loss: 2.0009\n",
            "Epoch 772/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.5436 - val_accuracy: 0.6198 - val_loss: 2.0138\n",
            "Epoch 773/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.5299 - val_accuracy: 0.6049 - val_loss: 1.9728\n",
            "Epoch 774/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.5473 - val_accuracy: 0.5926 - val_loss: 1.9850\n",
            "Epoch 775/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.5549 - val_accuracy: 0.6099 - val_loss: 1.9786\n",
            "Epoch 776/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.6207 - val_accuracy: 0.6000 - val_loss: 1.9884\n",
            "Epoch 777/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.5560 - val_accuracy: 0.6123 - val_loss: 1.9206\n",
            "Epoch 778/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8087 - loss: 0.5672 - val_accuracy: 0.6049 - val_loss: 1.9391\n",
            "Epoch 779/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.5842 - val_accuracy: 0.6000 - val_loss: 1.9509\n",
            "Epoch 780/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.5194 - val_accuracy: 0.5951 - val_loss: 1.9744\n",
            "Epoch 781/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.5171 - val_accuracy: 0.5951 - val_loss: 1.9964\n",
            "Epoch 782/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.5250 - val_accuracy: 0.6123 - val_loss: 1.9624\n",
            "Epoch 783/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.5759 - val_accuracy: 0.6049 - val_loss: 1.9752\n",
            "Epoch 784/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8129 - loss: 0.5221 - val_accuracy: 0.6123 - val_loss: 1.9856\n",
            "Epoch 785/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5591 - val_accuracy: 0.5901 - val_loss: 1.9830\n",
            "Epoch 786/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8008 - loss: 0.5785 - val_accuracy: 0.6123 - val_loss: 2.0040\n",
            "Epoch 787/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.5114 - val_accuracy: 0.6099 - val_loss: 1.9932\n",
            "Epoch 788/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.6001 - val_accuracy: 0.6099 - val_loss: 1.9887\n",
            "Epoch 789/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.4938 - val_accuracy: 0.6025 - val_loss: 2.0010\n",
            "Epoch 790/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.5765 - val_accuracy: 0.6000 - val_loss: 1.9937\n",
            "Epoch 791/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.6064 - val_accuracy: 0.6025 - val_loss: 1.9604\n",
            "Epoch 792/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.5524 - val_accuracy: 0.6099 - val_loss: 2.0036\n",
            "Epoch 793/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.5212 - val_accuracy: 0.6074 - val_loss: 2.0001\n",
            "Epoch 794/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.5097 - val_accuracy: 0.6025 - val_loss: 2.0154\n",
            "Epoch 795/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.5100 - val_accuracy: 0.5951 - val_loss: 2.0118\n",
            "Epoch 796/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.6142 - val_accuracy: 0.6025 - val_loss: 2.0100\n",
            "Epoch 797/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.5717 - val_accuracy: 0.5926 - val_loss: 2.0224\n",
            "Epoch 798/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8104 - loss: 0.5452 - val_accuracy: 0.6049 - val_loss: 1.9931\n",
            "Epoch 799/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 0.5081 - val_accuracy: 0.5951 - val_loss: 2.0090\n",
            "Epoch 800/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8135 - loss: 0.5193 - val_accuracy: 0.6049 - val_loss: 1.9919\n",
            "Epoch 801/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.5187 - val_accuracy: 0.6000 - val_loss: 2.0095\n",
            "Epoch 802/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8284 - loss: 0.5204 - val_accuracy: 0.6000 - val_loss: 2.0207\n",
            "Epoch 803/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8177 - loss: 0.4976 - val_accuracy: 0.5975 - val_loss: 2.0241\n",
            "Epoch 804/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 0.4860 - val_accuracy: 0.6049 - val_loss: 2.0429\n",
            "Epoch 805/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7939 - loss: 0.5505 - val_accuracy: 0.6000 - val_loss: 2.0441\n",
            "Epoch 806/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8199 - loss: 0.5324 - val_accuracy: 0.5901 - val_loss: 2.0326\n",
            "Epoch 807/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.5470 - val_accuracy: 0.6148 - val_loss: 2.0309\n",
            "Epoch 808/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.5574 - val_accuracy: 0.5951 - val_loss: 2.0460\n",
            "Epoch 809/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.5309 - val_accuracy: 0.6123 - val_loss: 2.0242\n",
            "Epoch 810/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.5400 - val_accuracy: 0.6000 - val_loss: 2.0216\n",
            "Epoch 811/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.5134 - val_accuracy: 0.6049 - val_loss: 2.0272\n",
            "Epoch 812/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.5315 - val_accuracy: 0.5975 - val_loss: 2.0556\n",
            "Epoch 813/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.4886 - val_accuracy: 0.5975 - val_loss: 2.0508\n",
            "Epoch 814/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.4860 - val_accuracy: 0.6049 - val_loss: 2.0470\n",
            "Epoch 815/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8361 - loss: 0.4891 - val_accuracy: 0.5901 - val_loss: 2.0357\n",
            "Epoch 816/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7901 - loss: 0.5991 - val_accuracy: 0.5852 - val_loss: 2.0622\n",
            "Epoch 817/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.5926 - val_accuracy: 0.6074 - val_loss: 2.0923\n",
            "Epoch 818/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.5622 - val_accuracy: 0.5951 - val_loss: 2.0747\n",
            "Epoch 819/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.5761 - val_accuracy: 0.5951 - val_loss: 2.0675\n",
            "Epoch 820/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.5541 - val_accuracy: 0.5802 - val_loss: 2.0839\n",
            "Epoch 821/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8080 - loss: 0.5509 - val_accuracy: 0.5975 - val_loss: 2.0394\n",
            "Epoch 822/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4930 - val_accuracy: 0.5852 - val_loss: 2.0747\n",
            "Epoch 823/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.5359 - val_accuracy: 0.6148 - val_loss: 2.0607\n",
            "Epoch 824/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.5587 - val_accuracy: 0.5951 - val_loss: 2.0888\n",
            "Epoch 825/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.5207 - val_accuracy: 0.6123 - val_loss: 2.0578\n",
            "Epoch 826/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8432 - loss: 0.4842 - val_accuracy: 0.6148 - val_loss: 2.0749\n",
            "Epoch 827/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.5324 - val_accuracy: 0.6247 - val_loss: 2.0879\n",
            "Epoch 828/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.5352 - val_accuracy: 0.6025 - val_loss: 2.0475\n",
            "Epoch 829/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.5400 - val_accuracy: 0.5926 - val_loss: 2.0844\n",
            "Epoch 830/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.5470 - val_accuracy: 0.6148 - val_loss: 2.0456\n",
            "Epoch 831/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.5544 - val_accuracy: 0.6123 - val_loss: 2.0301\n",
            "Epoch 832/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.5125 - val_accuracy: 0.6148 - val_loss: 2.0540\n",
            "Epoch 833/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.5266 - val_accuracy: 0.5975 - val_loss: 2.0678\n",
            "Epoch 834/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.5213 - val_accuracy: 0.6000 - val_loss: 2.0813\n",
            "Epoch 835/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.5507 - val_accuracy: 0.6074 - val_loss: 2.0425\n",
            "Epoch 836/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8085 - loss: 0.5263 - val_accuracy: 0.6049 - val_loss: 2.0553\n",
            "Epoch 837/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.5110 - val_accuracy: 0.6049 - val_loss: 2.0147\n",
            "Epoch 838/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.5385 - val_accuracy: 0.6296 - val_loss: 1.9973\n",
            "Epoch 839/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.5296 - val_accuracy: 0.6025 - val_loss: 1.9935\n",
            "Epoch 840/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.5272 - val_accuracy: 0.6025 - val_loss: 2.0012\n",
            "Epoch 841/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.5124 - val_accuracy: 0.6099 - val_loss: 2.0173\n",
            "Epoch 842/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.5022 - val_accuracy: 0.6000 - val_loss: 2.0305\n",
            "Epoch 843/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.5557 - val_accuracy: 0.6000 - val_loss: 2.0455\n",
            "Epoch 844/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.5454 - val_accuracy: 0.6049 - val_loss: 2.0817\n",
            "Epoch 845/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8168 - loss: 0.5042 - val_accuracy: 0.6074 - val_loss: 2.0095\n",
            "Epoch 846/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.5819 - val_accuracy: 0.6049 - val_loss: 2.0131\n",
            "Epoch 847/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8198 - loss: 0.5038 - val_accuracy: 0.6049 - val_loss: 2.0488\n",
            "Epoch 848/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8111 - loss: 0.5606 - val_accuracy: 0.6173 - val_loss: 2.0078\n",
            "Epoch 849/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.5041 - val_accuracy: 0.6123 - val_loss: 2.0332\n",
            "Epoch 850/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8194 - loss: 0.5623 - val_accuracy: 0.6049 - val_loss: 1.9935\n",
            "Epoch 851/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8367 - loss: 0.4960 - val_accuracy: 0.6049 - val_loss: 2.0503\n",
            "Epoch 852/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.5322 - val_accuracy: 0.6049 - val_loss: 2.0466\n",
            "Epoch 853/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.4723 - val_accuracy: 0.5926 - val_loss: 2.0740\n",
            "Epoch 854/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.5560 - val_accuracy: 0.6099 - val_loss: 2.0125\n",
            "Epoch 855/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.5198 - val_accuracy: 0.6025 - val_loss: 2.0523\n",
            "Epoch 856/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.5744 - val_accuracy: 0.6000 - val_loss: 2.0607\n",
            "Epoch 857/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.5128 - val_accuracy: 0.6025 - val_loss: 2.0662\n",
            "Epoch 858/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.5379 - val_accuracy: 0.6074 - val_loss: 2.0840\n",
            "Epoch 859/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.5042 - val_accuracy: 0.6000 - val_loss: 2.0562\n",
            "Epoch 860/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8145 - loss: 0.5427 - val_accuracy: 0.6099 - val_loss: 2.0432\n",
            "Epoch 861/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.4714 - val_accuracy: 0.6198 - val_loss: 2.0478\n",
            "Epoch 862/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.5021 - val_accuracy: 0.6222 - val_loss: 2.0800\n",
            "Epoch 863/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.5104 - val_accuracy: 0.6099 - val_loss: 2.0934\n",
            "Epoch 864/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.5544 - val_accuracy: 0.6000 - val_loss: 2.0557\n",
            "Epoch 865/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4737 - val_accuracy: 0.6049 - val_loss: 2.0312\n",
            "Epoch 866/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.5324 - val_accuracy: 0.6074 - val_loss: 2.0862\n",
            "Epoch 867/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.5740 - val_accuracy: 0.6074 - val_loss: 2.0784\n",
            "Epoch 868/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.5616 - val_accuracy: 0.6099 - val_loss: 2.0580\n",
            "Epoch 869/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.5359 - val_accuracy: 0.6198 - val_loss: 2.0544\n",
            "Epoch 870/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8179 - loss: 0.4962 - val_accuracy: 0.6222 - val_loss: 2.0545\n",
            "Epoch 871/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.5022 - val_accuracy: 0.6222 - val_loss: 2.0737\n",
            "Epoch 872/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.5614 - val_accuracy: 0.6123 - val_loss: 2.0802\n",
            "Epoch 873/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.5332 - val_accuracy: 0.6074 - val_loss: 2.0619\n",
            "Epoch 874/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.5297 - val_accuracy: 0.5852 - val_loss: 2.0810\n",
            "Epoch 875/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.5214 - val_accuracy: 0.6025 - val_loss: 2.0829\n",
            "Epoch 876/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.5660 - val_accuracy: 0.6049 - val_loss: 2.0539\n",
            "Epoch 877/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.5621 - val_accuracy: 0.6099 - val_loss: 2.0334\n",
            "Epoch 878/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.5669 - val_accuracy: 0.6123 - val_loss: 2.0435\n",
            "Epoch 879/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8171 - loss: 0.5673 - val_accuracy: 0.6000 - val_loss: 2.0314\n",
            "Epoch 880/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4930 - val_accuracy: 0.6148 - val_loss: 2.0574\n",
            "Epoch 881/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8051 - loss: 0.5816 - val_accuracy: 0.6099 - val_loss: 2.0758\n",
            "Epoch 882/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.5009 - val_accuracy: 0.6123 - val_loss: 2.0438\n",
            "Epoch 883/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.5325 - val_accuracy: 0.6123 - val_loss: 2.0247\n",
            "Epoch 884/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.5562 - val_accuracy: 0.6025 - val_loss: 2.0230\n",
            "Epoch 885/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.5612 - val_accuracy: 0.5975 - val_loss: 2.0826\n",
            "Epoch 886/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.5532 - val_accuracy: 0.6099 - val_loss: 2.0544\n",
            "Epoch 887/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.5427 - val_accuracy: 0.6148 - val_loss: 2.0680\n",
            "Epoch 888/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.4993 - val_accuracy: 0.6074 - val_loss: 2.0719\n",
            "Epoch 889/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.5493 - val_accuracy: 0.6099 - val_loss: 2.0515\n",
            "Epoch 890/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.5430 - val_accuracy: 0.6049 - val_loss: 2.0935\n",
            "Epoch 891/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8206 - loss: 0.5505 - val_accuracy: 0.6148 - val_loss: 2.0955\n",
            "Epoch 892/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.5175 - val_accuracy: 0.6099 - val_loss: 2.1005\n",
            "Epoch 893/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.4792 - val_accuracy: 0.6025 - val_loss: 2.0517\n",
            "Epoch 894/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7992 - loss: 0.5722 - val_accuracy: 0.6173 - val_loss: 2.0074\n",
            "Epoch 895/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.5412 - val_accuracy: 0.6173 - val_loss: 1.9827\n",
            "Epoch 896/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.5201 - val_accuracy: 0.6272 - val_loss: 2.0211\n",
            "Epoch 897/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.4996 - val_accuracy: 0.6173 - val_loss: 2.0432\n",
            "Epoch 898/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.5247 - val_accuracy: 0.6148 - val_loss: 2.0202\n",
            "Epoch 899/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8090 - loss: 0.5215 - val_accuracy: 0.6049 - val_loss: 2.0252\n",
            "Epoch 900/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.5287 - val_accuracy: 0.6198 - val_loss: 2.0493\n",
            "Epoch 901/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.4917 - val_accuracy: 0.6148 - val_loss: 2.0544\n",
            "Epoch 902/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8187 - loss: 0.5234 - val_accuracy: 0.5975 - val_loss: 2.0646\n",
            "Epoch 903/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.5150 - val_accuracy: 0.6025 - val_loss: 2.0501\n",
            "Epoch 904/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.4982 - val_accuracy: 0.6247 - val_loss: 2.0846\n",
            "Epoch 905/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4856 - val_accuracy: 0.6148 - val_loss: 2.0692\n",
            "Epoch 906/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.5501 - val_accuracy: 0.5975 - val_loss: 2.1109\n",
            "Epoch 907/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.5279 - val_accuracy: 0.6049 - val_loss: 2.0853\n",
            "Epoch 908/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8236 - loss: 0.4919 - val_accuracy: 0.6074 - val_loss: 2.0781\n",
            "Epoch 909/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4896 - val_accuracy: 0.6148 - val_loss: 2.0643\n",
            "Epoch 910/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.5568 - val_accuracy: 0.5852 - val_loss: 2.1175\n",
            "Epoch 911/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.5858 - val_accuracy: 0.5975 - val_loss: 2.0733\n",
            "Epoch 912/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8483 - loss: 0.4234 - val_accuracy: 0.6198 - val_loss: 2.0870\n",
            "Epoch 913/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.6102 - val_accuracy: 0.6000 - val_loss: 2.1122\n",
            "Epoch 914/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.5572 - val_accuracy: 0.6049 - val_loss: 2.1147\n",
            "Epoch 915/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.5086 - val_accuracy: 0.6074 - val_loss: 2.0884\n",
            "Epoch 916/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.4597 - val_accuracy: 0.6173 - val_loss: 2.0742\n",
            "Epoch 917/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8442 - loss: 0.4415 - val_accuracy: 0.6025 - val_loss: 2.0653\n",
            "Epoch 918/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.4838 - val_accuracy: 0.6000 - val_loss: 2.0743\n",
            "Epoch 919/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8187 - loss: 0.5484 - val_accuracy: 0.6099 - val_loss: 2.1004\n",
            "Epoch 920/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.5385 - val_accuracy: 0.6123 - val_loss: 2.1101\n",
            "Epoch 921/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8302 - loss: 0.5234 - val_accuracy: 0.5901 - val_loss: 2.1711\n",
            "Epoch 922/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5247 - val_accuracy: 0.6123 - val_loss: 2.1292\n",
            "Epoch 923/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.5632 - val_accuracy: 0.5901 - val_loss: 2.1249\n",
            "Epoch 924/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.5136 - val_accuracy: 0.5926 - val_loss: 2.1425\n",
            "Epoch 925/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.5763 - val_accuracy: 0.5926 - val_loss: 2.0774\n",
            "Epoch 926/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.4882 - val_accuracy: 0.6049 - val_loss: 2.1049\n",
            "Epoch 927/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.5567 - val_accuracy: 0.6123 - val_loss: 2.1267\n",
            "Epoch 928/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.5031 - val_accuracy: 0.6049 - val_loss: 2.1070\n",
            "Epoch 929/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.5431 - val_accuracy: 0.6049 - val_loss: 2.1054\n",
            "Epoch 930/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.5701 - val_accuracy: 0.5852 - val_loss: 2.1024\n",
            "Epoch 931/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8016 - loss: 0.5872 - val_accuracy: 0.5951 - val_loss: 2.0966\n",
            "Epoch 932/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.5185 - val_accuracy: 0.6025 - val_loss: 2.0887\n",
            "Epoch 933/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.5290 - val_accuracy: 0.6000 - val_loss: 2.1053\n",
            "Epoch 934/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8271 - loss: 0.5048 - val_accuracy: 0.5926 - val_loss: 2.0833\n",
            "Epoch 935/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.5447 - val_accuracy: 0.6074 - val_loss: 2.1135\n",
            "Epoch 936/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.4927 - val_accuracy: 0.6148 - val_loss: 2.1172\n",
            "Epoch 937/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.4355 - val_accuracy: 0.6049 - val_loss: 2.1392\n",
            "Epoch 938/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7997 - loss: 0.5272 - val_accuracy: 0.5975 - val_loss: 2.1125\n",
            "Epoch 939/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.4965 - val_accuracy: 0.6074 - val_loss: 2.0770\n",
            "Epoch 940/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.5140 - val_accuracy: 0.6123 - val_loss: 2.0731\n",
            "Epoch 941/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4917 - val_accuracy: 0.6198 - val_loss: 2.0938\n",
            "Epoch 942/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.5636 - val_accuracy: 0.6148 - val_loss: 2.1167\n",
            "Epoch 943/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.5430 - val_accuracy: 0.6123 - val_loss: 2.1247\n",
            "Epoch 944/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.5414 - val_accuracy: 0.6247 - val_loss: 2.1256\n",
            "Epoch 945/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.5310 - val_accuracy: 0.6000 - val_loss: 2.1567\n",
            "Epoch 946/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.4871 - val_accuracy: 0.6025 - val_loss: 2.1634\n",
            "Epoch 947/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.5476 - val_accuracy: 0.6099 - val_loss: 2.1581\n",
            "Epoch 948/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.6080 - val_accuracy: 0.6123 - val_loss: 2.1065\n",
            "Epoch 949/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.5121 - val_accuracy: 0.6049 - val_loss: 2.1231\n",
            "Epoch 950/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7899 - loss: 0.5402 - val_accuracy: 0.5975 - val_loss: 2.1017\n",
            "Epoch 951/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.5294 - val_accuracy: 0.5926 - val_loss: 2.1389\n",
            "Epoch 952/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.4882 - val_accuracy: 0.5852 - val_loss: 2.1216\n",
            "Epoch 953/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.5171 - val_accuracy: 0.5926 - val_loss: 2.1170\n",
            "Epoch 954/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.4818 - val_accuracy: 0.5827 - val_loss: 2.1048\n",
            "Epoch 955/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.5312 - val_accuracy: 0.6123 - val_loss: 2.0669\n",
            "Epoch 956/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.5565 - val_accuracy: 0.6025 - val_loss: 2.1077\n",
            "Epoch 957/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.4724 - val_accuracy: 0.6123 - val_loss: 2.0833\n",
            "Epoch 958/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.5518 - val_accuracy: 0.6173 - val_loss: 2.0534\n",
            "Epoch 959/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.5302 - val_accuracy: 0.6173 - val_loss: 2.0530\n",
            "Epoch 960/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.5518 - val_accuracy: 0.5901 - val_loss: 2.0694\n",
            "Epoch 961/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.5253 - val_accuracy: 0.5877 - val_loss: 2.0613\n",
            "Epoch 962/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.5229 - val_accuracy: 0.5877 - val_loss: 2.0492\n",
            "Epoch 963/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4957 - val_accuracy: 0.5926 - val_loss: 2.0527\n",
            "Epoch 964/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.5039 - val_accuracy: 0.5975 - val_loss: 2.0735\n",
            "Epoch 965/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.4887 - val_accuracy: 0.5852 - val_loss: 2.0490\n",
            "Epoch 966/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.5312 - val_accuracy: 0.5951 - val_loss: 2.0372\n",
            "Epoch 967/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.5019 - val_accuracy: 0.6000 - val_loss: 2.0265\n",
            "Epoch 968/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8104 - loss: 0.5261 - val_accuracy: 0.6049 - val_loss: 2.0328\n",
            "Epoch 969/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.5256 - val_accuracy: 0.5926 - val_loss: 2.0631\n",
            "Epoch 970/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8156 - loss: 0.5301 - val_accuracy: 0.6025 - val_loss: 2.0550\n",
            "Epoch 971/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.4963 - val_accuracy: 0.6123 - val_loss: 2.0626\n",
            "Epoch 972/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8267 - loss: 0.5180 - val_accuracy: 0.5951 - val_loss: 2.0387\n",
            "Epoch 973/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.5140 - val_accuracy: 0.5901 - val_loss: 2.0631\n",
            "Epoch 974/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8173 - loss: 0.4914 - val_accuracy: 0.5852 - val_loss: 2.0629\n",
            "Epoch 975/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.5022 - val_accuracy: 0.5877 - val_loss: 2.0685\n",
            "Epoch 976/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.4795 - val_accuracy: 0.5926 - val_loss: 2.0988\n",
            "Epoch 977/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.5507 - val_accuracy: 0.5951 - val_loss: 2.1172\n",
            "Epoch 978/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.5185 - val_accuracy: 0.5877 - val_loss: 2.1216\n",
            "Epoch 979/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8126 - loss: 0.5240 - val_accuracy: 0.5852 - val_loss: 2.1309\n",
            "Epoch 980/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.5574 - val_accuracy: 0.6025 - val_loss: 2.0675\n",
            "Epoch 981/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8354 - loss: 0.4780 - val_accuracy: 0.6123 - val_loss: 2.0808\n",
            "Epoch 982/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.5743 - val_accuracy: 0.5753 - val_loss: 2.0837\n",
            "Epoch 983/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.5188 - val_accuracy: 0.5975 - val_loss: 2.0995\n",
            "Epoch 984/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.5540 - val_accuracy: 0.6074 - val_loss: 2.1151\n",
            "Epoch 985/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.5420 - val_accuracy: 0.6074 - val_loss: 2.0863\n",
            "Epoch 986/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4927 - val_accuracy: 0.6099 - val_loss: 2.1144\n",
            "Epoch 987/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.5056 - val_accuracy: 0.6000 - val_loss: 2.1487\n",
            "Epoch 988/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4889 - val_accuracy: 0.6074 - val_loss: 2.1338\n",
            "Epoch 989/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.5297 - val_accuracy: 0.6074 - val_loss: 2.1442\n",
            "Epoch 990/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.5193 - val_accuracy: 0.6000 - val_loss: 2.1144\n",
            "Epoch 991/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.5125 - val_accuracy: 0.5951 - val_loss: 2.1044\n",
            "Epoch 992/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.5101 - val_accuracy: 0.6049 - val_loss: 2.0989\n",
            "Epoch 993/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.5820 - val_accuracy: 0.5877 - val_loss: 2.1002\n",
            "Epoch 994/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8337 - loss: 0.4934 - val_accuracy: 0.6049 - val_loss: 2.1105\n",
            "Epoch 995/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.5223 - val_accuracy: 0.5951 - val_loss: 2.1005\n",
            "Epoch 996/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4972 - val_accuracy: 0.6025 - val_loss: 2.1030\n",
            "Epoch 997/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8184 - loss: 0.4877 - val_accuracy: 0.6123 - val_loss: 2.0906\n",
            "Epoch 998/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.5078 - val_accuracy: 0.6049 - val_loss: 2.1334\n",
            "Epoch 999/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.5240 - val_accuracy: 0.6123 - val_loss: 2.0983\n",
            "Epoch 1000/1000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.5396 - val_accuracy: 0.6025 - val_loss: 2.1060\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "ANN Model Performance:\n",
            "Test Accuracy: 0.6025\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "          Axe       0.12      0.14      0.13        14\n",
            " BirdChirping       0.75      0.56      0.64        16\n",
            "     Chainsaw       0.80      0.80      0.80        15\n",
            "     Clapping       0.94      0.75      0.83        20\n",
            "         Fire       0.75      0.94      0.83        16\n",
            "     Firework       0.55      0.46      0.50        13\n",
            "    Footsteps       0.58      0.44      0.50        16\n",
            "         Frog       0.67      0.35      0.46        17\n",
            "    Generator       0.33      0.40      0.36        10\n",
            "      Gunshot       0.56      0.59      0.57        17\n",
            "      Handsaw       0.75      1.00      0.86        12\n",
            "   Helicopter       0.81      0.71      0.76        24\n",
            "       Insect       0.72      0.65      0.68        20\n",
            "         Lion       0.67      0.50      0.57        12\n",
            "         Rain       0.27      0.25      0.26        12\n",
            "      Silence       0.87      0.93      0.90        14\n",
            "     Speaking       0.71      0.53      0.61        19\n",
            "     Squirrel       0.47      0.41      0.44        17\n",
            " Thunderstorm       0.50      0.53      0.52        15\n",
            "  TreeFalling       0.58      0.64      0.61        11\n",
            "VehicleEngine       0.25      0.36      0.30        11\n",
            "   WaterDrops       0.62      0.87      0.72        15\n",
            "    Whistling       0.67      0.77      0.71        13\n",
            "         Wind       0.80      0.73      0.76        22\n",
            "  WingFlaping       0.62      0.31      0.42        16\n",
            "     WolfHowl       0.69      1.00      0.81        11\n",
            "     WoodChop       0.14      0.43      0.21         7\n",
            "\n",
            "     accuracy                           0.60       405\n",
            "    macro avg       0.60      0.59      0.58       405\n",
            " weighted avg       0.63      0.60      0.61       405\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 2  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0 11]\n",
            " [ 0  9  0  0  2  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  1  1  1  0\n",
            "   0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  1  0\n",
            "   0  0  0]\n",
            " [ 2  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
            "   0  0  2]\n",
            " [ 0  0  0  0 15  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 2  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  1  3  0  0  0  0  0\n",
            "   0  0  1]\n",
            " [ 1  0  0  1  1  1  7  0  0  0  0  0  0  0  0  0  0  0  0  2  0  1  0  0\n",
            "   1  0  1]\n",
            " [ 1  1  0  0  0  0  0  6  1  2  0  0  2  1  0  0  0  2  0  0  0  0  1  0\n",
            "   0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  4  0  0  0  0  0  1  0  0  1  0  0  3  0  0  0\n",
            "   0  0  0]\n",
            " [ 3  0  0  0  0  0  0  0  0 10  0  0  0  1  0  0  0  0  0  0  0  1  0  1\n",
            "   0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  1  0  0  0  0  0  1  0  0  0 17  0  0  0  0  0  1  1  0  3  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  1  0  0  0  0  1  1  0  0  0 13  0  1  0  0  0  0  0  0  0  2  0\n",
            "   0  1  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  1  0  0  0  6  0  0  0  0  1  0  0  0  0  0\n",
            "   1  2  0]\n",
            " [ 0  0  1  0  0  0  1  0  1  0  1  0  1  0  3  1  0  0  1  0  1  0  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  2  0  2  0  1  0  0 10  0  0  0  0  0  0  1\n",
            "   0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  1  1  0  0  0  1  7  0  1  4  1  0  0\n",
            "   0  0  0]\n",
            " [ 1  0  0  0  0  3  0  0  0  0  0  0  0  0  1  0  0  0  8  0  0  0  0  1\n",
            "   0  0  1]\n",
            " [ 0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  7  0  2  0  0\n",
            "   0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  1  0  1  1  0  0  0  0  1  2  0  0  4  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0 13  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0 10  0\n",
            "   0  1  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  2  1  0  0  1  0  0  0  0 16\n",
            "   1  0  0]\n",
            " [ 2  0  0  0  1  0  2  0  0  1  0  0  0  0  1  0  0  1  1  1  0  0  0  0\n",
            "   5  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0 11  0]\n",
            " [ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0\n",
            "   0  0  3]]\n",
            "\n",
            "Best ANN model saved as 'best_ann_model.h5'!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import joblib\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/extracted_features_final.csv')  # Replace with your actual file path\n",
        "\n",
        "# Encode the target column (Class Name)\n",
        "label_encoder = LabelEncoder()\n",
        "df['Encoded Class'] = label_encoder.fit_transform(df['Class Name'])  # Add encoded column\n",
        "\n",
        "# Drop 'Class ID' and select features/target\n",
        "df = df.drop(columns=['Class ID'])  # Drop 'Class ID' column\n",
        "X = df.iloc[:, 1:-1].values  # Features (exclude 'Class Name' and 'Encoded Class')\n",
        "y = df['Encoded Class'].values  # Encoded target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features for ANN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the ANN Model using Keras\n",
        "def create_ann_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model.add(layers.InputLayer(input_shape=input_shape))\n",
        "\n",
        "    # First hidden layer\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))  # Dropout to prevent overfitting\n",
        "\n",
        "    # Second hidden layer\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))  # Dropout\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))  # Softmax for multi-class classification\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape and number of output classes\n",
        "input_shape = (X_train.shape[1],)  # Input shape is the number of features\n",
        "num_classes = len(np.unique(y))    # Number of target classes (should match your data)\n",
        "\n",
        "# Create the model\n",
        "model = create_ann_model(input_shape, num_classes)\n",
        "\n",
        "# Train the ANN model\n",
        "print(\"Training ANN...\")\n",
        "model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_ann = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "# Print model accuracy\n",
        "print(\"\\nANN Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_ann):.4f}\")\n",
        "\n",
        "# Print classification report and confusion matrix\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_ann, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_ann))\n",
        "\n",
        "# Save the model\n",
        "model.save('best_ann_model.h5')\n",
        "print(\"\\nBest ANN model saved as 'best_ann_model.h5'!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install librosa numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woq_zbKGeh-q",
        "outputId": "de7ff681-16c6-4cc1-c84a-95e39daaaf4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for CNN (reshape to 2D if treating it like an image)\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Build the CNN Model\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Convolutional Layer\n",
        "    model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Second Convolutional Layer\n",
        "    model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
        "    model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Flatten and Fully Connected Layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define input shape for CNN\n",
        "input_shape_cnn = (X_train_cnn.shape[1], X_train_cnn.shape[2])\n",
        "\n",
        "# Create and train the CNN model\n",
        "cnn_model = create_cnn_model(input_shape_cnn, num_classes)\n",
        "print(\"Training CNN...\")\n",
        "cnn_model.fit(X_train_cnn, y_train, epochs=500, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "# Evaluate the CNN model\n",
        "y_pred_cnn = np.argmax(cnn_model.predict(X_test_cnn), axis=-1)\n",
        "\n",
        "# Print CNN accuracy\n",
        "print(\"\\nCNN Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_cnn):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_cnn, target_names=label_encoder.classes_))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_cnn))\n",
        "\n",
        "# Save the CNN model\n",
        "cnn_model.save('best_cnn_model.h5')\n",
        "print(\"\\nBest CNN model saved as 'best_cnn_model.h5'!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtOxPdzjoZCC",
        "outputId": "188869b2-34a8-4f71-cd73-b487320360c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.0701 - loss: 3.2666 - val_accuracy: 0.1358 - val_loss: 2.9930\n",
            "Epoch 2/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1338 - loss: 2.9597 - val_accuracy: 0.2173 - val_loss: 2.6261\n",
            "Epoch 3/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1875 - loss: 2.7111 - val_accuracy: 0.2617 - val_loss: 2.4677\n",
            "Epoch 4/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.2158 - loss: 2.5463 - val_accuracy: 0.2914 - val_loss: 2.3607\n",
            "Epoch 5/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2814 - loss: 2.3756 - val_accuracy: 0.3012 - val_loss: 2.2717\n",
            "Epoch 6/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3062 - loss: 2.3128 - val_accuracy: 0.3259 - val_loss: 2.1890\n",
            "Epoch 7/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3058 - loss: 2.2281 - val_accuracy: 0.3728 - val_loss: 2.1335\n",
            "Epoch 8/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3487 - loss: 2.1614 - val_accuracy: 0.3580 - val_loss: 2.0917\n",
            "Epoch 9/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3545 - loss: 2.0972 - val_accuracy: 0.4025 - val_loss: 2.0427\n",
            "Epoch 10/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3961 - loss: 1.9992 - val_accuracy: 0.3926 - val_loss: 2.0104\n",
            "Epoch 11/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4019 - loss: 1.9743 - val_accuracy: 0.4123 - val_loss: 1.9454\n",
            "Epoch 12/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3869 - loss: 1.9712 - val_accuracy: 0.3951 - val_loss: 1.9351\n",
            "Epoch 13/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4260 - loss: 1.8555 - val_accuracy: 0.4272 - val_loss: 1.8792\n",
            "Epoch 14/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4504 - loss: 1.8282 - val_accuracy: 0.4321 - val_loss: 1.8597\n",
            "Epoch 15/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4495 - loss: 1.7880 - val_accuracy: 0.4346 - val_loss: 1.8363\n",
            "Epoch 16/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4789 - loss: 1.7134 - val_accuracy: 0.4395 - val_loss: 1.8462\n",
            "Epoch 17/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4892 - loss: 1.6668 - val_accuracy: 0.4617 - val_loss: 1.7768\n",
            "Epoch 18/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4936 - loss: 1.6619 - val_accuracy: 0.4272 - val_loss: 1.8412\n",
            "Epoch 19/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4890 - loss: 1.6539 - val_accuracy: 0.4593 - val_loss: 1.7987\n",
            "Epoch 20/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4914 - loss: 1.6404 - val_accuracy: 0.4815 - val_loss: 1.7846\n",
            "Epoch 21/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5157 - loss: 1.5983 - val_accuracy: 0.4642 - val_loss: 1.7625\n",
            "Epoch 22/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5376 - loss: 1.5341 - val_accuracy: 0.4864 - val_loss: 1.7513\n",
            "Epoch 23/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5162 - loss: 1.4999 - val_accuracy: 0.4519 - val_loss: 1.7806\n",
            "Epoch 24/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5265 - loss: 1.4564 - val_accuracy: 0.4667 - val_loss: 1.7271\n",
            "Epoch 25/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5454 - loss: 1.4235 - val_accuracy: 0.4741 - val_loss: 1.7398\n",
            "Epoch 26/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5354 - loss: 1.4575 - val_accuracy: 0.5062 - val_loss: 1.7097\n",
            "Epoch 27/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5614 - loss: 1.3570 - val_accuracy: 0.4938 - val_loss: 1.7186\n",
            "Epoch 28/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5504 - loss: 1.3574 - val_accuracy: 0.4938 - val_loss: 1.7050\n",
            "Epoch 29/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5779 - loss: 1.3169 - val_accuracy: 0.4765 - val_loss: 1.6982\n",
            "Epoch 30/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5822 - loss: 1.3178 - val_accuracy: 0.4963 - val_loss: 1.6916\n",
            "Epoch 31/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5709 - loss: 1.3349 - val_accuracy: 0.4914 - val_loss: 1.7188\n",
            "Epoch 32/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5968 - loss: 1.2933 - val_accuracy: 0.4963 - val_loss: 1.6882\n",
            "Epoch 33/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5768 - loss: 1.2788 - val_accuracy: 0.4914 - val_loss: 1.6748\n",
            "Epoch 34/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6082 - loss: 1.2361 - val_accuracy: 0.5062 - val_loss: 1.6755\n",
            "Epoch 35/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6113 - loss: 1.2215 - val_accuracy: 0.5111 - val_loss: 1.6767\n",
            "Epoch 36/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6373 - loss: 1.1752 - val_accuracy: 0.4889 - val_loss: 1.7061\n",
            "Epoch 37/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6145 - loss: 1.1366 - val_accuracy: 0.5210 - val_loss: 1.6583\n",
            "Epoch 38/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6549 - loss: 1.0970 - val_accuracy: 0.4914 - val_loss: 1.7118\n",
            "Epoch 39/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6234 - loss: 1.1375 - val_accuracy: 0.5062 - val_loss: 1.6532\n",
            "Epoch 40/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6577 - loss: 1.0339 - val_accuracy: 0.4765 - val_loss: 1.7033\n",
            "Epoch 41/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6509 - loss: 1.0758 - val_accuracy: 0.5259 - val_loss: 1.6988\n",
            "Epoch 42/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6678 - loss: 1.0270 - val_accuracy: 0.4988 - val_loss: 1.6730\n",
            "Epoch 43/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6448 - loss: 1.0141 - val_accuracy: 0.5111 - val_loss: 1.6607\n",
            "Epoch 44/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6748 - loss: 1.0002 - val_accuracy: 0.5210 - val_loss: 1.6552\n",
            "Epoch 45/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.9674 - val_accuracy: 0.4988 - val_loss: 1.7614\n",
            "Epoch 46/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 1.0148 - val_accuracy: 0.5407 - val_loss: 1.6853\n",
            "Epoch 47/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6863 - loss: 0.9586 - val_accuracy: 0.5383 - val_loss: 1.6937\n",
            "Epoch 48/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6826 - loss: 0.9701 - val_accuracy: 0.5160 - val_loss: 1.7039\n",
            "Epoch 49/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6805 - loss: 0.9477 - val_accuracy: 0.4963 - val_loss: 1.7271\n",
            "Epoch 50/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.9549 - val_accuracy: 0.5432 - val_loss: 1.7071\n",
            "Epoch 51/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6974 - loss: 0.8935 - val_accuracy: 0.5136 - val_loss: 1.6880\n",
            "Epoch 52/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.8779 - val_accuracy: 0.5259 - val_loss: 1.7333\n",
            "Epoch 53/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6940 - loss: 0.8738 - val_accuracy: 0.5407 - val_loss: 1.6908\n",
            "Epoch 54/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6754 - loss: 0.8948 - val_accuracy: 0.5111 - val_loss: 1.7542\n",
            "Epoch 55/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.9028 - val_accuracy: 0.5358 - val_loss: 1.7211\n",
            "Epoch 56/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7280 - loss: 0.8495 - val_accuracy: 0.5160 - val_loss: 1.7192\n",
            "Epoch 57/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7275 - loss: 0.8099 - val_accuracy: 0.5383 - val_loss: 1.7462\n",
            "Epoch 58/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.7953 - val_accuracy: 0.5481 - val_loss: 1.7200\n",
            "Epoch 59/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.7962 - val_accuracy: 0.5383 - val_loss: 1.7428\n",
            "Epoch 60/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.8217 - val_accuracy: 0.5580 - val_loss: 1.6994\n",
            "Epoch 61/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7490 - loss: 0.7856 - val_accuracy: 0.5605 - val_loss: 1.7843\n",
            "Epoch 62/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7375 - loss: 0.7870 - val_accuracy: 0.5284 - val_loss: 1.8311\n",
            "Epoch 63/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.7784 - val_accuracy: 0.5333 - val_loss: 1.7951\n",
            "Epoch 64/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.7366 - val_accuracy: 0.5407 - val_loss: 1.8140\n",
            "Epoch 65/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7316 - loss: 0.7185 - val_accuracy: 0.5333 - val_loss: 1.7954\n",
            "Epoch 66/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.7279 - val_accuracy: 0.5309 - val_loss: 1.7896\n",
            "Epoch 67/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 0.7799 - val_accuracy: 0.5506 - val_loss: 1.8205\n",
            "Epoch 68/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.7495 - val_accuracy: 0.5605 - val_loss: 1.8357\n",
            "Epoch 69/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7554 - loss: 0.6948 - val_accuracy: 0.5358 - val_loss: 1.8070\n",
            "Epoch 70/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.6884 - val_accuracy: 0.5654 - val_loss: 1.8178\n",
            "Epoch 71/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7505 - loss: 0.6781 - val_accuracy: 0.5333 - val_loss: 1.9125\n",
            "Epoch 72/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7839 - loss: 0.6389 - val_accuracy: 0.5432 - val_loss: 1.8472\n",
            "Epoch 73/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.6862 - val_accuracy: 0.5506 - val_loss: 1.8387\n",
            "Epoch 74/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7760 - loss: 0.6288 - val_accuracy: 0.5333 - val_loss: 1.8608\n",
            "Epoch 75/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7980 - loss: 0.5925 - val_accuracy: 0.5531 - val_loss: 1.9146\n",
            "Epoch 76/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7860 - loss: 0.5931 - val_accuracy: 0.5556 - val_loss: 1.8685\n",
            "Epoch 77/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7916 - loss: 0.6267 - val_accuracy: 0.5877 - val_loss: 1.8479\n",
            "Epoch 78/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8000 - loss: 0.6041 - val_accuracy: 0.5580 - val_loss: 1.8687\n",
            "Epoch 79/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.5729 - val_accuracy: 0.5309 - val_loss: 1.9384\n",
            "Epoch 80/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7876 - loss: 0.6023 - val_accuracy: 0.5531 - val_loss: 1.9692\n",
            "Epoch 81/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.5938 - val_accuracy: 0.5457 - val_loss: 1.9401\n",
            "Epoch 82/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7885 - loss: 0.5994 - val_accuracy: 0.5728 - val_loss: 1.9413\n",
            "Epoch 83/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7969 - loss: 0.5669 - val_accuracy: 0.5506 - val_loss: 1.9460\n",
            "Epoch 84/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8123 - loss: 0.5392 - val_accuracy: 0.5432 - val_loss: 2.0420\n",
            "Epoch 85/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8108 - loss: 0.5460 - val_accuracy: 0.5630 - val_loss: 1.9861\n",
            "Epoch 86/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8064 - loss: 0.5777 - val_accuracy: 0.5605 - val_loss: 2.0151\n",
            "Epoch 87/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8025 - loss: 0.5602 - val_accuracy: 0.5506 - val_loss: 2.0313\n",
            "Epoch 88/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8134 - loss: 0.5171 - val_accuracy: 0.5506 - val_loss: 2.0389\n",
            "Epoch 89/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8197 - loss: 0.5193 - val_accuracy: 0.5235 - val_loss: 2.1026\n",
            "Epoch 90/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8132 - loss: 0.5382 - val_accuracy: 0.5481 - val_loss: 2.0846\n",
            "Epoch 91/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8229 - loss: 0.5068 - val_accuracy: 0.5654 - val_loss: 2.1164\n",
            "Epoch 92/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8080 - loss: 0.5397 - val_accuracy: 0.5753 - val_loss: 2.1344\n",
            "Epoch 93/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8234 - loss: 0.4915 - val_accuracy: 0.5778 - val_loss: 2.0661\n",
            "Epoch 94/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4859 - val_accuracy: 0.5556 - val_loss: 2.1618\n",
            "Epoch 95/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8232 - loss: 0.5135 - val_accuracy: 0.5630 - val_loss: 2.0718\n",
            "Epoch 96/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.4735 - val_accuracy: 0.5383 - val_loss: 2.1387\n",
            "Epoch 97/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.4915 - val_accuracy: 0.5778 - val_loss: 2.1348\n",
            "Epoch 98/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.4745 - val_accuracy: 0.5679 - val_loss: 2.1336\n",
            "Epoch 99/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8386 - loss: 0.4649 - val_accuracy: 0.5852 - val_loss: 2.0927\n",
            "Epoch 100/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.4712 - val_accuracy: 0.5556 - val_loss: 2.2284\n",
            "Epoch 101/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8369 - loss: 0.4678 - val_accuracy: 0.5728 - val_loss: 2.1865\n",
            "Epoch 102/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8220 - loss: 0.4735 - val_accuracy: 0.5654 - val_loss: 2.1784\n",
            "Epoch 103/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8530 - loss: 0.4414 - val_accuracy: 0.5630 - val_loss: 2.2455\n",
            "Epoch 104/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8482 - loss: 0.4425 - val_accuracy: 0.5728 - val_loss: 2.2487\n",
            "Epoch 105/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8480 - loss: 0.4315 - val_accuracy: 0.5630 - val_loss: 2.2840\n",
            "Epoch 106/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8444 - loss: 0.4621 - val_accuracy: 0.5728 - val_loss: 2.3127\n",
            "Epoch 107/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8386 - loss: 0.4453 - val_accuracy: 0.5802 - val_loss: 2.2502\n",
            "Epoch 108/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8462 - loss: 0.4315 - val_accuracy: 0.5704 - val_loss: 2.2721\n",
            "Epoch 109/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8471 - loss: 0.4048 - val_accuracy: 0.5580 - val_loss: 2.3175\n",
            "Epoch 110/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8655 - loss: 0.4004 - val_accuracy: 0.5556 - val_loss: 2.3734\n",
            "Epoch 111/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8567 - loss: 0.4073 - val_accuracy: 0.5704 - val_loss: 2.3422\n",
            "Epoch 112/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8612 - loss: 0.4029 - val_accuracy: 0.5605 - val_loss: 2.3238\n",
            "Epoch 113/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8431 - loss: 0.4538 - val_accuracy: 0.5630 - val_loss: 2.3482\n",
            "Epoch 114/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8484 - loss: 0.4143 - val_accuracy: 0.5654 - val_loss: 2.3585\n",
            "Epoch 115/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.3981 - val_accuracy: 0.5481 - val_loss: 2.3889\n",
            "Epoch 116/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.4209 - val_accuracy: 0.5259 - val_loss: 2.4641\n",
            "Epoch 117/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.3794 - val_accuracy: 0.5432 - val_loss: 2.4430\n",
            "Epoch 118/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8710 - loss: 0.3601 - val_accuracy: 0.5531 - val_loss: 2.3946\n",
            "Epoch 119/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.3635 - val_accuracy: 0.5679 - val_loss: 2.4443\n",
            "Epoch 120/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 0.3940 - val_accuracy: 0.5432 - val_loss: 2.4072\n",
            "Epoch 121/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8612 - loss: 0.4044 - val_accuracy: 0.5210 - val_loss: 2.4875\n",
            "Epoch 122/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.3979 - val_accuracy: 0.5630 - val_loss: 2.4201\n",
            "Epoch 123/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3850 - val_accuracy: 0.5728 - val_loss: 2.4202\n",
            "Epoch 124/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8515 - loss: 0.3989 - val_accuracy: 0.5753 - val_loss: 2.5597\n",
            "Epoch 125/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.3675 - val_accuracy: 0.5407 - val_loss: 2.4422\n",
            "Epoch 126/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.3756 - val_accuracy: 0.5580 - val_loss: 2.4697\n",
            "Epoch 127/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.3675 - val_accuracy: 0.5506 - val_loss: 2.5342\n",
            "Epoch 128/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8882 - loss: 0.3501 - val_accuracy: 0.5432 - val_loss: 2.6965\n",
            "Epoch 129/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8753 - loss: 0.3624 - val_accuracy: 0.5630 - val_loss: 2.6108\n",
            "Epoch 130/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8677 - loss: 0.3847 - val_accuracy: 0.5556 - val_loss: 2.5062\n",
            "Epoch 131/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8492 - loss: 0.3801 - val_accuracy: 0.5605 - val_loss: 2.5873\n",
            "Epoch 132/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8814 - loss: 0.3654 - val_accuracy: 0.5630 - val_loss: 2.6710\n",
            "Epoch 133/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8715 - loss: 0.3571 - val_accuracy: 0.5432 - val_loss: 2.6446\n",
            "Epoch 134/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8896 - loss: 0.3341 - val_accuracy: 0.5309 - val_loss: 2.7288\n",
            "Epoch 135/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8648 - loss: 0.3572 - val_accuracy: 0.5605 - val_loss: 2.6265\n",
            "Epoch 136/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8661 - loss: 0.3689 - val_accuracy: 0.5481 - val_loss: 2.5442\n",
            "Epoch 137/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8682 - loss: 0.3381 - val_accuracy: 0.5457 - val_loss: 2.6423\n",
            "Epoch 138/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8791 - loss: 0.3213 - val_accuracy: 0.5383 - val_loss: 2.6619\n",
            "Epoch 139/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8772 - loss: 0.3502 - val_accuracy: 0.5457 - val_loss: 2.7193\n",
            "Epoch 140/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8856 - loss: 0.3044 - val_accuracy: 0.5481 - val_loss: 2.6247\n",
            "Epoch 141/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8806 - loss: 0.3218 - val_accuracy: 0.5654 - val_loss: 2.6109\n",
            "Epoch 142/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8924 - loss: 0.3275 - val_accuracy: 0.5679 - val_loss: 2.6962\n",
            "Epoch 143/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8858 - loss: 0.3219 - val_accuracy: 0.5531 - val_loss: 2.7092\n",
            "Epoch 144/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3606 - val_accuracy: 0.5556 - val_loss: 2.7490\n",
            "Epoch 145/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8898 - loss: 0.3086 - val_accuracy: 0.5654 - val_loss: 2.7394\n",
            "Epoch 146/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.3058 - val_accuracy: 0.5531 - val_loss: 2.6370\n",
            "Epoch 147/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.3455 - val_accuracy: 0.5679 - val_loss: 2.7180\n",
            "Epoch 148/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8975 - loss: 0.3004 - val_accuracy: 0.5556 - val_loss: 2.7968\n",
            "Epoch 149/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8878 - loss: 0.3181 - val_accuracy: 0.5506 - val_loss: 2.8423\n",
            "Epoch 150/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8788 - loss: 0.3442 - val_accuracy: 0.5728 - val_loss: 2.7559\n",
            "Epoch 151/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8885 - loss: 0.2996 - val_accuracy: 0.5580 - val_loss: 2.7939\n",
            "Epoch 152/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8916 - loss: 0.3094 - val_accuracy: 0.5580 - val_loss: 2.8601\n",
            "Epoch 153/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.2972 - val_accuracy: 0.5432 - val_loss: 2.9032\n",
            "Epoch 154/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8973 - loss: 0.2660 - val_accuracy: 0.5679 - val_loss: 2.8958\n",
            "Epoch 155/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8885 - loss: 0.3094 - val_accuracy: 0.5506 - val_loss: 2.8706\n",
            "Epoch 156/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8839 - loss: 0.2916 - val_accuracy: 0.5654 - val_loss: 2.8039\n",
            "Epoch 157/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9145 - loss: 0.2626 - val_accuracy: 0.5605 - val_loss: 2.8812\n",
            "Epoch 158/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9042 - loss: 0.2816 - val_accuracy: 0.5457 - val_loss: 2.8123\n",
            "Epoch 159/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9060 - loss: 0.2746 - val_accuracy: 0.5531 - val_loss: 2.8608\n",
            "Epoch 160/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8919 - loss: 0.2907 - val_accuracy: 0.5556 - val_loss: 2.8024\n",
            "Epoch 161/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8902 - loss: 0.3070 - val_accuracy: 0.5407 - val_loss: 2.8562\n",
            "Epoch 162/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.2787 - val_accuracy: 0.5531 - val_loss: 2.8905\n",
            "Epoch 163/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.2787 - val_accuracy: 0.5457 - val_loss: 2.8968\n",
            "Epoch 164/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.3132 - val_accuracy: 0.5654 - val_loss: 2.8772\n",
            "Epoch 165/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.3175 - val_accuracy: 0.5630 - val_loss: 2.7274\n",
            "Epoch 166/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8875 - loss: 0.2983 - val_accuracy: 0.5556 - val_loss: 2.9868\n",
            "Epoch 167/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9014 - loss: 0.2808 - val_accuracy: 0.5556 - val_loss: 2.9657\n",
            "Epoch 168/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9043 - loss: 0.2766 - val_accuracy: 0.5481 - val_loss: 2.9633\n",
            "Epoch 169/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8982 - loss: 0.2914 - val_accuracy: 0.5654 - val_loss: 2.9323\n",
            "Epoch 170/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8888 - loss: 0.3113 - val_accuracy: 0.5556 - val_loss: 2.9440\n",
            "Epoch 171/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8955 - loss: 0.2773 - val_accuracy: 0.5728 - val_loss: 2.9134\n",
            "Epoch 172/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8967 - loss: 0.2738 - val_accuracy: 0.5630 - val_loss: 3.0281\n",
            "Epoch 173/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8827 - loss: 0.2921 - val_accuracy: 0.5506 - val_loss: 2.9206\n",
            "Epoch 174/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8870 - loss: 0.3021 - val_accuracy: 0.5580 - val_loss: 2.9312\n",
            "Epoch 175/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.2642 - val_accuracy: 0.5457 - val_loss: 3.1992\n",
            "Epoch 176/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.2656 - val_accuracy: 0.5531 - val_loss: 3.0301\n",
            "Epoch 177/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9050 - loss: 0.2833 - val_accuracy: 0.5481 - val_loss: 3.1097\n",
            "Epoch 178/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9033 - loss: 0.2828 - val_accuracy: 0.5630 - val_loss: 3.0893\n",
            "Epoch 179/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9013 - loss: 0.2538 - val_accuracy: 0.5728 - val_loss: 3.1552\n",
            "Epoch 180/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8995 - loss: 0.2612 - val_accuracy: 0.5481 - val_loss: 3.2086\n",
            "Epoch 181/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9048 - loss: 0.2600 - val_accuracy: 0.5679 - val_loss: 3.2558\n",
            "Epoch 182/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8986 - loss: 0.2806 - val_accuracy: 0.5383 - val_loss: 3.1742\n",
            "Epoch 183/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9058 - loss: 0.2432 - val_accuracy: 0.5556 - val_loss: 3.2462\n",
            "Epoch 184/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8993 - loss: 0.2635 - val_accuracy: 0.5580 - val_loss: 3.2028\n",
            "Epoch 185/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8876 - loss: 0.2794 - val_accuracy: 0.5753 - val_loss: 3.1476\n",
            "Epoch 186/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9019 - loss: 0.2728 - val_accuracy: 0.5605 - val_loss: 3.1705\n",
            "Epoch 187/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.2487 - val_accuracy: 0.5605 - val_loss: 3.1675\n",
            "Epoch 188/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2595 - val_accuracy: 0.5704 - val_loss: 3.2709\n",
            "Epoch 189/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.2472 - val_accuracy: 0.5481 - val_loss: 3.1639\n",
            "Epoch 190/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.2500 - val_accuracy: 0.5531 - val_loss: 3.2313\n",
            "Epoch 191/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.2473 - val_accuracy: 0.5654 - val_loss: 3.2023\n",
            "Epoch 192/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.2745 - val_accuracy: 0.5259 - val_loss: 3.3107\n",
            "Epoch 193/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8933 - loss: 0.2520 - val_accuracy: 0.5531 - val_loss: 3.0892\n",
            "Epoch 194/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9135 - loss: 0.2490 - val_accuracy: 0.5457 - val_loss: 3.2389\n",
            "Epoch 195/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9239 - loss: 0.2243 - val_accuracy: 0.5432 - val_loss: 3.3580\n",
            "Epoch 196/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9233 - loss: 0.2209 - val_accuracy: 0.5556 - val_loss: 3.3210\n",
            "Epoch 197/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9110 - loss: 0.2314 - val_accuracy: 0.5580 - val_loss: 3.2566\n",
            "Epoch 198/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9246 - loss: 0.2305 - val_accuracy: 0.5630 - val_loss: 3.4513\n",
            "Epoch 199/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9039 - loss: 0.2439 - val_accuracy: 0.5407 - val_loss: 3.3108\n",
            "Epoch 200/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9061 - loss: 0.2389 - val_accuracy: 0.5531 - val_loss: 3.5021\n",
            "Epoch 201/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9160 - loss: 0.2359 - val_accuracy: 0.5605 - val_loss: 3.3479\n",
            "Epoch 202/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.2351 - val_accuracy: 0.5679 - val_loss: 3.3760\n",
            "Epoch 203/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9003 - loss: 0.2664 - val_accuracy: 0.5704 - val_loss: 3.3134\n",
            "Epoch 204/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9135 - loss: 0.2341 - val_accuracy: 0.5556 - val_loss: 3.4058\n",
            "Epoch 205/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9239 - loss: 0.2126 - val_accuracy: 0.5827 - val_loss: 3.3010\n",
            "Epoch 206/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9150 - loss: 0.2172 - val_accuracy: 0.5778 - val_loss: 3.1932\n",
            "Epoch 207/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.2434 - val_accuracy: 0.5580 - val_loss: 3.4466\n",
            "Epoch 208/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9085 - loss: 0.2423 - val_accuracy: 0.5506 - val_loss: 3.3920\n",
            "Epoch 209/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9134 - loss: 0.2525 - val_accuracy: 0.5457 - val_loss: 3.3571\n",
            "Epoch 210/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.2533 - val_accuracy: 0.5358 - val_loss: 3.3805\n",
            "Epoch 211/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2247 - val_accuracy: 0.5679 - val_loss: 3.3807\n",
            "Epoch 212/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9062 - loss: 0.2480 - val_accuracy: 0.5654 - val_loss: 3.4878\n",
            "Epoch 213/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.2203 - val_accuracy: 0.5580 - val_loss: 3.3933\n",
            "Epoch 214/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9167 - loss: 0.2177 - val_accuracy: 0.5605 - val_loss: 3.4308\n",
            "Epoch 215/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9159 - loss: 0.2179 - val_accuracy: 0.5531 - val_loss: 3.3479\n",
            "Epoch 216/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9177 - loss: 0.2432 - val_accuracy: 0.5309 - val_loss: 3.5099\n",
            "Epoch 217/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9054 - loss: 0.2476 - val_accuracy: 0.5704 - val_loss: 3.4601\n",
            "Epoch 218/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.2236 - val_accuracy: 0.5679 - val_loss: 3.5622\n",
            "Epoch 219/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9042 - loss: 0.2433 - val_accuracy: 0.5531 - val_loss: 3.5675\n",
            "Epoch 220/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9016 - loss: 0.2403 - val_accuracy: 0.5556 - val_loss: 3.6027\n",
            "Epoch 221/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9182 - loss: 0.2177 - val_accuracy: 0.5506 - val_loss: 3.5932\n",
            "Epoch 222/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9135 - loss: 0.2234 - val_accuracy: 0.5531 - val_loss: 3.6331\n",
            "Epoch 223/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9094 - loss: 0.2288 - val_accuracy: 0.5728 - val_loss: 3.6429\n",
            "Epoch 224/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9200 - loss: 0.2224 - val_accuracy: 0.5556 - val_loss: 3.5808\n",
            "Epoch 225/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9231 - loss: 0.2004 - val_accuracy: 0.5531 - val_loss: 3.5852\n",
            "Epoch 226/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9128 - loss: 0.2230 - val_accuracy: 0.5580 - val_loss: 3.5438\n",
            "Epoch 227/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9081 - loss: 0.2225 - val_accuracy: 0.5432 - val_loss: 3.6364\n",
            "Epoch 228/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9143 - loss: 0.2253 - val_accuracy: 0.5481 - val_loss: 3.7100\n",
            "Epoch 229/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9284 - loss: 0.2029 - val_accuracy: 0.5531 - val_loss: 3.6156\n",
            "Epoch 230/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9036 - loss: 0.2481 - val_accuracy: 0.5457 - val_loss: 3.7074\n",
            "Epoch 231/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9001 - loss: 0.2567 - val_accuracy: 0.5654 - val_loss: 3.6548\n",
            "Epoch 232/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9127 - loss: 0.2220 - val_accuracy: 0.5605 - val_loss: 3.5802\n",
            "Epoch 233/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9377 - loss: 0.1887 - val_accuracy: 0.5556 - val_loss: 3.6809\n",
            "Epoch 234/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9242 - loss: 0.2197 - val_accuracy: 0.5580 - val_loss: 3.6392\n",
            "Epoch 235/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9349 - loss: 0.1947 - val_accuracy: 0.5654 - val_loss: 3.5747\n",
            "Epoch 236/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9212 - loss: 0.2040 - val_accuracy: 0.5457 - val_loss: 3.6335\n",
            "Epoch 237/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9204 - loss: 0.2091 - val_accuracy: 0.5605 - val_loss: 3.7006\n",
            "Epoch 238/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9328 - loss: 0.2006 - val_accuracy: 0.5531 - val_loss: 3.7494\n",
            "Epoch 239/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9073 - loss: 0.2306 - val_accuracy: 0.5630 - val_loss: 3.7875\n",
            "Epoch 240/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9184 - loss: 0.2201 - val_accuracy: 0.5556 - val_loss: 3.6937\n",
            "Epoch 241/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.2068 - val_accuracy: 0.5580 - val_loss: 3.6843\n",
            "Epoch 242/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9072 - loss: 0.2396 - val_accuracy: 0.5506 - val_loss: 3.8231\n",
            "Epoch 243/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.1971 - val_accuracy: 0.5358 - val_loss: 3.7912\n",
            "Epoch 244/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.2099 - val_accuracy: 0.5605 - val_loss: 3.7805\n",
            "Epoch 245/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9301 - loss: 0.2144 - val_accuracy: 0.5556 - val_loss: 3.5805\n",
            "Epoch 246/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.2351 - val_accuracy: 0.5531 - val_loss: 3.7980\n",
            "Epoch 247/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9156 - loss: 0.2035 - val_accuracy: 0.5457 - val_loss: 3.8543\n",
            "Epoch 248/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9190 - loss: 0.2039 - val_accuracy: 0.5457 - val_loss: 3.8338\n",
            "Epoch 249/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9244 - loss: 0.2116 - val_accuracy: 0.5531 - val_loss: 3.6784\n",
            "Epoch 250/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2124 - val_accuracy: 0.5407 - val_loss: 3.8649\n",
            "Epoch 251/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.2060 - val_accuracy: 0.5605 - val_loss: 3.7891\n",
            "Epoch 252/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9407 - loss: 0.1647 - val_accuracy: 0.5654 - val_loss: 3.9901\n",
            "Epoch 253/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2063 - val_accuracy: 0.5383 - val_loss: 3.8177\n",
            "Epoch 254/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.2214 - val_accuracy: 0.5358 - val_loss: 3.7752\n",
            "Epoch 255/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.1915 - val_accuracy: 0.5457 - val_loss: 3.8060\n",
            "Epoch 256/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.2219 - val_accuracy: 0.5481 - val_loss: 3.8338\n",
            "Epoch 257/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9245 - loss: 0.1962 - val_accuracy: 0.5605 - val_loss: 3.9156\n",
            "Epoch 258/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9255 - loss: 0.1949 - val_accuracy: 0.5556 - val_loss: 3.9431\n",
            "Epoch 259/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9182 - loss: 0.2131 - val_accuracy: 0.5506 - val_loss: 3.9836\n",
            "Epoch 260/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9253 - loss: 0.2014 - val_accuracy: 0.5630 - val_loss: 4.0393\n",
            "Epoch 261/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9207 - loss: 0.2096 - val_accuracy: 0.5556 - val_loss: 3.7983\n",
            "Epoch 262/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9127 - loss: 0.2029 - val_accuracy: 0.5580 - val_loss: 3.9011\n",
            "Epoch 263/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.2067 - val_accuracy: 0.5481 - val_loss: 3.8273\n",
            "Epoch 264/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9366 - loss: 0.1802 - val_accuracy: 0.5457 - val_loss: 4.0959\n",
            "Epoch 265/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.2003 - val_accuracy: 0.5580 - val_loss: 4.0288\n",
            "Epoch 266/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.1889 - val_accuracy: 0.5556 - val_loss: 4.0388\n",
            "Epoch 267/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2120 - val_accuracy: 0.5556 - val_loss: 3.9909\n",
            "Epoch 268/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.1966 - val_accuracy: 0.5506 - val_loss: 3.8723\n",
            "Epoch 269/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.1823 - val_accuracy: 0.5333 - val_loss: 3.9130\n",
            "Epoch 270/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9397 - loss: 0.1781 - val_accuracy: 0.5556 - val_loss: 3.9768\n",
            "Epoch 271/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.2071 - val_accuracy: 0.5432 - val_loss: 4.0018\n",
            "Epoch 272/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.1974 - val_accuracy: 0.5630 - val_loss: 3.9325\n",
            "Epoch 273/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2054 - val_accuracy: 0.5506 - val_loss: 4.0280\n",
            "Epoch 274/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1541 - val_accuracy: 0.5679 - val_loss: 4.1534\n",
            "Epoch 275/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9314 - loss: 0.1952 - val_accuracy: 0.5309 - val_loss: 4.1272\n",
            "Epoch 276/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9303 - loss: 0.1986 - val_accuracy: 0.5556 - val_loss: 3.9924\n",
            "Epoch 277/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2259 - val_accuracy: 0.5556 - val_loss: 4.1469\n",
            "Epoch 278/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2182 - val_accuracy: 0.5407 - val_loss: 4.1028\n",
            "Epoch 279/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.1998 - val_accuracy: 0.5481 - val_loss: 4.1091\n",
            "Epoch 280/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9316 - loss: 0.1857 - val_accuracy: 0.5432 - val_loss: 3.9931\n",
            "Epoch 281/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9128 - loss: 0.2164 - val_accuracy: 0.5704 - val_loss: 4.1374\n",
            "Epoch 282/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9173 - loss: 0.1929 - val_accuracy: 0.5383 - val_loss: 4.3799\n",
            "Epoch 283/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.1926 - val_accuracy: 0.5407 - val_loss: 4.1899\n",
            "Epoch 284/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.2035 - val_accuracy: 0.5531 - val_loss: 4.1727\n",
            "Epoch 285/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.1691 - val_accuracy: 0.5605 - val_loss: 4.2444\n",
            "Epoch 286/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.2113 - val_accuracy: 0.5407 - val_loss: 4.1432\n",
            "Epoch 287/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9374 - loss: 0.1795 - val_accuracy: 0.5605 - val_loss: 4.1602\n",
            "Epoch 288/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.1861 - val_accuracy: 0.5531 - val_loss: 4.1942\n",
            "Epoch 289/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2242 - val_accuracy: 0.5654 - val_loss: 4.3033\n",
            "Epoch 290/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1920 - val_accuracy: 0.5605 - val_loss: 4.1128\n",
            "Epoch 291/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9311 - loss: 0.1875 - val_accuracy: 0.5358 - val_loss: 4.3175\n",
            "Epoch 292/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.1720 - val_accuracy: 0.5580 - val_loss: 4.2268\n",
            "Epoch 293/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9268 - loss: 0.1966 - val_accuracy: 0.5556 - val_loss: 4.2702\n",
            "Epoch 294/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.1680 - val_accuracy: 0.5432 - val_loss: 4.1864\n",
            "Epoch 295/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9329 - loss: 0.1792 - val_accuracy: 0.5654 - val_loss: 4.3364\n",
            "Epoch 296/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9371 - loss: 0.1874 - val_accuracy: 0.5531 - val_loss: 4.3663\n",
            "Epoch 297/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9398 - loss: 0.1548 - val_accuracy: 0.5457 - val_loss: 4.2927\n",
            "Epoch 298/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9343 - loss: 0.1662 - val_accuracy: 0.5457 - val_loss: 4.3200\n",
            "Epoch 299/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9416 - loss: 0.1639 - val_accuracy: 0.5556 - val_loss: 4.3448\n",
            "Epoch 300/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9298 - loss: 0.2078 - val_accuracy: 0.5481 - val_loss: 4.4539\n",
            "Epoch 301/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9294 - loss: 0.1993 - val_accuracy: 0.5556 - val_loss: 4.4091\n",
            "Epoch 302/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9374 - loss: 0.1699 - val_accuracy: 0.5580 - val_loss: 4.3388\n",
            "Epoch 303/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9131 - loss: 0.2237 - val_accuracy: 0.5432 - val_loss: 4.3299\n",
            "Epoch 304/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1649 - val_accuracy: 0.5654 - val_loss: 4.2931\n",
            "Epoch 305/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.1818 - val_accuracy: 0.5457 - val_loss: 4.3775\n",
            "Epoch 306/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9367 - loss: 0.1673 - val_accuracy: 0.5679 - val_loss: 4.2961\n",
            "Epoch 307/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9410 - loss: 0.1547 - val_accuracy: 0.5679 - val_loss: 4.2059\n",
            "Epoch 308/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1502 - val_accuracy: 0.5556 - val_loss: 4.3122\n",
            "Epoch 309/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9285 - loss: 0.1781 - val_accuracy: 0.5309 - val_loss: 4.2830\n",
            "Epoch 310/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.1873 - val_accuracy: 0.5457 - val_loss: 4.3113\n",
            "Epoch 311/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.1970 - val_accuracy: 0.5457 - val_loss: 4.2463\n",
            "Epoch 312/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.1932 - val_accuracy: 0.5481 - val_loss: 4.4556\n",
            "Epoch 313/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1669 - val_accuracy: 0.5457 - val_loss: 4.2508\n",
            "Epoch 314/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.1583 - val_accuracy: 0.5630 - val_loss: 4.2327\n",
            "Epoch 315/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2075 - val_accuracy: 0.5580 - val_loss: 4.3978\n",
            "Epoch 316/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9323 - loss: 0.1660 - val_accuracy: 0.5383 - val_loss: 4.5857\n",
            "Epoch 317/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2043 - val_accuracy: 0.5358 - val_loss: 4.4354\n",
            "Epoch 318/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2174 - val_accuracy: 0.5284 - val_loss: 4.5196\n",
            "Epoch 319/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.1642 - val_accuracy: 0.5457 - val_loss: 4.3971\n",
            "Epoch 320/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9369 - loss: 0.1566 - val_accuracy: 0.5309 - val_loss: 4.5779\n",
            "Epoch 321/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.1629 - val_accuracy: 0.5556 - val_loss: 4.4823\n",
            "Epoch 322/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.1664 - val_accuracy: 0.5432 - val_loss: 4.5618\n",
            "Epoch 323/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.1841 - val_accuracy: 0.5580 - val_loss: 4.4375\n",
            "Epoch 324/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.1496 - val_accuracy: 0.5506 - val_loss: 4.5206\n",
            "Epoch 325/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.1947 - val_accuracy: 0.5309 - val_loss: 4.6165\n",
            "Epoch 326/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.1801 - val_accuracy: 0.5407 - val_loss: 4.7769\n",
            "Epoch 327/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9245 - loss: 0.2127 - val_accuracy: 0.5481 - val_loss: 4.4887\n",
            "Epoch 328/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9287 - loss: 0.1892 - val_accuracy: 0.5284 - val_loss: 4.8267\n",
            "Epoch 329/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.1922 - val_accuracy: 0.5457 - val_loss: 4.6214\n",
            "Epoch 330/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.2008 - val_accuracy: 0.5531 - val_loss: 4.6302\n",
            "Epoch 331/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1570 - val_accuracy: 0.5506 - val_loss: 4.6568\n",
            "Epoch 332/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.1613 - val_accuracy: 0.5457 - val_loss: 4.7909\n",
            "Epoch 333/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1484 - val_accuracy: 0.5506 - val_loss: 4.6998\n",
            "Epoch 334/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9448 - loss: 0.1440 - val_accuracy: 0.5333 - val_loss: 4.7303\n",
            "Epoch 335/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9381 - loss: 0.1879 - val_accuracy: 0.5481 - val_loss: 4.6145\n",
            "Epoch 336/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9465 - loss: 0.1555 - val_accuracy: 0.5506 - val_loss: 4.7647\n",
            "Epoch 337/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9393 - loss: 0.1595 - val_accuracy: 0.5506 - val_loss: 4.9551\n",
            "Epoch 338/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9507 - loss: 0.1331 - val_accuracy: 0.5432 - val_loss: 4.9659\n",
            "Epoch 339/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9440 - loss: 0.1397 - val_accuracy: 0.5358 - val_loss: 4.9086\n",
            "Epoch 340/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.1570 - val_accuracy: 0.5383 - val_loss: 4.7411\n",
            "Epoch 341/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1444 - val_accuracy: 0.5605 - val_loss: 4.9156\n",
            "Epoch 342/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9457 - loss: 0.1642 - val_accuracy: 0.5407 - val_loss: 4.7267\n",
            "Epoch 343/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9338 - loss: 0.1741 - val_accuracy: 0.5531 - val_loss: 4.6463\n",
            "Epoch 344/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1523 - val_accuracy: 0.5506 - val_loss: 4.7634\n",
            "Epoch 345/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.1276 - val_accuracy: 0.5506 - val_loss: 4.7668\n",
            "Epoch 346/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.1581 - val_accuracy: 0.5407 - val_loss: 4.8819\n",
            "Epoch 347/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.1502 - val_accuracy: 0.5630 - val_loss: 4.6839\n",
            "Epoch 348/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.1861 - val_accuracy: 0.5728 - val_loss: 4.8274\n",
            "Epoch 349/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.2023 - val_accuracy: 0.5457 - val_loss: 4.7020\n",
            "Epoch 350/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9382 - loss: 0.1501 - val_accuracy: 0.5457 - val_loss: 4.8412\n",
            "Epoch 351/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9468 - loss: 0.1413 - val_accuracy: 0.5407 - val_loss: 4.9168\n",
            "Epoch 352/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1434 - val_accuracy: 0.5556 - val_loss: 4.8822\n",
            "Epoch 353/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9457 - loss: 0.1493 - val_accuracy: 0.5309 - val_loss: 4.9934\n",
            "Epoch 354/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 0.1521 - val_accuracy: 0.5556 - val_loss: 4.9846\n",
            "Epoch 355/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.1766 - val_accuracy: 0.5481 - val_loss: 4.8778\n",
            "Epoch 356/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.1926 - val_accuracy: 0.5358 - val_loss: 4.7983\n",
            "Epoch 357/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.1773 - val_accuracy: 0.5432 - val_loss: 4.8276\n",
            "Epoch 358/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.1677 - val_accuracy: 0.5333 - val_loss: 4.9483\n",
            "Epoch 359/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9487 - loss: 0.1418 - val_accuracy: 0.5383 - val_loss: 5.0505\n",
            "Epoch 360/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1728 - val_accuracy: 0.5235 - val_loss: 4.8003\n",
            "Epoch 361/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.1559 - val_accuracy: 0.5407 - val_loss: 4.7867\n",
            "Epoch 362/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.1927 - val_accuracy: 0.5531 - val_loss: 4.8390\n",
            "Epoch 363/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9514 - loss: 0.1248 - val_accuracy: 0.5185 - val_loss: 5.0598\n",
            "Epoch 364/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 0.1562 - val_accuracy: 0.5457 - val_loss: 4.8529\n",
            "Epoch 365/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.1538 - val_accuracy: 0.5432 - val_loss: 4.8344\n",
            "Epoch 366/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1493 - val_accuracy: 0.5556 - val_loss: 4.8423\n",
            "Epoch 367/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.1524 - val_accuracy: 0.5580 - val_loss: 4.8101\n",
            "Epoch 368/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9332 - loss: 0.1812 - val_accuracy: 0.5531 - val_loss: 4.8360\n",
            "Epoch 369/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.1684 - val_accuracy: 0.5531 - val_loss: 4.8884\n",
            "Epoch 370/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.1373 - val_accuracy: 0.5580 - val_loss: 4.9191\n",
            "Epoch 371/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9382 - loss: 0.1570 - val_accuracy: 0.5605 - val_loss: 5.0081\n",
            "Epoch 372/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.1449 - val_accuracy: 0.5457 - val_loss: 5.0360\n",
            "Epoch 373/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.1622 - val_accuracy: 0.5481 - val_loss: 5.0077\n",
            "Epoch 374/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9417 - loss: 0.1822 - val_accuracy: 0.5210 - val_loss: 5.3558\n",
            "Epoch 375/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9349 - loss: 0.1756 - val_accuracy: 0.5432 - val_loss: 5.1200\n",
            "Epoch 376/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9537 - loss: 0.1426 - val_accuracy: 0.5358 - val_loss: 5.0117\n",
            "Epoch 377/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9312 - loss: 0.1800 - val_accuracy: 0.5333 - val_loss: 5.1882\n",
            "Epoch 378/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9338 - loss: 0.1487 - val_accuracy: 0.5383 - val_loss: 5.1180\n",
            "Epoch 379/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9382 - loss: 0.1678 - val_accuracy: 0.5556 - val_loss: 5.0428\n",
            "Epoch 380/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.1887 - val_accuracy: 0.5235 - val_loss: 5.0169\n",
            "Epoch 381/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9331 - loss: 0.1555 - val_accuracy: 0.5432 - val_loss: 5.0480\n",
            "Epoch 382/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9321 - loss: 0.1705 - val_accuracy: 0.5407 - val_loss: 5.0798\n",
            "Epoch 383/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.1605 - val_accuracy: 0.5605 - val_loss: 5.0431\n",
            "Epoch 384/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9541 - loss: 0.1445 - val_accuracy: 0.5432 - val_loss: 5.0706\n",
            "Epoch 385/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.1267 - val_accuracy: 0.5432 - val_loss: 5.1678\n",
            "Epoch 386/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.1349 - val_accuracy: 0.5580 - val_loss: 5.0201\n",
            "Epoch 387/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1263 - val_accuracy: 0.5506 - val_loss: 5.0371\n",
            "Epoch 388/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.1337 - val_accuracy: 0.5531 - val_loss: 5.0081\n",
            "Epoch 389/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.1641 - val_accuracy: 0.5432 - val_loss: 4.9604\n",
            "Epoch 390/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.1490 - val_accuracy: 0.5235 - val_loss: 5.1596\n",
            "Epoch 391/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.1466 - val_accuracy: 0.5383 - val_loss: 5.1171\n",
            "Epoch 392/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9501 - loss: 0.1300 - val_accuracy: 0.5383 - val_loss: 5.3086\n",
            "Epoch 393/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9540 - loss: 0.1452 - val_accuracy: 0.5506 - val_loss: 5.2274\n",
            "Epoch 394/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.1615 - val_accuracy: 0.5432 - val_loss: 5.2153\n",
            "Epoch 395/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.1504 - val_accuracy: 0.5358 - val_loss: 5.2870\n",
            "Epoch 396/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.1605 - val_accuracy: 0.5481 - val_loss: 5.1518\n",
            "Epoch 397/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1317 - val_accuracy: 0.5556 - val_loss: 5.0523\n",
            "Epoch 398/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.1326 - val_accuracy: 0.5383 - val_loss: 5.0726\n",
            "Epoch 399/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.1438 - val_accuracy: 0.5531 - val_loss: 5.0753\n",
            "Epoch 400/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.1564 - val_accuracy: 0.5309 - val_loss: 5.1725\n",
            "Epoch 401/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.1677 - val_accuracy: 0.5383 - val_loss: 5.0653\n",
            "Epoch 402/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9524 - loss: 0.1338 - val_accuracy: 0.5457 - val_loss: 5.0424\n",
            "Epoch 403/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.1364 - val_accuracy: 0.5309 - val_loss: 5.1204\n",
            "Epoch 404/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9471 - loss: 0.1226 - val_accuracy: 0.5556 - val_loss: 5.2994\n",
            "Epoch 405/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9506 - loss: 0.1258 - val_accuracy: 0.5259 - val_loss: 5.1442\n",
            "Epoch 406/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1712 - val_accuracy: 0.5556 - val_loss: 5.0858\n",
            "Epoch 407/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.1636 - val_accuracy: 0.5457 - val_loss: 5.1306\n",
            "Epoch 408/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.1469 - val_accuracy: 0.5407 - val_loss: 5.3955\n",
            "Epoch 409/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9519 - loss: 0.1215 - val_accuracy: 0.5531 - val_loss: 5.1984\n",
            "Epoch 410/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1487 - val_accuracy: 0.5383 - val_loss: 5.0893\n",
            "Epoch 411/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.1777 - val_accuracy: 0.5580 - val_loss: 5.0725\n",
            "Epoch 412/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9498 - loss: 0.1488 - val_accuracy: 0.5679 - val_loss: 5.0437\n",
            "Epoch 413/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9363 - loss: 0.1520 - val_accuracy: 0.5556 - val_loss: 5.0392\n",
            "Epoch 414/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9448 - loss: 0.1445 - val_accuracy: 0.5605 - val_loss: 4.9249\n",
            "Epoch 415/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9412 - loss: 0.1407 - val_accuracy: 0.5481 - val_loss: 5.1079\n",
            "Epoch 416/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9340 - loss: 0.1705 - val_accuracy: 0.5333 - val_loss: 5.1593\n",
            "Epoch 417/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9387 - loss: 0.1432 - val_accuracy: 0.5432 - val_loss: 5.0112\n",
            "Epoch 418/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9400 - loss: 0.1613 - val_accuracy: 0.5383 - val_loss: 5.2684\n",
            "Epoch 419/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9576 - loss: 0.1423 - val_accuracy: 0.5259 - val_loss: 5.2702\n",
            "Epoch 420/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9493 - loss: 0.1591 - val_accuracy: 0.5284 - val_loss: 5.1789\n",
            "Epoch 421/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9420 - loss: 0.1681 - val_accuracy: 0.5284 - val_loss: 5.1988\n",
            "Epoch 422/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.1430 - val_accuracy: 0.5531 - val_loss: 5.3643\n",
            "Epoch 423/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9485 - loss: 0.1444 - val_accuracy: 0.5432 - val_loss: 5.1067\n",
            "Epoch 424/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9347 - loss: 0.1777 - val_accuracy: 0.5333 - val_loss: 4.9273\n",
            "Epoch 425/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9325 - loss: 0.1927 - val_accuracy: 0.5407 - val_loss: 5.0318\n",
            "Epoch 426/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9417 - loss: 0.1456 - val_accuracy: 0.5605 - val_loss: 5.1416\n",
            "Epoch 427/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9523 - loss: 0.1212 - val_accuracy: 0.5259 - val_loss: 5.3137\n",
            "Epoch 428/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9587 - loss: 0.1172 - val_accuracy: 0.5383 - val_loss: 5.4081\n",
            "Epoch 429/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.1445 - val_accuracy: 0.5309 - val_loss: 5.2355\n",
            "Epoch 430/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9341 - loss: 0.1499 - val_accuracy: 0.5160 - val_loss: 5.3554\n",
            "Epoch 431/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.1863 - val_accuracy: 0.5284 - val_loss: 5.4012\n",
            "Epoch 432/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.1530 - val_accuracy: 0.5432 - val_loss: 5.3500\n",
            "Epoch 433/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9330 - loss: 0.1557 - val_accuracy: 0.5506 - val_loss: 5.2783\n",
            "Epoch 434/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9430 - loss: 0.1633 - val_accuracy: 0.5358 - val_loss: 5.4095\n",
            "Epoch 435/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.1615 - val_accuracy: 0.5457 - val_loss: 5.5489\n",
            "Epoch 436/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.1381 - val_accuracy: 0.5457 - val_loss: 5.4618\n",
            "Epoch 437/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9390 - loss: 0.1442 - val_accuracy: 0.5210 - val_loss: 5.3798\n",
            "Epoch 438/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1536 - val_accuracy: 0.5580 - val_loss: 5.2189\n",
            "Epoch 439/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.1275 - val_accuracy: 0.5481 - val_loss: 5.0972\n",
            "Epoch 440/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.1247 - val_accuracy: 0.5333 - val_loss: 5.1278\n",
            "Epoch 441/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9600 - loss: 0.1041 - val_accuracy: 0.5556 - val_loss: 5.2686\n",
            "Epoch 442/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.1441 - val_accuracy: 0.5309 - val_loss: 5.5345\n",
            "Epoch 443/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.1704 - val_accuracy: 0.5556 - val_loss: 5.5167\n",
            "Epoch 444/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9489 - loss: 0.1274 - val_accuracy: 0.5457 - val_loss: 5.4730\n",
            "Epoch 445/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9554 - loss: 0.1137 - val_accuracy: 0.5506 - val_loss: 5.4167\n",
            "Epoch 446/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9429 - loss: 0.1649 - val_accuracy: 0.5506 - val_loss: 5.4921\n",
            "Epoch 447/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9553 - loss: 0.1203 - val_accuracy: 0.5333 - val_loss: 5.6057\n",
            "Epoch 448/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9417 - loss: 0.1608 - val_accuracy: 0.5185 - val_loss: 5.7016\n",
            "Epoch 449/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9478 - loss: 0.1347 - val_accuracy: 0.5383 - val_loss: 5.3688\n",
            "Epoch 450/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9466 - loss: 0.1327 - val_accuracy: 0.5506 - val_loss: 5.6031\n",
            "Epoch 451/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1387 - val_accuracy: 0.5333 - val_loss: 5.4591\n",
            "Epoch 452/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9562 - loss: 0.1135 - val_accuracy: 0.5432 - val_loss: 5.4853\n",
            "Epoch 453/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9564 - loss: 0.1202 - val_accuracy: 0.5333 - val_loss: 5.4925\n",
            "Epoch 454/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9439 - loss: 0.1459 - val_accuracy: 0.5333 - val_loss: 5.5150\n",
            "Epoch 455/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1350 - val_accuracy: 0.5580 - val_loss: 5.3540\n",
            "Epoch 456/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.1448 - val_accuracy: 0.5358 - val_loss: 5.4938\n",
            "Epoch 457/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9551 - loss: 0.1288 - val_accuracy: 0.5432 - val_loss: 5.6263\n",
            "Epoch 458/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9340 - loss: 0.1571 - val_accuracy: 0.5457 - val_loss: 5.5131\n",
            "Epoch 459/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9529 - loss: 0.1414 - val_accuracy: 0.5358 - val_loss: 5.3347\n",
            "Epoch 460/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9599 - loss: 0.1131 - val_accuracy: 0.5481 - val_loss: 5.5690\n",
            "Epoch 461/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9520 - loss: 0.1350 - val_accuracy: 0.5432 - val_loss: 5.8228\n",
            "Epoch 462/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.1337 - val_accuracy: 0.5210 - val_loss: 5.7412\n",
            "Epoch 463/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9497 - loss: 0.1420 - val_accuracy: 0.5457 - val_loss: 5.6198\n",
            "Epoch 464/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 0.1200 - val_accuracy: 0.5284 - val_loss: 5.6694\n",
            "Epoch 465/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.1594 - val_accuracy: 0.5358 - val_loss: 5.5979\n",
            "Epoch 466/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1052 - val_accuracy: 0.5210 - val_loss: 5.6166\n",
            "Epoch 467/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9524 - loss: 0.1169 - val_accuracy: 0.5284 - val_loss: 5.7075\n",
            "Epoch 468/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.1627 - val_accuracy: 0.5210 - val_loss: 5.9114\n",
            "Epoch 469/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9522 - loss: 0.1194 - val_accuracy: 0.5383 - val_loss: 5.6893\n",
            "Epoch 470/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.1315 - val_accuracy: 0.5333 - val_loss: 5.8880\n",
            "Epoch 471/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9276 - loss: 0.1812 - val_accuracy: 0.5284 - val_loss: 5.9769\n",
            "Epoch 472/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9444 - loss: 0.1565 - val_accuracy: 0.5383 - val_loss: 5.7394\n",
            "Epoch 473/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.1689 - val_accuracy: 0.5210 - val_loss: 5.9758\n",
            "Epoch 474/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9281 - loss: 0.1776 - val_accuracy: 0.5457 - val_loss: 5.7238\n",
            "Epoch 475/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.1259 - val_accuracy: 0.5284 - val_loss: 5.5940\n",
            "Epoch 476/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1389 - val_accuracy: 0.5383 - val_loss: 5.5035\n",
            "Epoch 477/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1264 - val_accuracy: 0.5210 - val_loss: 5.6672\n",
            "Epoch 478/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9462 - loss: 0.1340 - val_accuracy: 0.5333 - val_loss: 5.7498\n",
            "Epoch 479/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1111 - val_accuracy: 0.5309 - val_loss: 5.7319\n",
            "Epoch 480/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9568 - loss: 0.1172 - val_accuracy: 0.5333 - val_loss: 5.6684\n",
            "Epoch 481/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1194 - val_accuracy: 0.5235 - val_loss: 5.6777\n",
            "Epoch 482/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9539 - loss: 0.1300 - val_accuracy: 0.5457 - val_loss: 5.6644\n",
            "Epoch 483/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9523 - loss: 0.1519 - val_accuracy: 0.5432 - val_loss: 5.9362\n",
            "Epoch 484/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9414 - loss: 0.1344 - val_accuracy: 0.5407 - val_loss: 5.7846\n",
            "Epoch 485/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9338 - loss: 0.1806 - val_accuracy: 0.5432 - val_loss: 5.5724\n",
            "Epoch 486/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1478 - val_accuracy: 0.5481 - val_loss: 5.9080\n",
            "Epoch 487/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9515 - loss: 0.1299 - val_accuracy: 0.5383 - val_loss: 5.8616\n",
            "Epoch 488/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1020 - val_accuracy: 0.5432 - val_loss: 5.8843\n",
            "Epoch 489/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9465 - loss: 0.1570 - val_accuracy: 0.5358 - val_loss: 5.6555\n",
            "Epoch 490/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9532 - loss: 0.1287 - val_accuracy: 0.5136 - val_loss: 5.7050\n",
            "Epoch 491/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9561 - loss: 0.1161 - val_accuracy: 0.5457 - val_loss: 5.4929\n",
            "Epoch 492/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9539 - loss: 0.1270 - val_accuracy: 0.5457 - val_loss: 5.5473\n",
            "Epoch 493/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.1392 - val_accuracy: 0.5383 - val_loss: 5.7656\n",
            "Epoch 494/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9541 - loss: 0.1398 - val_accuracy: 0.5210 - val_loss: 5.7666\n",
            "Epoch 495/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1274 - val_accuracy: 0.5235 - val_loss: 5.7600\n",
            "Epoch 496/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.1174 - val_accuracy: 0.5432 - val_loss: 5.8827\n",
            "Epoch 497/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.1271 - val_accuracy: 0.5309 - val_loss: 5.8684\n",
            "Epoch 498/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1404 - val_accuracy: 0.5259 - val_loss: 5.9659\n",
            "Epoch 499/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.1488 - val_accuracy: 0.5506 - val_loss: 5.7814\n",
            "Epoch 500/500\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9516 - loss: 0.1277 - val_accuracy: 0.5457 - val_loss: 6.0167\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CNN Model Performance:\n",
            "Test Accuracy: 0.5457\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          Axe       0.46      0.43      0.44        14\n",
            " BirdChirping       0.75      0.75      0.75        16\n",
            "     Chainsaw       0.48      0.73      0.58        15\n",
            "     Clapping       0.91      0.50      0.65        20\n",
            "         Fire       0.76      1.00      0.86        16\n",
            "     Firework       0.27      0.31      0.29        13\n",
            "    Footsteps       0.55      0.38      0.44        16\n",
            "         Frog       0.71      0.29      0.42        17\n",
            "    Generator       0.38      0.50      0.43        10\n",
            "      Gunshot       0.53      0.47      0.50        17\n",
            "      Handsaw       0.69      0.75      0.72        12\n",
            "   Helicopter       0.71      0.50      0.59        24\n",
            "       Insect       0.72      0.65      0.68        20\n",
            "         Lion       0.30      0.25      0.27        12\n",
            "         Rain       0.36      0.33      0.35        12\n",
            "      Silence       0.85      0.79      0.81        14\n",
            "     Speaking       0.61      0.58      0.59        19\n",
            "     Squirrel       0.38      0.53      0.44        17\n",
            " Thunderstorm       0.50      0.60      0.55        15\n",
            "  TreeFalling       0.71      0.45      0.56        11\n",
            "VehicleEngine       0.19      0.27      0.22        11\n",
            "   WaterDrops       0.59      0.67      0.62        15\n",
            "    Whistling       0.69      0.69      0.69        13\n",
            "         Wind       0.93      0.59      0.72        22\n",
            "  WingFlaping       0.19      0.19      0.19        16\n",
            "     WolfHowl       0.75      0.82      0.78        11\n",
            "     WoodChop       0.22      0.71      0.33         7\n",
            "\n",
            "     accuracy                           0.55       405\n",
            "    macro avg       0.56      0.55      0.54       405\n",
            " weighted avg       0.59      0.55      0.55       405\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  8]\n",
            " [ 0 12  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0\n",
            "   0  0  0]\n",
            " [ 0  0 11  1  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  1  0  0  0\n",
            "   0  0  0]\n",
            " [ 2  0  0 10  0  2  0  0  0  2  2  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
            "   0  0  1]\n",
            " [ 0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 3  1  0  0  0  4  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  0\n",
            "   0  0  1]\n",
            " [ 1  0  0  0  1  3  6  0  0  0  0  0  1  0  0  0  0  0  0  1  0  1  0  0\n",
            "   1  0  1]\n",
            " [ 0  0  0  0  0  0  1  5  1  1  0  2  1  0  0  0  0  2  0  0  0  1  2  0\n",
            "   0  1  0]\n",
            " [ 0  0  2  0  0  0  0  0  5  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0\n",
            "   0  1  0]\n",
            " [ 1  0  1  0  0  0  0  0  2  8  1  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
            "   1  0  2]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   2  0  0]\n",
            " [ 0  1  0  0  0  1  0  0  1  0  0 12  0  0  0  0  2  1  1  0  4  0  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  1  0  0  0  0  1  1  0  0  0 13  1  0  0  0  2  1  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  3  0  0  2  0  2  0  0  1  0  0\n",
            "   0  1  2]\n",
            " [ 0  0  3  0  1  0  0  0  0  0  0  0  0  0  4  2  0  0  1  0  0  1  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  1  0  1 11  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  0  1  0  2  1  0 11  1  0  0  0  0  1  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  9  0  0  1  2  0  0\n",
            "   3  0  0]\n",
            " [ 0  0  0  0  0  2  1  0  0  0  1  0  0  0  0  0  0  1  9  0  1  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  5  0  0  0  0\n",
            "   2  0  1]\n",
            " [ 0  2  1  0  0  0  0  0  2  0  0  0  0  0  0  0  0  2  0  0  3  0  0  0\n",
            "   1  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 10  0  0\n",
            "   2  0  1]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  1  0  0  1  0  9  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  3  0  1  1  1  0  1  0  0 13\n",
            "   1  0  0]\n",
            " [ 0  0  1  0  1  1  2  0  0  1  0  0  0  0  1  0  0  1  2  0  2  0  0  0\n",
            "   3  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0\n",
            "   0  9  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
            "   0  0  5]]\n",
            "\n",
            "Best CNN model saved as 'best_cnn_model.h5'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for RNN (reshape to 3D as required for LSTM input)\n",
        "X_train_rnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_rnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Build the RNN Model using LSTM\n",
        "def create_rnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # LSTM Layer\n",
        "    model.add(layers.LSTM(128, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Second LSTM Layer\n",
        "    model.add(layers.LSTM(64))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Fully Connected Output Layer\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define input shape for RNN\n",
        "input_shape_rnn = (X_train_rnn.shape[1], X_train_rnn.shape[2])\n",
        "\n",
        "# Create and train the RNN model\n",
        "rnn_model = create_rnn_model(input_shape_rnn, num_classes)\n",
        "print(\"Training RNN...\")\n",
        "rnn_model.fit(X_train_rnn, y_train, epochs=100, batch_size=32, validation_data=(X_test_rnn, y_test))\n",
        "\n",
        "# Evaluate the RNN model\n",
        "y_pred_rnn = np.argmax(rnn_model.predict(X_test_rnn), axis=-1)\n",
        "\n",
        "# Print RNN accuracy\n",
        "print(\"\\nRNN Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_rnn):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rnn, target_names=label_encoder.classes_))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rnn))\n",
        "\n",
        "# Save the RNN model\n",
        "rnn_model.save('best_rnn_model.h5')\n",
        "print(\"\\nBest RNN model saved as 'best_rnn_model.h5'!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBS7JNY0ow-P",
        "outputId": "53c18bfe-cbb8-4019-9313-d3e55b1c4d48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN...\n",
            "Epoch 1/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 149ms/step - accuracy: 0.0629 - loss: 3.2459 - val_accuracy: 0.0840 - val_loss: 3.0985\n",
            "Epoch 2/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.0987 - loss: 3.0757 - val_accuracy: 0.1333 - val_loss: 2.9408\n",
            "Epoch 3/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.1306 - loss: 2.9397 - val_accuracy: 0.1481 - val_loss: 2.8408\n",
            "Epoch 4/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.1812 - loss: 2.7773 - val_accuracy: 0.1728 - val_loss: 2.7428\n",
            "Epoch 5/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.1793 - loss: 2.7377 - val_accuracy: 0.1827 - val_loss: 2.7194\n",
            "Epoch 6/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 157ms/step - accuracy: 0.2022 - loss: 2.6935 - val_accuracy: 0.2099 - val_loss: 2.6305\n",
            "Epoch 7/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - accuracy: 0.1973 - loss: 2.5817 - val_accuracy: 0.2198 - val_loss: 2.5816\n",
            "Epoch 8/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.2346 - loss: 2.5321 - val_accuracy: 0.2173 - val_loss: 2.5287\n",
            "Epoch 9/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.2505 - loss: 2.5144 - val_accuracy: 0.2346 - val_loss: 2.4632\n",
            "Epoch 10/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.2573 - loss: 2.4271 - val_accuracy: 0.2247 - val_loss: 2.5310\n",
            "Epoch 11/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.2891 - loss: 2.3680 - val_accuracy: 0.2543 - val_loss: 2.4068\n",
            "Epoch 12/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - accuracy: 0.2773 - loss: 2.3858 - val_accuracy: 0.2000 - val_loss: 2.6126\n",
            "Epoch 13/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.2746 - loss: 2.4558 - val_accuracy: 0.2519 - val_loss: 2.3821\n",
            "Epoch 14/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.3187 - loss: 2.3414 - val_accuracy: 0.2469 - val_loss: 2.4215\n",
            "Epoch 15/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.3110 - loss: 2.2968 - val_accuracy: 0.2543 - val_loss: 2.3656\n",
            "Epoch 16/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.3149 - loss: 2.2498 - val_accuracy: 0.2667 - val_loss: 2.3534\n",
            "Epoch 17/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - accuracy: 0.3192 - loss: 2.2539 - val_accuracy: 0.2864 - val_loss: 2.3747\n",
            "Epoch 18/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.3015 - loss: 2.2702 - val_accuracy: 0.2840 - val_loss: 2.3253\n",
            "Epoch 19/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 145ms/step - accuracy: 0.3242 - loss: 2.2365 - val_accuracy: 0.2790 - val_loss: 2.3021\n",
            "Epoch 20/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.3197 - loss: 2.2203 - val_accuracy: 0.2815 - val_loss: 2.2716\n",
            "Epoch 21/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - accuracy: 0.3482 - loss: 2.1438 - val_accuracy: 0.2988 - val_loss: 2.2500\n",
            "Epoch 22/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.3490 - loss: 2.1083 - val_accuracy: 0.3210 - val_loss: 2.2483\n",
            "Epoch 23/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.3553 - loss: 2.1018 - val_accuracy: 0.3259 - val_loss: 2.2346\n",
            "Epoch 24/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.3694 - loss: 2.1004 - val_accuracy: 0.3111 - val_loss: 2.2207\n",
            "Epoch 25/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.3778 - loss: 2.0212 - val_accuracy: 0.3432 - val_loss: 2.1983\n",
            "Epoch 26/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - accuracy: 0.3584 - loss: 2.0569 - val_accuracy: 0.3481 - val_loss: 2.1963\n",
            "Epoch 27/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.3719 - loss: 2.0232 - val_accuracy: 0.3185 - val_loss: 2.1996\n",
            "Epoch 28/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.3434 - loss: 2.0381 - val_accuracy: 0.3580 - val_loss: 2.1563\n",
            "Epoch 29/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.3656 - loss: 2.1018 - val_accuracy: 0.3432 - val_loss: 2.1773\n",
            "Epoch 30/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.4033 - loss: 1.9699 - val_accuracy: 0.3407 - val_loss: 2.1537\n",
            "Epoch 31/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.4119 - loss: 1.9415 - val_accuracy: 0.3506 - val_loss: 2.1670\n",
            "Epoch 32/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.3995 - loss: 1.9501 - val_accuracy: 0.3753 - val_loss: 2.1436\n",
            "Epoch 33/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.4463 - loss: 1.8676 - val_accuracy: 0.3481 - val_loss: 2.1020\n",
            "Epoch 34/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.4198 - loss: 1.8582 - val_accuracy: 0.3778 - val_loss: 2.0809\n",
            "Epoch 35/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.4302 - loss: 1.8806 - val_accuracy: 0.3358 - val_loss: 2.1965\n",
            "Epoch 36/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.4144 - loss: 1.8608 - val_accuracy: 0.3630 - val_loss: 2.1135\n",
            "Epoch 37/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - accuracy: 0.4224 - loss: 1.8492 - val_accuracy: 0.3383 - val_loss: 2.1257\n",
            "Epoch 38/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.4606 - loss: 1.7922 - val_accuracy: 0.3605 - val_loss: 2.0861\n",
            "Epoch 39/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.4414 - loss: 1.8017 - val_accuracy: 0.3679 - val_loss: 2.1118\n",
            "Epoch 40/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - accuracy: 0.4036 - loss: 1.9190 - val_accuracy: 0.3827 - val_loss: 2.0983\n",
            "Epoch 41/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.4588 - loss: 1.7495 - val_accuracy: 0.3432 - val_loss: 2.1197\n",
            "Epoch 42/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - accuracy: 0.4879 - loss: 1.7159 - val_accuracy: 0.3728 - val_loss: 2.0909\n",
            "Epoch 43/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.4827 - loss: 1.7221 - val_accuracy: 0.3506 - val_loss: 2.1434\n",
            "Epoch 44/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - accuracy: 0.4585 - loss: 1.7004 - val_accuracy: 0.3827 - val_loss: 2.0492\n",
            "Epoch 45/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.4511 - loss: 1.7704 - val_accuracy: 0.3728 - val_loss: 2.1080\n",
            "Epoch 46/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.4495 - loss: 1.7412 - val_accuracy: 0.4025 - val_loss: 2.0478\n",
            "Epoch 47/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.4878 - loss: 1.6627 - val_accuracy: 0.3556 - val_loss: 2.1420\n",
            "Epoch 48/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.5082 - loss: 1.6645 - val_accuracy: 0.3827 - val_loss: 2.0656\n",
            "Epoch 49/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.4871 - loss: 1.6144 - val_accuracy: 0.3951 - val_loss: 2.0629\n",
            "Epoch 50/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.4911 - loss: 1.6084 - val_accuracy: 0.3802 - val_loss: 2.1035\n",
            "Epoch 51/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.4794 - loss: 1.6650 - val_accuracy: 0.3852 - val_loss: 2.0805\n",
            "Epoch 52/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5155 - loss: 1.5611 - val_accuracy: 0.3877 - val_loss: 2.0863\n",
            "Epoch 53/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.4784 - loss: 1.6015 - val_accuracy: 0.3679 - val_loss: 2.0793\n",
            "Epoch 54/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.5005 - loss: 1.5817 - val_accuracy: 0.3901 - val_loss: 2.1112\n",
            "Epoch 55/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5255 - loss: 1.5344 - val_accuracy: 0.4074 - val_loss: 2.0535\n",
            "Epoch 56/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.5195 - loss: 1.5072 - val_accuracy: 0.3901 - val_loss: 2.0858\n",
            "Epoch 57/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 0.5362 - loss: 1.4690 - val_accuracy: 0.3802 - val_loss: 2.1147\n",
            "Epoch 58/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5355 - loss: 1.4569 - val_accuracy: 0.4025 - val_loss: 2.0373\n",
            "Epoch 59/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.5311 - loss: 1.4493 - val_accuracy: 0.3901 - val_loss: 2.0787\n",
            "Epoch 60/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.5404 - loss: 1.4509 - val_accuracy: 0.4025 - val_loss: 2.0586\n",
            "Epoch 61/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5360 - loss: 1.4405 - val_accuracy: 0.3852 - val_loss: 2.1106\n",
            "Epoch 62/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5599 - loss: 1.3943 - val_accuracy: 0.4074 - val_loss: 2.0451\n",
            "Epoch 63/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5541 - loss: 1.3971 - val_accuracy: 0.3951 - val_loss: 2.1095\n",
            "Epoch 64/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.5546 - loss: 1.3777 - val_accuracy: 0.4198 - val_loss: 2.0869\n",
            "Epoch 65/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.5593 - loss: 1.3940 - val_accuracy: 0.4074 - val_loss: 2.0339\n",
            "Epoch 66/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.5455 - loss: 1.4284 - val_accuracy: 0.4148 - val_loss: 2.1212\n",
            "Epoch 67/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.5607 - loss: 1.3798 - val_accuracy: 0.4123 - val_loss: 2.0804\n",
            "Epoch 68/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5606 - loss: 1.3770 - val_accuracy: 0.3951 - val_loss: 2.1546\n",
            "Epoch 69/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.5546 - loss: 1.3687 - val_accuracy: 0.4074 - val_loss: 2.0992\n",
            "Epoch 70/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.5910 - loss: 1.3065 - val_accuracy: 0.4025 - val_loss: 2.0794\n",
            "Epoch 71/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.5565 - loss: 1.3609 - val_accuracy: 0.4000 - val_loss: 2.1432\n",
            "Epoch 72/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5773 - loss: 1.3525 - val_accuracy: 0.4370 - val_loss: 2.0500\n",
            "Epoch 73/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5903 - loss: 1.2737 - val_accuracy: 0.4123 - val_loss: 2.1171\n",
            "Epoch 74/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6231 - loss: 1.2297 - val_accuracy: 0.4148 - val_loss: 2.0968\n",
            "Epoch 75/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.6103 - loss: 1.2383 - val_accuracy: 0.4296 - val_loss: 2.1161\n",
            "Epoch 76/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6264 - loss: 1.1904 - val_accuracy: 0.4519 - val_loss: 2.0729\n",
            "Epoch 77/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6156 - loss: 1.1951 - val_accuracy: 0.4494 - val_loss: 2.0710\n",
            "Epoch 78/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6342 - loss: 1.2297 - val_accuracy: 0.4346 - val_loss: 2.1449\n",
            "Epoch 79/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.6231 - loss: 1.2242 - val_accuracy: 0.4370 - val_loss: 2.1480\n",
            "Epoch 80/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.6283 - loss: 1.1871 - val_accuracy: 0.4123 - val_loss: 2.0979\n",
            "Epoch 81/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.6206 - loss: 1.1703 - val_accuracy: 0.4173 - val_loss: 2.2000\n",
            "Epoch 82/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.6228 - loss: 1.1891 - val_accuracy: 0.4198 - val_loss: 2.1858\n",
            "Epoch 83/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.6441 - loss: 1.1879 - val_accuracy: 0.4568 - val_loss: 2.1584\n",
            "Epoch 84/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6474 - loss: 1.0620 - val_accuracy: 0.4346 - val_loss: 2.1576\n",
            "Epoch 85/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6342 - loss: 1.1394 - val_accuracy: 0.4395 - val_loss: 2.1291\n",
            "Epoch 86/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.6170 - loss: 1.1632 - val_accuracy: 0.4074 - val_loss: 2.1852\n",
            "Epoch 87/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6553 - loss: 1.0450 - val_accuracy: 0.4519 - val_loss: 2.1111\n",
            "Epoch 88/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6297 - loss: 1.1581 - val_accuracy: 0.4395 - val_loss: 2.1143\n",
            "Epoch 89/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.6604 - loss: 1.0821 - val_accuracy: 0.4346 - val_loss: 2.1745\n",
            "Epoch 90/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6721 - loss: 1.0548 - val_accuracy: 0.4173 - val_loss: 2.1576\n",
            "Epoch 91/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6554 - loss: 1.1039 - val_accuracy: 0.4198 - val_loss: 2.2852\n",
            "Epoch 92/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.6882 - loss: 0.9880 - val_accuracy: 0.4296 - val_loss: 2.2320\n",
            "Epoch 93/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.6684 - loss: 1.0210 - val_accuracy: 0.4247 - val_loss: 2.2971\n",
            "Epoch 94/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6712 - loss: 1.0436 - val_accuracy: 0.4370 - val_loss: 2.1908\n",
            "Epoch 95/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6816 - loss: 0.9587 - val_accuracy: 0.4395 - val_loss: 2.2251\n",
            "Epoch 96/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.6943 - loss: 1.0344 - val_accuracy: 0.4123 - val_loss: 2.2956\n",
            "Epoch 97/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6523 - loss: 1.0662 - val_accuracy: 0.4444 - val_loss: 2.3131\n",
            "Epoch 98/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6653 - loss: 1.0355 - val_accuracy: 0.4198 - val_loss: 2.2858\n",
            "Epoch 99/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.6699 - loss: 1.0331 - val_accuracy: 0.4469 - val_loss: 2.2299\n",
            "Epoch 100/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - accuracy: 0.7028 - loss: 0.9603 - val_accuracy: 0.4395 - val_loss: 2.2801\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RNN Model Performance:\n",
            "Test Accuracy: 0.4395\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          Axe       0.50      0.43      0.46        14\n",
            " BirdChirping       0.62      0.81      0.70        16\n",
            "     Chainsaw       0.27      0.27      0.27        15\n",
            "     Clapping       0.82      0.45      0.58        20\n",
            "         Fire       0.65      0.81      0.72        16\n",
            "     Firework       0.31      0.31      0.31        13\n",
            "    Footsteps       0.46      0.38      0.41        16\n",
            "         Frog       0.44      0.24      0.31        17\n",
            "    Generator       0.25      0.30      0.27        10\n",
            "      Gunshot       0.33      0.12      0.17        17\n",
            "      Handsaw       0.53      0.67      0.59        12\n",
            "   Helicopter       0.62      0.42      0.50        24\n",
            "       Insect       0.71      0.75      0.73        20\n",
            "         Lion       0.29      0.17      0.21        12\n",
            "         Rain       0.23      0.25      0.24        12\n",
            "      Silence       0.64      0.64      0.64        14\n",
            "     Speaking       0.78      0.37      0.50        19\n",
            "     Squirrel       0.25      0.29      0.27        17\n",
            " Thunderstorm       0.35      0.40      0.38        15\n",
            "  TreeFalling       0.25      0.64      0.36        11\n",
            "VehicleEngine       0.20      0.27      0.23        11\n",
            "   WaterDrops       0.47      0.47      0.47        15\n",
            "    Whistling       0.59      0.77      0.67        13\n",
            "         Wind       0.62      0.45      0.53        22\n",
            "  WingFlaping       0.12      0.12      0.12        16\n",
            "     WolfHowl       0.50      0.64      0.56        11\n",
            "     WoodChop       0.15      0.43      0.22         7\n",
            "\n",
            "     accuracy                           0.44       405\n",
            "    macro avg       0.44      0.44      0.42       405\n",
            " weighted avg       0.47      0.44      0.44       405\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
            "   1  0  6]\n",
            " [ 0 13  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  4  0  0  0  0  2  0  0  1  0  1  1  3  0  0  0  0  1  1  0  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  0  9  0  2  1  1  0  2  1  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
            "   0  0  3]\n",
            " [ 0  0  0  0 13  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0\n",
            "   0  0  0]\n",
            " [ 3  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  1  1  0\n",
            "   0  0  2]\n",
            " [ 0  0  0  0  2  0  6  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  1  0\n",
            "   0  0  2]\n",
            " [ 0  1  2  0  2  0  0  4  0  0  0  0  1  0  0  0  0  2  0  1  0  1  2  0\n",
            "   0  1  0]\n",
            " [ 0  0  2  0  0  0  0  0  3  0  0  0  2  0  1  0  0  1  0  0  1  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  2  0  0  0  0  0  0  2  1  0  1  0  0  0  0  0  0  1  0  0  1  1\n",
            "   5  1  2]\n",
            " [ 0  0  1  0  0  1  0  0  0  0  8  0  0  0  0  0  0  0  0  2  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  1  1  0  0  0  0  1  2  0  0 10  0  0  0  0  0  2  0  0  3  0  0  1\n",
            "   3  0  0]\n",
            " [ 0  1  1  0  0  0  0  0  0  0  0  1 15  0  0  0  0  1  1  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  1  1  2  0  0  2  0  0  1  0  2  0  0  0  0  0\n",
            "   2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  3  1  0  2  2  1  1  1  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  9  0  2  1  0  0  0  0  1\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  1  0  2  1  0  7  0  0  0  1  0  0  1\n",
            "   1  2  1]\n",
            " [ 0  1  0  1  0  0  0  0  0  0  0  1  1  0  0  0  0  5  0  3  4  1  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  1  4  0  0  1  0  0  0  0  0  0  0  0  0  6  2  0  0  0  0\n",
            "   0  0  1]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  7  0  0  1  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  2  0  0  1  0  0  0  0  0  2  0  0  3  0  0  0\n",
            "   1  1  0]\n",
            " [ 1  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  3  0  7  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0 10  0\n",
            "   0  1  0]\n",
            " [ 0  1  0  0  1  0  1  0  0  0  1  1  0  0  4  2  0  0  1  0  0  0  0 10\n",
            "   0  0  0]\n",
            " [ 1  0  0  0  0  1  3  0  0  0  0  0  0  1  1  1  0  1  2  1  1  0  0  0\n",
            "   2  1  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  1  0  0  0  0  0  1  0\n",
            "   0  7  0]\n",
            " [ 0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
            "   1  0  3]]\n",
            "\n",
            "Best RNN model saved as 'best_rnn_model.h5'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Load your audio file\n",
        "file_path = '/content/drive/MyDrive/Audio Files/21_12104.wav'  # Replace with the path to your audio file\n",
        "y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# Extract features\n",
        "features = []\n",
        "\n",
        "# 1. MFCCs (13 features)\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "mfccs_mean = np.mean(mfccs, axis=1)\n",
        "features.extend(mfccs_mean)\n",
        "\n",
        "# 2. Chroma Features (1 feature)\n",
        "chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "chroma_mean = np.mean(chroma)\n",
        "features.append(chroma_mean)\n",
        "\n",
        "# 3. Spectral Contrast (6 features)\n",
        "spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
        "spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
        "features.extend(spectral_contrast_mean)\n",
        "\n",
        "# 4. Spectral Bandwidth (1 feature)\n",
        "spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "spectral_bandwidth_mean = np.mean(spectral_bandwidth)\n",
        "features.append(spectral_bandwidth_mean)\n",
        "\n",
        "# 5. Spectral Rolloff (1 feature)\n",
        "spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "spectral_rolloff_mean = np.mean(spectral_rolloff)\n",
        "features.append(spectral_rolloff_mean)\n",
        "\n",
        "# 6. Zero-Crossing Rate (1 feature)\n",
        "zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
        "zero_crossing_rate_mean = np.mean(zero_crossing_rate)\n",
        "features.append(zero_crossing_rate_mean)\n",
        "\n",
        "# Final feature vector (29 features)\n",
        "audio_features = np.array(features)\n",
        "print(\"Extracted Features:\", audio_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvWvDOhig9WC",
        "outputId": "3575d31e-d721-47d4-f0e1-3c1af165da87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Features: [-3.41216217e+02  2.37820328e+02 -7.58395233e+01  3.00383415e+01\n",
            "  4.63048820e+01 -5.31961966e+00  2.13348999e+01 -6.41554880e+00\n",
            " -5.12659454e+00  1.60339432e+01  3.17877889e+00  3.73776340e+00\n",
            " -1.76511586e+00  6.29004717e-01  1.25360154e+01  7.84837768e+00\n",
            "  1.10629346e+01  1.31765242e+01  1.76815033e+01  2.62041708e+01\n",
            "  3.46152252e+01  1.75817916e+03  2.96563667e+03  4.92008501e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape and scale the features\n",
        "audio_features_scaled = scaler.transform(audio_features.reshape(1, -1))  # Shape must be (1, 29)\n",
        "\n",
        "# Predict the class\n",
        "prediction = np.argmax(model.predict(audio_features_scaled), axis=-1)\n",
        "\n",
        "# Map the prediction to the original class name\n",
        "predicted_class = label_encoder.inverse_transform(prediction)\n",
        "print(f\"Predicted Class: {predicted_class[0]}\")\n"
      ],
      "metadata": {
        "id": "xbwVYCUhhRk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}